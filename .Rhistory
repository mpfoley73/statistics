install.packages("radiant.data")
file.create('.nojekyll')
list.files()
?list.files()
list.files(all.files = TRUE)
library(tidyverse)
library(gtsummary)
library(foreign)
library(scales)
library(janitor)
library(flextable)
cs <- list()
# Two continuous (c) vars
cs$dat1 <- read.spss("./input/pearson-correlation.sav", to.data.frame = TRUE)
# Two continuous (c) vars, but violating normality/outlier assumption.
cs$dat1b <- read.spss("./input/spearmans-correlation.sav", to.data.frame = TRUE)
# Two ordinal (o) vars
cs$dat2 <- read.spss("./input/kendalls-tau-b.sav", to.data.frame = TRUE)
bind_rows(
`Linear` = cs$dat1,
`Non-Linear` = cs$dat1b,
.id = "set"
) %>%
ggplot(aes(x = time_tv, y = cholesterol)) +
geom_point(color = "snow4", alpha = 0.6) +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "goldenrod", linetype = 2) +
theme_minimal() +
facet_wrap(vars(set)) +
labs(
title = "Scatter Plot of Cholesterol Concentration by Time Watching TV",
subtitle = "Two data sets, only one meeting all conditions for parametric test.",
x = "Time (mins/d)",
y = "Cholesterol (mmol/L)"
)
cs$dat2 %>%
count(income, tax_too_high) %>%
ggplot(aes(x = income, y = tax_too_high, size = n)) +
geom_point(color = "snow4", alpha = 0.6) +
theme_minimal() +
labs(
title = "Scatter Plot of Tax Attitude by Income Level",
x = "Income Level",
y = "Taxes too high?"
)
shapiro.test(cs$dat1$time_tv)
shapiro.test(cs$dat1$cholesterol)
(cs$cc_pearson <-
cor.test(cs$dat1$cholesterol, cs$dat1$time_tv, method = "pearson")
)
cor(cs$dat1$cholesterol, cs$dat1$time_tv, method = "kendall")
cor(cs$dat1$cholesterol, cs$dat1$time_tv, method = "spearman")
lm(
y ~ x,
data = cs$dat1 %>% mutate(y = scale(cholesterol), x = scale(time_tv))
)
cov(rank(cs$dat2$income), rank(cs$dat2$tax_too_high)) /
(sd(rank(cs$dat2$income)) * sd(rank(cs$dat2$tax_too_high)))
(cs$spearman <-
cor.test(
as.numeric(cs$dat2$tax_too_high),
as.numeric(cs$dat2$income),
method = "spearman")
)
(cs$kendall <-
cor.test(
as.numeric(cs$dat2$tax_too_high),
as.numeric(cs$dat2$income),
method = "kendall")
)
(tea <- matrix(c(3, 1, 1, 3), nrow = 2,
dimnames = list(Guess = c("Milk", "Tea"),
Truth = c("Milk", "Tea"))))
tibble::tribble(
~` `, ~Sampled, ~`Not Sampled`,  ~Total,
"success", "k", "K-k", "K",
"non-success", "n-k", "(N-K)-(n-k)", "N-K",
"Total", "n", "N-n", "N"
) %>%
flextable::flextable() %>%
flextable::autofit()
k <- 3; n <- 4; K <- 4; N <- 8
choose(K, k) * choose(N-K, n-k) / choose(N, n) +
choose(K, k+1) * choose(N-K, n-(k+1)) / choose(N, n)
(pi <- phyper(q = k-1, m = K, n = N-K, k = n, lower.tail = FALSE))
fisher.test(tea, alternative = "greater")
# Gender vs Competition
# https://statistics.laerd.com/premium/spss/or2x2/odds-ratio-2x2-in-spss.php
cs$or2x2 <- read.spss("./input/odds-ratio-2x2-individual-scores.sav", to.data.frame = TRUE)
# Same data, already summarized! Do no use this.
# https://statistics.laerd.com/premium/spss/cstfa/chi-square-test-for-association-in-spss.php
cs$cstfa <- read.spss("./input/chi-square-test-for-association-frequencies.sav", to.data.frame = TRUE)
# Gender vs Competition again, but this time with small cell counts
# https://statistics.laerd.com/premium/spss/fet2x2/fishers-exact-test-in-spss.php
cs$fet2x2 <- read.spss("./input/fishers-exact-test-2x2-individual-scores.sav", to.data.frame = TRUE)
cs$or2x2 %>%
gtsummary::tbl_cross(
percent = "row",
label = list(comp ~ "Competitive")
) %>%
gtsummary::add_p()
exer_table <- cs$or2x2 %>% table()
expected <- marginSums(exer_table, 1) %*% t(marginSums(exer_table, 2)) / sum(exer_table)
(X2 <- sum((exer_table - expected)^2 / expected))
(df <- (2 - 1) * (2 - 1))
pchisq(X2, df, lower.tail = FALSE)
(G <- 2 * sum(exer_table * log(exer_table / expected)))
pchisq(G, df, lower.tail = FALSE)
(cs$or2x2_chisq.test <- chisq.test(exer_table, correct = FALSE))
(cs$or2x2_g.test <- DescTools::GTest(exer_table, correct = "none"))
chisq.test(exer_table, correct = FALSE, simulate.p.value = TRUE)
phyper(q = exer_table[1, 1] - 1,  # k minus 1
m = sum(exer_table[1, ]),  # K
n = sum(exer_table[2, ]),  # N - K
k = sum(exer_table[, 1]),  # n
lower.tail = FALSE) * 2
(cs$or2x2_fisher.test <- fisher.test(exer_table))
# by hand
sqrt(cs$or2x2_chisq.test$statistic / sum(exer_table) / (min(2, 2) - 1))
# from package
(cs$or2x2_v <- rcompanion::cramerV(exer_table))
matrix(c("A", "C", "B", "D"), nrow = 2)
# by hand
det(matrix(exer_table, nrow = 2)) /
sqrt(prod(c(marginSums(exer_table, 1), marginSums(exer_table, 2))))
# from package
(cs$or2x2_phi <- psych::phi(exer_table))
cs$or2
# Smoking vs Lung Cancer
# https://statistics.laerd.com/premium/spss/rr2x2/relative-risk-2x2-in-spss.php
cs$rr2x2 <- read.spss(
"./input/relative-risk-2x2-individual-scores.sav",
to.data.frame = TRUE
)
# 37x5 data set from [PSU STAT 505](https://online.stat.psu.edu/stat505/lesson/4/4.7).
wechsler <- readr::read_fwf(
file = "./input/wechsler.txt",
col_positions = readr::fwf_widths(
c(2, 3, 3, 3, 3),
col_names = c("ID", "Information", "Similarities", "Arithmetic", "PictureCompletion")
),
show_col_types = FALSE
)
# Correlation between Information and Similarities
cor(wechsler$Information, wechsler$Similarities)
# t.test with 95% CI.
cor.test(wechsler$Information, wechsler$Similarities)
