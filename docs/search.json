[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "Preface\nThese notes are a personal reference related to my statistics work.\nRepo for this quarto book: https://github.com/mpfoley73/statistics.\nThere are at least three approaches to establishing statistical inference: frequentist, likelihood, and Bayesian. Think of them philosophically. The frequentist approach is the path of action. It rejects a null hypothesis if the p-value is low because repeated sample analyses are likely to agree. The likelihood approach is the path of knowledge. It compares the observed summary measure to the likelihoods of the other possible realities. The Bayesian approach is the path of belief. It uses a summary measure to update the prior belief.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html",
    "href": "01-frequentist-statistics.html",
    "title": "1  Frequentist Statistics",
    "section": "",
    "text": "1.1 Central Tendancy and Dispersion\nSuppose you have a data set with \\(j = [1 .. p]\\) variables. Each variable will have a distribution that can be characterized by its mean and variance. If you consider them together, you can see how variance and covariance are related. For the matrix algebra that follows, assume the data are organized in rows, so \\(X_j\\) is a row vector of \\(n\\) observations. \\(X_{ij}\\) refers to column \\(i\\) of row \\(j\\).\nThe mean of row vector \\(X_j\\) is \\(\\bar{x}_j = \\frac{1}{n} \\sum_{i = 1}^n X_{ij}\\). \\(\\bar{x}_j\\) estimates the population mean, \\(\\mu_j = E(X_j)\\). The collection of means are a column vector.\n\\[\\boldsymbol{\\bar{x}} = \\begin{pmatrix} \\bar{x}_1 \\\\ \\bar{x}_2 \\\\ \\cdots \\\\ \\bar{x}_p  \\end{pmatrix}\\]\nThe variance of row vector \\(X_j\\) is the average squared difference from the mean, \\(s_j^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar{x}_j)^2\\). \\(s_j^2\\) estimates the population variance, \\(\\sigma_j^2 = E(X_j - \\mu_j)^2\\). Again, the collection is represented as a column vector,\n\\[\\boldsymbol{s}^2 = \\begin{pmatrix} s_1^2 \\\\ s_2^2 \\\\ \\cdots \\\\ s_p^2  \\end{pmatrix}\\]\nThe square root of \\(s^2\\) is called the standard deviation. The concept of variance can be extended to pairs of variables, \\(j\\) and \\(k\\). The covariance of \\(X_j\\) and \\(X_k\\) is the average product of differences from their respective means, \\(s_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar{x}_j) (X_{ik} - \\bar{x}_k)\\). \\(s_{jk}\\) estimates the population covariance, \\(\\sigma_{jk} = E\\{ (X_{ij} - \\mu_j) (X_{ik} - \\mu_k)\\}\\). Notice how the sign of \\(s_{jk}\\) tells you how the variables relate. It’s positive if when one variable is larger than its mean, so is the other. It’s zero if the value of one variable tells you nothing about the other. It can be shown that \\(s_{jk}\\) is equivalently expressed as\n\\[\ns_{jk} = \\frac{1}{n-1} \\left[ \\sum_{i=1}^n X_{ij}X_{ik} - \\frac{\\sum_{i = 1}^n X_{ij} \\sum_{i = 1}^n X_{ik}}{n} \\right]\n\\]\nThis is how it is actually calculated. The first term is dot product, \\(X_j \\cdot X_k\\). The second term is the product of the averages. Use matrix algebra to generalize across all \\(p\\) variables to form the variance-covariance matrix.\n\\[\n\\begin{align}\nS &= \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{x}) (X_i - \\bar{x})' \\\\\n&= \\frac{1}{n-1} \\left[ \\sum_{i=1}^n X_i X_i^{'} - \\frac{\\sum_{i = 1}^n X_i \\sum_{i = 1}^n X_i}{n} \\right]\n\\end{align}\n\\]\n\\(S\\) estimates the population variance-covariance matrix, \\(\\boldsymbol{\\Sigma}\\). Divide the covariances by their product of their standard deviations to get their correlation, \\(r_{jk} = \\frac{s_{jk}}{s_j s_k}\\). \\(r_{jk}\\) estimates the population correlation, \\(\\rho_{jk} = \\frac{\\sigma_{jk}}{\\sigma_j \\sigma_k}\\).",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html#hypothesis-testing",
    "href": "01-frequentist-statistics.html#hypothesis-testing",
    "title": "1  Frequentist Statistics",
    "section": "1.2 Hypothesis Testing",
    "text": "1.2 Hypothesis Testing\nP-values express how surprising a summary measure is given the null hypothesis (H0). Suppose you hypothesize that IQs have increased from their intended mean of \\(\\mu\\) = 100, \\(\\sigma\\) = 15. H0 is \\(\\mu_0\\) = 100 with alternative H1 that \\(\\mu\\) &gt; 100. Suppose also that you are right: \\(\\mu\\) is actually 106. The presumed and actual distribution of IQs would look like this:\n\n\n\n\n\n\n\n\n\nAccording to the Central Limit Theorem (CLM), repeated samples of size n from a large population will yield \\(\\bar{x}\\) values that approach a normal distribution centered at \\(\\mu\\) with a standard deviation equal to the the standard error, \\(SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{15}{\\sqrt{30}}\\) = 2.7. Repeated samples would be distributed \\(\\sim N(100, 2.7^2).\\)\nSuppose you take a random sample of n = 30 IQs from the population and measure \\(\\bar{x}\\) = 104, SD = 15.2. How surprising is this if H0 is true? I.e., what is the probability of observing an \\(\\bar{x}\\) of 104 if \\(\\mu\\) is 100 and \\(\\sigma\\) is 15? The situation looks like this:\n\n\n\n\n\n\n\n\n\nThe \\(\\alpha\\) region starts at qnorm(.05, 100, 2.7, lower.tail = FALSE) = 104.5. \\(\\bar{x}\\) would have had to be at least that large to reject H0. The probability of measuring \\(\\bar{x} \\ge 104\\) is derived from the z score, \\(z = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}} = \\frac{104 - 100}{2.7}\\) = 1.5. The probability of measuring a z score that high given H0 is \\(P(z \\ge 1.5)\\) = 0.072, meaning 7.2% of the area under the null distribution is to the right of 104. Therefore, do not reject H0 at the \\(\\alpha\\) = .05 level of significance.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html#type-i-and-ii-errors",
    "href": "01-frequentist-statistics.html#type-i-and-ii-errors",
    "title": "1  Frequentist Statistics",
    "section": "1.3 Type I and II Errors",
    "text": "1.3 Type I and II Errors\nEither H0 (\\(\\mu = 106\\)) or H1 (\\(\\mu \\ge 106\\)) is correct. You must choose to either reject or not reject H0. That means there are four possible states at the end of your analysis. If your summary measure is extreme enough for you to declare a “positive” result and reject H0, you are either correct (true positive) or incorrect (false positive). False positives are called Type I errors. Alternatively, if it is not extreme enough, you are either correct (true negative) or incorrect (false negative). False negatives are called Type II errors.\nThe probabilities of landing in these four states depend on your chosen significance level, \\(\\alpha\\), and on the statistical power of the study, 1 - \\(\\beta\\).\n\n\n\n\n\n\n\n\n\nH0 True\nH0 False\n\n\n\n\nPositive test, reject H0.\nFalse Positive Type I Error Probability = \\(\\alpha\\)\nTrue Positive Good Call!  Probability = 1 - \\(\\beta\\)\n\n\nNegative test, do not reject H0.\nTrue Negative  Good Call! Probability = (\\(1 - \\alpha\\))\nFalse Negative Type II Error Probability = \\(\\beta\\)\n\n\n\n\\(\\alpha\\) is the expected Type I error rate - extreme summary measures occurring by chance when there is no effect to measure. \\(\\beta\\) is the expected Type II error rate - summary measures that by chance were not extreme enough to reject H0 even though there is an actual effect.\nIf the population mean really was \\(\\mu\\) = 100, any sample mean greater than 104.5 would mistakenly reject H0 at the \\(\\alpha\\) = .05 significance level, a Type I error. However, the population mean is actually \\(\\mu\\) = 106, and our measured \\(\\bar{x}\\) = 104 only achieved a p-value of 0.072, so we failed to reject H0, a Type II error.\nHad the sample size been larger, the study would have had the power to reject H0. Here’s the plot with n = 50. The null and actual distributions are tighter, and the \\(\\alpha\\) region starts at 103.5.\n\n\n\n\n\n\n\n\n\nThe area under the actual distribution to the left of \\(alpha\\) is labeled \\(\\beta\\). It’s the Type II error zone. You don’t usually see much discussion of \\(\\beta\\) in reports because \\(\\beta\\) is based on the unknown actual population distribution. \\(\\beta\\) is relevant at the design stage. It informs how large your sample needs to be in order to reject H0 given some expected \\(\\bar{x}\\). Interestingly, you can see how there can be such a thing as too much power. If n is large enough, you can reject H0 with even a trivial effect size.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html#statistical-power",
    "href": "01-frequentist-statistics.html#statistical-power",
    "title": "1  Frequentist Statistics",
    "section": "1.4 Statistical Power",
    "text": "1.4 Statistical Power\nThe ability to detect a difference when it exists (the true positive) is called the power of the test. It’s measured by the area outside of \\(\\beta\\). Changing n from 30 to 50 reduced the area in the \\(\\beta\\) region, increasing the power of the test.\nStatistical power is an increasing function of sample size, effect size, and significance level. The positive association with significance level means there is a trade-off between Type I and Type II error rates. A small \\(\\alpha\\) sets a high bar for rejecting H0, but you run the risk of failing to appreciate a real difference. On the other hand, a large \\(\\alpha\\) sets a low bar for rejecting H0, but you run the risk of mistaking a random difference as real.\nThe 1 - \\(\\beta\\) statistical power threshold is usually set at .80, similar to the \\(\\alpha\\) = .05 level of significance threshold convention. Given a real effect, a study with a statistical power of .80 will only find a positive test result 80% of the time. You may think more power is better, but beware that with a large enough sample size, even trivial effect sizes may yield a positive test result. You need to consider both sides of this coin.\nA power analysis determines the sample size required to detect a threshold effect size given an \\(\\alpha\\) level of significance. A power analysis expresses the relationship among four components. If you know any three, it tells you the fourth: The components are n, \\(\\alpha\\), , 1 - \\(\\beta\\), and Cohen’s d = \\((\\bar{x} - \\mu_0)/\\sigma\\).\nSuppose you set power at .80, significance level at .05, and n = 30. What effect size will this design detect?\n\n(pwr &lt;- pwr::pwr.t.test(\n  n = 30,\n  sig.level = .05,\n  power = 0.80,\n  type = \"one.sample\",\n  alternative = \"greater\"\n))\n\n\n     One-sample t test power calculation \n\n              n = 30\n              d = 0.464949\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\n\nAn effect size of d = 0.465 will fall in the \\(\\alpha\\) = .05 region with probability 1 - \\(\\beta\\) = .80 if the sample size is n = 30. Multiply d = 0.465 by \\(\\sigma\\) = 15 to convert to the IQ units, 7.0. More likely, you will use the power test to detect the required sample size. Suppose you set \\(1 - \\beta\\) = .8 and \\(\\alpha\\) = .05, and want to detect an effect size of \\(5 / 15\\).\n\n(pwr &lt;- pwr::pwr.t.test(\n  d = 5 / 15,\n  sig.level = .05,\n  power = 0.80,\n  type = \"one.sample\",\n  alternative = \"greater\"\n))\n\n\n     One-sample t test power calculation \n\n              n = 57.02048\n              d = 0.3333333\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\n\nYou need a larger sample, n = 58. You can use the power test formula for various n sizes to see the relationship with effect size. Note: the y-axis multiplies Cohen’s d by \\(\\sigma\\) to get the effect size in original units.\n\n\n\n\n\n\n\n\n\nThe dashed lines show a sample size of 30 is required to detect an effect size of 7 at a .05 significance level with 80% probability.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html#power-analyses",
    "href": "01-frequentist-statistics.html#power-analyses",
    "title": "1  Frequentist Statistics",
    "section": "1.5 Power Analyses",
    "text": "1.5 Power Analyses\n\nOne-Sample Prop Test (greater)\nHow large must a sample be to detect a proportion meaningfully greater than 50% (null hypothesis H0: \\(\\pi_0 = .50\\))? You might define meaningfully as at least 10 percentage points.\nThe effect size for a proportion power calculation uses the arcsine transformation. 10 percentage points equates to an effect size of about .20.\n\\[ h = 2*\\arcsin(\\sqrt{p1})-2*\\arcsin(\\sqrt{p2})\n\\tag{1.1}\\]\n\n(h &lt;- pwr::ES.h(p1 = .60, p2 = .50))\n\n[1] 0.2013579\n\n\nUse the power calculation to calculate n for an effect size of .20 with 80% power and .05 level of significance.\n\n(pwr_calc &lt;- pwr::pwr.p.test(\n  h = h, \n  sig.level = .05, \n  power = .80, \n  alternative = \"greater\"\n))\n\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2013579\n              n = 152.4863\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\n\nIf you repeatedly draw samples of size 153 from a population with proportion \\(\\pi\\) = .60, expect to reject the H0 80% of the time. The critical value for a one-sided test is 87 (0.57), meaning only measured proportions of at least 0.57 reject H0.\n\nn &lt;- ceiling(pwr_calc$n)\n\n(crit_val &lt;- qbinom(p = .05, size = n, prob = .50, lower.tail = FALSE))\n## [1] 87\n\n(crit_prop &lt;- crit_val / n)\n## [1] 0.5686275\n\nIn a plot of the theoretical distributions for samples of size 153 from populations centered at \\(\\pi_0\\) = .50 and \\(\\pi\\) = .60, 20% of the \\(\\pi\\) distribution is to the left of the critical value.\n\n\nShow the code\nH0_str &lt;- \"H0: p = .50\"\nH0 &lt;- .50\nact_str &lt;- \"Actual: pi = .60\"\npop &lt;- .60\npal &lt;- c(\"gray30\", \"darkgoldenrod\")\nnames(pal) &lt;- c(H0_str, act_str)\n\nsampling_dist &lt;- \n  tibble(\n    grp = factor(c(rep(H0_str, n), rep(act_str, n)), levels = c(H0_str, act_str)),\n    cnt = rep(seq(1, n, 1), 2),\n    prob = c(rep(H0, n), rep(pop, n)),\n    prop = cnt / n,\n    dens = pmap_dbl(list(cnt, prob), \\(x, prob) dbinom(x, size = n, prob))\n  )\n\nsampling_dist |&gt;\n  ggplot() +\n  geom_line(aes(x = prop, y = dens, color = grp, fill = grp)) +\n  geom_area(aes(x = prop, fill = grp, \n                y = if_else(cnt &gt;= crit_val & grp == H0_str, dens, NA_real_)), \n            alpha = .2) +\n  geom_area(aes(x = prop, fill = grp, \n                y = if_else(cnt &lt;= crit_val & grp == act_str, dens, NA_real_)), \n            alpha = .2) +\n  annotate(\"text\", x = .55, y = .005, label = \"beta\", parse = TRUE, size = 4.5, \n           color = pal[act_str]) +\n  annotate(\"text\", x = .58, y = .005, label = \"alpha\", parse = TRUE, size = 4.5, \n           color = pal[H0_str]) +\n  geom_vline(xintercept = H0, color = pal[H0_str], linetype = 2, linewidth = 1) +\n  geom_vline(xintercept = pop, color = pal[act_str], linetype = 2, linewidth = 1) +\n  scale_fill_manual(values = pal) +\n  scale_color_manual(values = pal) +\n  scale_x_continuous(breaks = c(H0, pop, crit_prop), labels = comma_format(.01)) +\n  coord_cartesian(xlim = c(.3, .7)) +\n  guides(fill = \"none\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = .5)) +\n  labs(\n    x = \"Proportion\", y = \"Density\", color = NULL,\n    title = \"Power Analysis for One Proportion, One-sided\",\n    subtitle = str_wrap(glue(\n      \"Effect size h = .2 (10 pct pts), 80% power, Sample size n = {comma(n)}. \",\n      \"Proportions &gt; {comma(crit_prop, .01)} reject {H0_str} at alpha = .05.\"\n    ), 95)\n  )\n\n\n\n\n\n\n\n\n\n\n\nOne-Sample Prop Test (two-sided)\nHow does this change for a two-sided test of the same effect size?\n\n(pwr_calc &lt;- pwr::pwr.p.test(\n  h = h, \n  sig.level = .05, \n  power = .80, \n  alternative = \"two.sided\"\n))\n\n\n     proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2013579\n              n = 193.5839\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nYou need more people for a two-sided test. n increased from 153 to 194.\n\nn &lt;- ceiling(pwr_calc$n)\n\n(crit_val_lwr &lt;- qbinom(p = .025, size = n, prob = .50, lower.tail = TRUE))\n## [1] 83\n\n(crit_prop_lwr &lt;- crit_val_lwr / n)\n## [1] 0.4278351\n\n(crit_val_upr &lt;- qbinom(p = .025, size = n, prob = .50, lower.tail = FALSE))\n## [1] 111\n\n(crit_prop_upr &lt;- crit_val_upr / n)\n## [1] 0.5721649\n\nHere are the theoretical distributions.\n\n\n\n\n\n\n\n\n\n~20% of the area under Actual: pi = .40 is to the right of 0.43 and ~20% of the area under Actual: pi = .60 is to the left of 0.57.\n\npbinom(q = crit_val_lwr, size = n, prob = pop_lwr, lower.tail = FALSE)\n## [1] 0.1932935\npbinom(q = crit_val_upr, size = n, prob = pop_upr, lower.tail = TRUE)\n## [1] 0.2356584\n\n\n\nTwo-Sample Prop Test (greater)\nHow many people would you need to survey to detect a clear difference in support for an issue between two groups? \\(H_0\\) is that groups A and B have the same support rate. As before, you set a minimum effect size of 10 percentage points. A one-sided test assesses whether A has a higher (lower) support rate than B.\n\nh &lt;- pwr::ES.h(p1 = .60, p2 = .50)\n\n(pwr &lt;- pwr::pwr.2p.test(\n  h = h, \n  sig.level = .05, \n  power = .80, \n  alternative = \"greater\"\n))\n\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2013579\n              n = 304.9725\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\nNOTE: same sample sizes\n\n\nWhoa, we need twice as many people for each group! Why is that? Recall from your notes that the two proportions test is a test on the distribution of proportion difference, \\(d = p_1 - p_2\\). The sampling distribution of \\(d\\) has a standard error \\(SE = \\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}\\). The test statistic is \\(Z = (d-d_0) / SE\\).\nThere is a similar test that allows for unequal group sample sizes. If the first group is 305, so will be the second group. If the first group is 400, the second needs to be 247. The minimum sample size is always going to be for equal sample sizes.\n\npwr::pwr.2p2n.test(\n  h = h, \n  n1 = 400,\n  sig.level = .05, \n  power = .80, \n  alternative = \"greater\"\n)\n\n\n     difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2013579\n             n1 = 400\n             n2 = 246.4288\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\nNOTE: different sample sizes\n\n\n\nn &lt;- ceiling(pwr$n)\n\nSE &lt;- sqrt(.5 * (1 - .5) / n + .6 * (1 - .6) / n)\n\n(crit_val &lt;- qnorm(p = .05, mean = 0, sd = SE, lower.tail = FALSE))\n## [1] 0.06592883\n\n\n\n\n\n\n\n\n\n\n\n\nTwo-Sample Prop Test (two-sided)\nHow many people would you need to survey to detect a clear difference in support for an issue between two groups? \\(H_0\\) is that groups A and B have the same support rate. Again, suppose you care about a difference of at least a 10 percentage points. In the two-sided test, group A can be a higher or lower than B.\n\nh &lt;- pwr::ES.h(p1 = .60, p2 = .50)\n\n(pwr &lt;- pwr::pwr.2p.test(\n  h = h, \n  sig.level = .05, \n  power = .80, \n  alternative = \"two.sided\"\n))\n\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2013579\n              n = 387.1677\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: same sample sizes\n\n\nThe two-sided test requires a larger sample and the critical values are a little further from zero.\n\nn &lt;- ceiling(pwr$n)\n\nSE &lt;- sqrt(.5 * (1 - .5) / n + .6 * (1 - .6) / n)\n\n(crit_val_lwr &lt;- qnorm(p = .025, mean = 0, sd = SE, lower.tail = TRUE))\n## [1] -0.06965147\n\n(crit_val_upr &lt;- qnorm(p = .025, mean = 0, sd = SE, lower.tail = FALSE))\n## [1] 0.06965147\n\n\n\n\n\n\n\n\n\n\n\n\nOne-sample t-test (greater)\nHow many people would you need to survey to detect a clear level of agreement for an item measured in a 7-level Likert scale? This is an ordinal variable, but you can treat it as continuous. \\(H_0\\) is 4 (middle value) and \\(H_a\\) is &gt;4. By “clear agreement”, you might mean “at least .5 points”. If true average is &gt;4, but less than 4.5, you are okay with not rejecting \\(H_0\\).\n\nsd &lt;- 1  # assumption\ncohen.d &lt;- (4.5 - 4) / sd\n\n(pwr &lt;- pwr::pwr.t.test(\n  d = cohen.d, \n  sig.level = .05, \n  power = .80, \n  type = \"one.sample\",\n  alternative = \"greater\"\n))\n\n\n     One-sample t test power calculation \n\n              n = 26.13753\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\n\nIf you repeatedly survey random samples of 27 people from a population where the average preference is level is 4.5 of 7, you should expect to reject H0 80% of the time.\n\nn &lt;- ceiling(pwr$n)\nse &lt;- sd / sqrt(n)\n\n(crit_val &lt;- qt(p = .05, df = n - 1, lower.tail = FALSE))\n## [1] 1.705618\n\n(crit_rating &lt;- crit_val * se + 4)\n## [1] 4.328246\n\nYou can see this in a plot of the theoretical distributions for samples of size 27 from populations centered at 4 and 4.5. ~20% of the mean 4.5 curve is to the left of the critical value.\n\n\n\n\n\n\n\n\n\n\n\nOne-sample t-test (two-sided)\nHow many people would you need to survey to detect a clear level of preference for an item measured in a 7-level Likert scale? Treating the ordinal variable as continuous. \\(H_0\\) is 4 (middle value) and \\(H_a\\) is &lt;&gt;4. “Clear agreement” might mean “at least .5 points” either direction. If true average is between 3.5 and 4.5, you are okay with not rejecting \\(H_0\\).\n\nsd &lt;- 1  # assumption\ncohen.d &lt;- (4.5 - 4) / sd\n\n(pwr &lt;- pwr::pwr.t.test(\n  d = cohen.d, \n  sig.level = .05, \n  power = .80, \n  type = \"one.sample\",\n  alternative = \"two.sided\"\n))\n\n\n     One-sample t test power calculation \n\n              n = 33.36713\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nThe sample size increased from 27 to 34. If you repeatedly survey random samples of 34 people from a population where the average preference is level is 3.5 or 4.5 of 7, you should expect to reject H0 80% of the time.\n\nn &lt;- ceiling(pwr$n)\nse &lt;- sd / sqrt(n)\n\n(crit_val_lwr &lt;- qt(p = .05, df = n - 1, lower.tail = TRUE))\n## [1] -1.69236\n(crit_val_upr &lt;- qt(p = .05, df = n - 1, lower.tail = FALSE))\n## [1] 1.69236\n\n(crit_rating_lwr &lt;- crit_val_lwr * se + 4)\n## [1] 3.709763\n(crit_rating_upr &lt;- crit_val_upr * se + 4)\n## [1] 4.290237\n\nYou can see this in a plot of the theoretical distributions for samples of size 34 from populations centered at 3.5, 4 and 4.5. ~20% of the mean 4.5 curve and mean 3.5 curve is to the left of the critical value.\n\n\n\n\n\n\n\n\n\n\n\nIndep Samples t-test (greater)\nHow many people would you need to survey to detect a clear group difference in agreement for an item measured in a 7-level Likert scale? \\(H_0\\) is that groups A and B have the same average rating. As before, you set a minimum effect size of .5 points. The one-sided test assesses whether A has a higher (lower) average than B.\n\ns1 &lt;- 1  # assumption\ns2 &lt;- 1  # assumption\ncohen.d &lt;- (4.5 - 4) / s1\n\n(pwr &lt;- pwr::pwr.t2n.test(\n  n1 = 54,\n  d = cohen.d, \n  sig.level = .05, \n  power = .80, \n  alternative = \"greater\"\n))\n\n\n     t test power calculation \n\n             n1 = 54\n             n2 = 46.80756\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = greater\n\n\nWe need about twice as many people for each group! Recall from your notes that the independent samples t-test is a test on the distribution of the difference in means, \\(\\hat{d} = \\bar{x}_1 - \\bar{x}_2\\). The sampling distribution of \\(d\\) has a standard error \\(SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\\). The test statistic is \\(T = (\\hat{d}-d_0) / SE\\).\n\nn1 &lt;- 54\nn2 &lt;- ceiling(pwr$n2)\nsp2 &lt;- ((n1 - 1)*s1^2 + (n2 - 1)*s2^2) / (n1 + n2 - 2)\nSE &lt;- sqrt(sp2) * sqrt(1/n1 + 1/n2)\ndf &lt;- n1 + n2 - 2\n\n(crit_val &lt;- qt(p = .05, df = df, lower.tail = FALSE))\n## [1] 1.660391\n\n(crit_diff &lt;- crit_val * SE)\n## [1] 0.3312267\n\n\n\n\n\n\n\n\n\n\n\n\nIndep Samples t-test (two-sided)\nHow many people would you need to survey to detect a clear group difference in agreement for an item measured in a 7-level Likert scale? \\(H_0\\) is that groups A and B have the same average rating. As before, you set a minimum effect size of .5 points. The two-sided test assesses whether A has a different average than B.\n\ns1 &lt;- 1  # assumption\ns2 &lt;- 1  # assumption\ncohen.d &lt;- (4.5 - 4) / s1\n\n(pwr &lt;- pwr::pwr.t2n.test(\n  n1 = 54,\n  d = cohen.d, \n  sig.level = .05, \n  power = .80, \n  alternative = \"two.sided\"\n))\n\n\n     t test power calculation \n\n             n1 = 54\n             n2 = 77.74746\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nIf \\(n_1\\) is 54, then \\(n_2\\) needs to be 78 - higher than the one-sided test.\n\nn1 &lt;- 54\nn2 &lt;- ceiling(pwr$n2)\nsp2 &lt;- ((n1 - 1)*s1^2 + (n2 - 1)*s2^2) / (n1 + n2 - 2)\nSE &lt;- sqrt(sp2) * sqrt(1/n1 + 1/n2)\ndf &lt;- n1 + n2 - 2\n\n(crit_val_l &lt;- qt(p = .05, df = df, lower.tail = TRUE))\n## [1] -1.656659\n(crit_val_u &lt;- qt(p = .05, df = df, lower.tail = FALSE))\n## [1] 1.656659\n\n(crit_diff_l &lt;- crit_val_l * SE)\n## [1] -0.2932757\n(crit_diff_u &lt;- crit_val_u * SE)\n## [1] 0.2932757",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html#p-value-intuition",
    "href": "01-frequentist-statistics.html#p-value-intuition",
    "title": "1  Frequentist Statistics",
    "section": "1.6 p-value Intuition",
    "text": "1.6 p-value Intuition\nWhat distribution of p-values would you expect if there is a true effect and you repeated the study many times? What if there is no true effect? The answer is completely determined by the statistical power of the study.1\nTo see this, run 100,000 simulations of an experiment measuring the average IQ from a sample of size n = 26. The samples will be 26 random values from the normal distribution centered at 106 with a standard deviation of 15. H0 is \\(\\mu\\) = 100.\n\n# 100,000 random samples of IQ simulations from a normal distribution where\n# SIGMA = 15. True population value is 100, but we'll try other values.\nn_sims &lt;- 1E5\nmu &lt;- 100\nSIGMA &lt;- 15\n\nrun_sim &lt;- function(MU_0 = 106, n = 26) {\n  data.frame(i = 1:n_sims) %&gt;%\n    mutate(\n      x = map(i, ~ rnorm(n = n, mean = MU_0, sd = SIGMA)),\n      z = map(x, ~ t.test(., mu = mu)),\n      p = map_dbl(z, ~ .x$p.value),\n      x_bar = map_dbl(x, mean)\n    ) %&gt;%\n    select(x_bar, p)\n}\n\nThe null hypothesis is that the average IQ is 100. Our rigged simulation finds an average IQ of 106 - an effect size of 6.\n\nsim_106_26 &lt;- run_sim(MU_0 = 106, n = 26)\n\nglimpse(sim_106_26)\n## Rows: 100,000\n## Columns: 2\n## $ x_bar &lt;dbl&gt; 112.4862, 101.5958, 104.4396, 106.2315, 102.1960, 108.6005, 104.…\n## $ p     &lt;dbl&gt; 0.0001718698, 0.6059147572, 0.0985672856, 0.0428457450, 0.443911…\n\nmean(sim_106_26$x_bar)\n## [1] 105.9953\n\nThe statistical power achieved by the simulations is 50%. That is, the typical simulation detected the effect size of 6 at the .05 significance level about 50% of the time.\n\npwr.t.test(\n  n = 26,\n  d = (106 - 100) / 15,\n  sig.level = .05,\n  type = \"one.sample\",\n  alternative = \"two.sided\"\n)\n\n\n     One-sample t test power calculation \n\n              n = 26\n              d = 0.4\n      sig.level = 0.05\n          power = 0.5004646\n    alternative = two.sided\n\n\nThat means that given a population with an average IQ of 106, a two-sided hypothesis test of H0: \\(\\mu\\) = 100 from a sample of size 26 will measure an \\(\\bar{x}\\) with a p-value under .05 only 50% of the time. You can see that in this histogram of p-values.\n\nsim_106_26 %&gt;% plot_sim()\n\n\n\n\n\n\n\n\nHad there been no effect to observe, you’d expect all p-values to be equally likely, so the 20 bins would all have been 5% of the number of simulations – i.e., uniformly distributed under the null. This is called “0 power”, although 5% of the p-values will still be significant at the .05 level. The 5% of p-values &lt; .05 is the Type II error rate - that probability of a positive test result when there is no actual effect to observe.\n\nrun_sim(MU_0 = 100, n = 26) %&gt;%\n  plot_sim(MU_0 = 100)\n\n\n\n\n\n\n\n\nIf you want a higher powered study that would detect the effect at least 80% of the time (the normal standard), you’ll need a higher sample size. How high? Conduct the power analysis again, but specify the power while leaving out the sample size.\n\npwr.t.test(\n  power = 0.80,\n  d = (106 - 100) / 15,\n  sig.level = .05,\n  type = \"one.sample\",\n  alternative = \"two.sided\"\n)\n\n\n     One-sample t test power calculation \n\n              n = 51.00945\n              d = 0.4\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nYou need 51 people (technically, you might want to round up to 52). Here’s what that looks like. 80% of p-values are below .05 now.\n\nrun_sim(MU_0 = 106, n = 51) %&gt;%\n  plot_sim(MU_0 = 106)\n\n\n\n\n\n\n\n\nSo far, we’ve discovered that when there is an effect, the probability that the measure p-value is under the \\(\\alpha\\) significance level equals the power of the study, 1 - \\(\\beta\\) - the true positive rate, and \\(\\beta\\) will be above the \\(\\alpha\\) level - the false negative rate. We’ve also discovered that when there is no effect, all p-values are equally likely, so \\(\\alpha\\) of them will be below the \\(alpha\\) level of significance - the false positive rate, and 1 - \\(\\alpha\\) will be above \\(\\alpha\\) - the true negative rate.\nIt’s not the case that all p-values below 0.05 are support for the alternative hypothesis. If the statistical power is high enough, a p-value just under .05 can be even less likely under the null hypothesis.\n\nrun_sim(MU_0 = 108, n = 51)  %&gt;%\n    mutate(bin = case_when(p &lt; .01 ~ \"0.00 - 0.01\",\n                         p &lt; .02 ~ \"0.01 - 0.02\",\n                         p &lt; .03 ~ \"0.02 - 0.03\",\n                         p &lt; .04 ~ \"0.03 - 0.04\",\n                         p &lt; .05 ~ \"0.04 - 0.05\",\n                         TRUE ~ \"other\")\n  ) %&gt;%\n  janitor::tabyl(bin)\n\n         bin     n percent\n 0.00 - 0.01 86544 0.86544\n 0.01 - 0.02  5044 0.05044\n 0.02 - 0.03  2340 0.02340\n 0.03 - 0.04  1308 0.01308\n 0.04 - 0.05   908 0.00908\n       other  3856 0.03856\n\n\n(Recall that under H0, all p-values are equally likely, so each of the percentile bins would contain 1% of p-values.)\nIn fact, at best, a p-value between .04 and .05 can only be about four times as likely under the alternative hypothesis as the null hypothesis. If your p-value is just under .05, it is at best weak support for the alternative hypothesis.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "01-frequentist-statistics.html#footnotes",
    "href": "01-frequentist-statistics.html#footnotes",
    "title": "1  Frequentist Statistics",
    "section": "",
    "text": "This section is based on ideas I learned from homework assignment 1 in Daniel Lakens’s Coursera class Improving your statistical inferences.↩︎",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Frequentist Statistics</span>"
    ]
  },
  {
    "objectID": "02-likelihood-statistics.html",
    "href": "02-likelihood-statistics.html",
    "title": "2  Likelihood Statistics",
    "section": "",
    "text": "2.1 Maximum Likelihood Estimation\nLikelihood functions are an approach to statistical inference (along with Frequentist and Bayesian). Likelihoods are functions of a data distribution parameter. For example, the binomial likelihood function is\n\\[L(\\theta) = \\frac{n!}{x!(n-x)!}\\cdot \\theta^x \\cdot (1-\\theta)^{n-x}\\]\nYou can use the binomial likelihood function to assess the likelihoods of various hypothesized population probabilities, \\(\\theta\\). Suppose you sample n = 10 coin flips and observe x = 8 successful events (heads) for an estimated heads probability of .8. The likelihood of a fair coin, \\(\\theta\\) = .05 given the evidence is only 0.044.\nYou can see from the plot below that the likelihood function is maximized at \\(\\theta\\) = 0.8 (likelihood = 0.302). The actual value of the likelihood is unimportant - it’s a density.\nYou can combine likelihood estimates by multiplying them. Suppose one experiment finds 4 of 10 heads and a second experiment finds 8 of 10 heads. You’d hope two experiments could be combined to achieve the same result as a single experiment with 12 of 20 heads, and that is indeed the case.\nCompare competing estimates of \\(\\theta\\) with the likelihood ratio. The likelihood of \\(\\theta\\) = .8 vs \\(\\theta\\) = .5 (fair coin) is \\(\\frac{L(\\theta = 0.8)}{L(\\theta = 0.5)}\\) = 6.87.\nA likelihood ratio of &gt;= 8 is moderately strong evidence for an alternative hypothesis. A likelihood ratio of &gt;= 32 is strong evidence for the alternative hypothesis. Keep in mind that likelihood ratios are relative evidence of H1 vs H0 - both hypotheses may be quite unlikely!\nA set of studies usually include both positive and negative test results. You can see this from the likelihood plots below. These are the likelihood curves produced from x = [0..3] successes in a sample of 3. Think of this as the likelihood of [0..3] positive findings in 3 studies based on an \\(\\alpha\\) = .05 level of significance and a .80 1 - \\(\\beta\\) statistical power of the study.\nThe yellow line at .05 is the likelihood of a Type I error of concluding there is an effect when H1 is false. The yellow line at .80 is the likelihood of a Type II error of concluding there is no effect when H1 is true. The likelihood of 0 of 3 experiments reporting a positive effect under \\(\\alpha\\) = .05, 1 - \\(\\beta\\) = .80 is much higher under H0 (\\(\\theta\\) = .05) than under H1 (\\(\\theta\\) = .80): 0.857 vs 0.008 for a likelihood ratio of 107. The likelihood of 1 of 3 experiments reporting a positive effect is still higher under H0 than under H1: 0.135 vs 0.096 for a likelihood ratio of 1.41. For 2 of 3 experiments reporting a positive effect the likelihood ratio is 0.019, and for 3 of 3 experiments reporting a positive effect the likelihood ratio is 0.00024.\nThe blue lines demarcates the points where mixed results are as likely as unanimous results. A set of studies are likely to produce unanimous results only if the number of studies is fairly high \\((\\gt 1 - n / (n+1))\\) or low \\((&lt; n / (n + 1))\\).\nSuppose a process \\(T\\) is the time to event of a process following an exponential probability distribution (notes), \\(f(T = t; \\lambda) = \\lambda e^{-\\lambda t}\\). Fitting a model to the data means estimating the distribution’s parameter, \\(\\lambda\\). The way this is typically done is by the process of maximum likelihood estimation (MLE). MLE compares the observed outcomes to those produced by the range of possible parameter values within the parameter space \\(\\lambda \\in \\Lambda\\) and chooses the parameter value that maximizes the likelihood of producing the observed outcome, \\(\\hat{\\lambda} = \\underset{\\lambda \\in \\Lambda}{\\arg\\max} \\hat{L}_t(\\lambda, t)\\).\nFor the exponential distribution, the likelihood that \\(\\lambda\\) produces the observed outcomes is the product of the probability densities for each observation because they are a sequence of independent variables.\n\\[\\begin{eqnarray}\nL(\\lambda; t_1, t_2, \\dots, t_n) &=& f(t_1; \\lambda) \\cdot f(t_2; \\lambda) \\cdots f(t_n; \\lambda) \\\\\n&=& \\Pi_{i=1}^n f(t_i; \\lambda) \\\\\n&=& \\Pi_{i=1}^n \\lambda e^{-\\lambda t_i} \\\\\n&=& \\lambda^n \\exp \\left(-\\lambda \\sum_{i=1}^n t_i \\right)\n\\end{eqnarray}\\]\nThat is difficult to optimize, but the log of it is simple.\n\\[l(\\lambda; t_1, t_2, \\dots, t_n) = n \\ln(\\lambda) - \\lambda \\sum_{i=1}^n t_i\\]\nMaximize the log-likelihood equation by setting its derivative to zero and solving for \\(\\lambda\\).\n\\[\\begin{eqnarray}\n\\frac{d}{d \\lambda} l(\\lambda; t_1, t_2, \\dots, t_n) &=& \\frac{d}{d \\lambda} \\left( n \\ln(\\lambda) - \\lambda \\sum_{i=1}^n t_i \\right) \\\\\n0 &=& \\frac{n}{\\lambda} - \\sum_{i=1}^n t_i \\\\\n\\lambda &=& \\frac{n}{\\sum_{i=1}^n t_i}\n\\end{eqnarray}\\]\n\\(\\lambda\\) is the reciprocal of the sample mean.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Likelihood Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html",
    "href": "03-bayesian-statistics.html",
    "title": "3  Bayesian Statistics",
    "section": "",
    "text": "3.1 Bayes’ Theorem\nBayesian inference is an alternative to classical (aka, frequentist) inference. Both methods assume a data generating mechanism expressed as a likelihood, but while classical inference treats the mechanism as infinitely repeatable, Bayesian inference treats each event as unique. Instead of estimating a single population parameter (usually the mean), Bayesian inference estimates the parameter distribution. In fact Bayesian inference insists that all uncertainties be described by probabilities. Finally, whereas the machinery of classical inference is maximizing likelihood, Bayesian inference updates a prior probability distribution in light of the new information.\nBayes’ Theorem is the inverse conditional probability, the probability of the condition given the observed outcome. It reorganizes the relationship between joint probability and conditional probability.\n\\[\n\\begin{align}\nP(\\theta D) = P(\\theta|D)P(D) &= P(D|\\theta)P(\\theta) \\\\\nP(\\theta|D) &= \\frac{P(D|\\theta)P(\\theta)}{P(D)}\n\\end{align}\n\\]\nThe probability of \\(\\theta\\) after observing \\(D\\) is equal to the probability of observing \\(D\\) when \\(\\theta\\) is true divided by the probability of observing \\(D\\) under any circumstance.\nOne illustration of Bayes’ Theorem is interpreting medical tests. \\(P(D|\\theta)\\) is the test’s sensitivity, the probability of a positive test result \\(D\\) when the condition \\(\\theta\\) in fact exists. \\(P(\\theta)\\) is the probability prior to testing, the general rate. The numerator of Bayes’ Theorem is the joint probability, the probability of having the condition and testing positive, \\(P(D \\theta) = P(D|\\theta)P(\\theta)\\). However, there is another way to test positive - the false positive, \\(P(D | \\hat{\\theta})\\)! A test’s specificity is the probability of a negative test result when the condition does not exist. Specificity is the compliment of the false positive, \\(P(\\hat{D} | \\hat{\\theta}) = 1 - P(D | \\hat{\\theta})\\). The denominator of Bayes’ Theorem is the overall probability of a positive test result.\n\\[\n\\begin{align}\nP(\\theta|D) &= \\frac{P(D|\\theta)P(\\theta)}{P(D)} \\\\\n&= \\frac{P(D|\\theta)P(\\theta)}{P(D|\\theta)P(\\theta) + P(D|\\hat\\theta)P(\\hat\\theta)} \\\\\n&= \\frac{\\text{sensitivity} \\cdot \\text{prior}}{\\text{sensitivity} \\cdot \\text{prior} + (1 - \\text{specificity}) \\cdot (1 - \\text{prior})}\n\\end{align}\n\\]\nSuppose E. Coli is typically present in \\(P(\\theta)\\) = 4.5% of samples, and an E. Coli screen has a sensitivity of \\(P(D|\\theta)\\) = 95% and a specificity of 1 - \\(P(D|\\hat\\theta)\\) = 99%. Given a positive test result, what is the probability that E. Coli is actually present?\n\\[P(\\theta|D) = \\frac{.95\\cdot .045}{.95\\cdot .045 + (1 - .99)(1 - .045)} = \\frac{.04275}{.05230} = 81.7\\%.\\]\nThe elements of Bayes’ Theorem come directly from the contingency table. The first row is the positive test result. The probability of E. Coli is the joint probability of E. Coli and a positive test divided by the probability of a positive test.\nE. ColiSafeTotalPositive Test.95 * .045 = 0.04275.01 * .955 = 0.009550.05230Negative Test.05 * .045 = 0.00225.99 * .955 = 0.945450.94770Total0.045000.955001.00000",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#bayes-theorem",
    "href": "03-bayesian-statistics.html#bayes-theorem",
    "title": "3  Bayesian Statistics",
    "section": "",
    "text": "Think of \\(P(\\theta)\\) as the strength of your belief prior to considering \\(D\\).\n\\(P(D|\\theta)\\) is the likelihood of observing \\(D\\) from a generative model with parameter \\(\\theta\\). Likelihoods are probability densities, and are not quite the same as probabilities. For continuous variables, likelihoods will sum to greater than 1.1\n\\(P(D)\\) is the likelihood of observing \\(D\\) from any prior. It is the marginal distribution, or prior predictive distribution of \\(D\\). The likelihood divided by the marginal distribution is the proportional adjustment made to the prior in light of the data.\n\\(P(\\theta|D)\\) is the strength of your belief posterior to considering \\(D\\).",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#bayesian-inference",
    "href": "03-bayesian-statistics.html#bayesian-inference",
    "title": "3  Bayesian Statistics",
    "section": "3.2 Bayesian Inference",
    "text": "3.2 Bayesian Inference\nBayesian inference extends the logic of Bayes’ Theorem by replacing the prior probability estimate that \\(\\theta\\) is true with a prior probability distribution that \\(\\theta\\) is true. Rather than saying, “I am x% certain \\(\\theta\\) is true,” you say “I believe the probability that \\(\\theta\\) is true is somewhere in a range that has maximum likelihood at x%”.\n\\[\nf(\\theta | D) = \\frac{f(D|\\theta) f(\\theta)}{\\int_\\Theta f(D|\\theta) f(\\theta) d\\theta}\n\\]\nThis formula expresses the posterior distribution of \\(\\theta\\) as a function of the prior distribution and new information. Let \\(\\Pi(\\theta)\\) be the prior probability function. \\(\\Pi(\\theta)\\) has a PMF or PDF \\(f(\\theta)\\), and a set of conditional distributions, \\(f(D|\\theta)\\), called the generative model that express the likelihood of observing \\(D\\) given \\(\\theta\\). The posterior probability distribution of \\(\\theta\\), conditioned on the observance of \\(D\\), is the joint distribution of \\(D\\) and \\(\\theta\\) (aka joint density, the product of the likelihood and the prior) divided by the marginal distribution of \\(D\\) (aka marginal density or prior predictive distribution). For discrete cases, replace the integral with a sum. The numerator makes the posterior proportional to the prior. The denominator is a normalizing constant that scales the likelihood into a proper density function (whose values sum to 1).\nIt is easier to see how observed evidence shifts the probabilities of the priors into their posterior probabilities by working with discrete priors first. From there it is straight-forward to grasp the more abstract case of continuous prior and posterior distributions.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#markov-chain-monte-carlo-mcmc",
    "href": "03-bayesian-statistics.html#markov-chain-monte-carlo-mcmc",
    "title": "3  Bayesian Statistics",
    "section": "3.3 Markov Chain Monte Carlo (MCMC)",
    "text": "3.3 Markov Chain Monte Carlo (MCMC)\nMarkov chain Monte Carlo (MCMC) methods are a class of algorithms for random sampling from high-dimensional probability distributions. Whereas Monte Carlo methods draw independent samples from a distribution, MCMC draw samples where the next value is dependent on the prior sample, creating a chain that zeros in on the target. MCMC improves on the less efficient rejection sampling, grid search, etc. methods. An example will show how Bayesian inference works with the less efficient methods, and the more sophisticated MCMC methods.2\nThe Howell data set contains the height (cm) of 165 adult males. Human height has an \\(\\sim N(\\mu, \\sigma)\\) distribution. What is the expected height of an adult male?\n\n# downloaded this from \n# https://github.com/rmcelreath/rethinking/blob/master/data/Howell1.csv\nhowell &lt;- \n  read_delim(\"input/Howell1.csv\", delim = \";\", show_col_types = FALSE) %&gt;%\n  filter(age &gt;= 18, male == 1)\n\nhowell %&gt;% ggplot(aes(sample = height)) + stat_qq() + geom_qq_line() +\n  labs(title = \"Adult heights are ~normally distributed.\")\n\n\n\n\n\n\n\n\n\n3.3.1 The Classical Approach\nThe classical approach is to construct a 95% CI around the mean with a one-sample mean t test. The mean height is 160.4 (95% CI, 159.4 to 161.3) with standard deviation 6.0.\n\nt.test(howell$height)\n\n\n    One Sample t-test\n\ndata:  howell$height\nt = 342.78, df = 164, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 159.4348 161.2822\nsample estimates:\nmean of x \n 160.3585 \n\n\n\n\n3.3.2 Rejection Sampling\nRejection sampling samples the parameter space (\\(\\mu\\) and \\(\\tau\\)), then conditions on the observed evidence (\\(\\bar{y}\\)).\n\nITER &lt;- 10^5\n\nset.seed(12345)\n\ndat &lt;- tibble(\n  mu = round(runif(ITER, 150, 170), 1),\n  tau = round(runif(ITER, .3, .6), 2),\n  sampled_height = round(rnorm(ITER, mu, 1/sqrt(tau)), 1)\n)\n\n# Condition on observed mean (160.4)\nobserved_mean &lt;- round(mean(howell$height), 1)\ndat %&gt;% \n  filter(sampled_height == observed_mean) %&gt;% \n  summarize(mu_mean = mean(mu), mu_025 = quantile(mu, .025), mu_975 = quantile(mu, .975))\n\n# A tibble: 1 × 3\n  mu_mean mu_025 mu_975\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    160.   157.   163.\n\n\nThis is rather inefficient. We generated 100,000 data points, then conditioned on just the 533 that had the observed mean. Plus, we limited ourselves to one-decimal precision for the search. However, the result, 160.4 (95% CI, 157.3 to 163.4) was close to the classical estimate of 160.4 (95% CI, 159.4 to 161.3)\n\n\n3.3.3 Gibbs Sampler\nSection @ref(normal-pop-est) explains that if you have data from a normally distributed population \\(\\sim N(\\mu, \\sigma)\\), you can use a normal prior for \\(\\mu \\sim N(\\mu_0, \\tau_0)\\) where \\(\\tau = 1 / \\sigma^2\\), and a gamma prior for \\(\\tau \\sim \\text{Gamma}(a, b)\\). The posterior distributions are\n\\[\n\\begin{align}\n\\mu|y & \\sim N\\left( \\frac{n \\tau \\bar{y}}{n \\tau + \\tau_0}, n \\tau + \\tau_0 \\right) \\\\\n\\tau|y & \\sim \\text{Gamma} \\left( a = \\frac{n}{2}, b = \\frac{1}{2} \\sum_i (y_i - \\mu)^2 \\right)\n\\end{align}\n\\]\nThe Gibbs sampler algorithm is to set priors, randomly sample from rnorm() and rgamma() to get posteriors, then make the posteriors the new priors for repeated iterations. After some burn-in period, the posteriors should stabilize. Take the mean and quantiles of the posteriors (minus the burn-in). From prior knowledge, we know average height is \\(\\mu_0 = 175 \\pm 10\\). As a rule of thumb, \\(\\pm\\) is 2SD, so \\(\\sigma_0 = 5\\) and therefore \\(\\tau_0 = 1 / 5^2\\). For gamma, we can use priors \\(a = .01\\) and \\(b = .01\\).\n\nset.seed(12345)\n\n# Iterations\nITER &lt;- 10^3\n\n# Prior parameter values based on intuition or prior studies.\nmu_0 &lt;- 175\ntau_0 &lt;- 1 / 5^2\n\n# Monitors to track burn-in.\nmonitor_mu &lt;- numeric(ITER)\nmonitor_tau &lt;- numeric(ITER)\n\n# Initialize the algorithm.\n(n &lt;- nrow(howell))\n## [1] 165\ny &lt;- howell$height\n(y_bar &lt;- mean(y))\n## [1] 160.3585\n(mu &lt;- mean(y))\n## [1] 160.3585\n(tau &lt;- 1 / var(y))\n## [1] 0.027693\na &lt;- .01\nb &lt;- .01\n\nfor(iter in 1:ITER) {\n  # mu\n  new_mu &lt;- (n * tau * y_bar) / (n * tau + tau_0)\n  new_tau &lt;- n * tau + tau_0\n  monitor_mu[iter] &lt;- rnorm(1, new_mu, 1 / sqrt(new_tau))\n  # tau\n  new_a &lt;- a + n/2\n  new_b &lt;- b + .5 * sum((y-mu)^2)\n  monitor_tau[iter] &lt;- rgamma(1, new_a, new_b)\n  # update state\n  mu &lt;- monitor_mu[iter]\n  tau &lt;- monitor_tau[iter]\n}\n\n# Discard burn-in and estimate.\nmean(monitor_mu[-500])\n## [1] 158.9003\nquantile(monitor_mu[-500], c(.025, .975))\n##     2.5%    97.5% \n## 157.8919 159.8737\n\n# Check out the burn-in. Actually looks like it took 1 iteration.\ntibble(index = 1:ITER, M = monitor_mu) %&gt;% ggplot(aes(x = index, y = M)) + geom_line()\n\n\n\n\n\n\n\n\n\n\n3.3.4 Metropolis-Hastings\nThe Metropolis-Hastings model is like MCMC except that the posterior is accepted with probability \\(\\min(R, 1)\\) where \\(R\\) is\n\\[\nR = \\frac{f(y|\\theta')f(\\theta')}{f(y|\\theta)f(\\theta)} \\frac{q(\\theta|\\theta')}{q(\\theta'|\\theta)}\n\\]\nIf the proposed distribution is symmetric, the second term drops out and \\(R\\) is just the ratio of posterior distributions. The symmetric version is called Metropolis instead of Metropolis-Hastings.\nSuppose your data is \\(n = 100\\) values from a \\(N(\\mu = 2, \\tau = 1/4)\\) distribution.\n\nset.seed(12345)\n\n# Iterations\nITER &lt;- 10^3\n\n# Prior parameter values based on intuition or prior studies.\nmu_0 &lt;- 175\ntau_0 &lt;- 1 / 5^2\n\n# Monitors to track burn-in.\nmonitor_mu &lt;- numeric(ITER)\nmonitor_tau &lt;- numeric(ITER)\n\n# Initialize the algorithm.\n(n &lt;- nrow(howell))\n\n[1] 165\n\ny &lt;- howell$height\n(y_bar &lt;- mean(y))\n\n[1] 160.3585\n\n(mu &lt;- mean(y))\n\n[1] 160.3585\n\n(tau &lt;- 1 / var(y))\n\n[1] 0.027693\n\na &lt;- .01\nb &lt;- .01\n\nfor(iter in 1:ITER) {\n  # mu\n  new_mu &lt;- (n * tau * y_bar) / (n * tau + tau_0)\n  new_tau &lt;- n * tau + tau_0\n  proposed_mu &lt;- rnorm(1, new_mu, 1 / sqrt(new_tau)) # tentative for now!\n  # tau\n  new_a &lt;- a + n/2\n  new_b &lt;- b + .5 * sum((y-mu)^2)\n  monitor_tau[iter] &lt;- rgamma(1, new_a, new_b)\n  # update state\n  # log of the acceptance ratio\n  logR &lt;- sum(dnorm(y, proposed_mu, 1/sqrt(tau), log = T)) - # new likelihood\n          sum(dnorm(y, mu         , 1/sqrt(tau), log = T)) + # old likelihood\n          dnorm(proposed_mu, mu_0, 1/sqrt(tau_0), log = T) - # new prior\n          dnorm(mu         , mu_0, 1/sqrt(tau_0), log = T)   # old prior\n  # accept with probability min(R,1)\n  logU &lt;- log(runif(1,0,1))\n  if(logU &lt; logR) {mu &lt;- new_mu}\n  monitor_mu[iter] &lt;- mu # this is either current or the proposed.\n  tau &lt;- monitor_tau[iter]\n}\n\n# Discard burn-in and estimate.\nmean(monitor_mu[-500])\n\n[1] 158.9385\n\nquantile(monitor_mu[-500], c(.025, .975))\n\n    2.5%    97.5% \n158.5900 159.2169 \n\n# Check out the burn-in. Actually looks like it took 1 iteration.\ntibble(index = 1:ITER, M = monitor_mu) %&gt;% ggplot(aes(x = index, y = M)) + geom_line()\n\n\n\n\n\n\n\n\n\n\n3.3.5 Other Notes\nOne simple Bayesian approach is to run several (we’ll use 1,000) experiments that sample 100 ad impression events from an rbinom() generative model using a uniform prior distribution of 0-30% click probability. The resulting 1,000 row data set of click probabilities is the prior predictive distribution of \\(D\\), the denominator of Bayes’ Theorem. The subset where \\(D = 13\\) is the likelihood, \\(P(D|\\theta)\\). The sampled \\(\\theta\\)’s are the prior, \\(P(\\theta) = \\text{unif}(.0, .3)\\). Their product is the joint probability distribution, \\(P(D|\\theta)P(\\theta)\\), the numerator of Bayes’ Theorem. This method is called rejection sampling because you sample across the whole parameter space, then condition on the observed evidence.\n\ndf_sim &lt;- tibble(\n  click_prob = runif(1000, 0.0, 0.3),\n  click_n = rbinom(1000, 100, click_prob)\n)\n\ndf_sim %&gt;% \n  mutate(is_13 = factor(click_n == 13, levels = c(TRUE, FALSE))) %&gt;%\n  ggplot(aes(x = click_prob, y = click_n, color = is_13)) +\n  geom_point(alpha = 0.6, show.legend = FALSE) +\n  geom_hline(yintercept = 13, color = \"steelblue\", linetype = 1, linewidth = .5) +\n  scale_color_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray80\")) +\n  scale_y_continuous(breaks = c(seq(0, 40, 10), 13)) +\n  labs(title = \"Joint probability of observed clicks and click probability\",\n       subtitle = \"with conditioning on 13 observed clicks.\",\n       y = \"clicks per 100 ads\",\n       x = expression(theta))\n\n\n\n\n\n\n\n\nCondition the joint probability distribution on the 30 rows that produced 13 observed clicks to update the prior. The quantile() function returns the median and the .025 and .975 percentile values - the credible interval.\n\n# median and credible interval\n(sim_ci &lt;- df_sim %&gt;% filter(click_n == 13) %&gt;% pull(click_prob) %&gt;% \n  quantile(c(.025, .5, .975)))\n\n     2.5%       50%     97.5% \n0.1030532 0.1428307 0.2028469 \n\n\nThe posterior click rate likelihood is 14.3% with 95% credible interval (10.3%, 20.3%). Here is the density plot of the 30 simulations that produced the 13 clicks. The median and 95% credible interval are marked.\n\ndf_sim %&gt;% \n  filter(click_n == 13) %&gt;%\n  ggplot(aes(x = click_prob)) +\n  geom_density() +\n  geom_vline(xintercept = sim_ci[2]) +\n  geom_vline(xintercept = sim_ci[1], linetype = 2) +\n  geom_vline(xintercept = sim_ci[3], linetype = 2) +\n  # coord_cartesian(xlim = c(0, .3)) +\n  scale_x_continuous(breaks = c(seq(0, .3, .05), sim_ci), labels = percent_format(.1)) +\n  labs(title = \"Posterior click likelihood distribution\", \n       subtitle = glue(\"p = {percent(sim_ci[2], .1)}, 95%-CI (\",\n       \"{percent(sim_ci[1], .1)}, {percent(sim_ci[3], .1)})\"),\n       x = expression(theta), y = \"density (likelihood)\")\n\n\n\n\n\n\n\n\nThat’s pretty close to the classical result! Instead of sampling, you could define a discrete set of candidate click probabilities and calculate the click probability density for the 100 ad impressions. This method is called grid approximation.\n\ndf_bayes &lt;- expand.grid(\n  click_prob = seq(0.01, .30, by = .001), \n  click_n = 0:100\n) %&gt;%\n  mutate(\n    prior = dunif(click_prob, min = 0, max = 0.3),\n    likelihood = dbinom(click_n, 100, click_prob),\n    probability = likelihood * prior / sum(likelihood * prior)\n  )\n\ndf_bayes %&gt;% \n  mutate(is_13 = factor(click_n == 13, levels = c(TRUE, FALSE))) %&gt;%\n  # filter(probability &gt; .0001) %&gt;%\n  ggplot(aes(x = click_prob, y = click_n, color = is_13)) +\n  geom_point(aes(color = probability), show.legend = FALSE, size = 1) +\n  geom_hline(yintercept = 13, color = \"steelblue\", linetype = 1, linewidth = .5) +\n  coord_cartesian(ylim = c(0, 50)) +\n  scale_y_continuous(breaks = c(seq(0, 50, 10), 13)) +\n  scale_color_gradient(low = \"#FFFFFF\", high = \"steelblue\") +\n  # scale_color_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray20\")) +\n  labs(title = \"Joint probability of clicks and click probability.\",\n       subtitle = \"with conditioning on 13 observed clicks.\",\n       y = \"clicks per 100 ads\",\n       x = expression(theta))\n\n\n\n\n\n\n\n\nCondition the joint probability distribution on the 13 observed clicks to update your prior. Resample the posterior probability to create a distribution.\n\ndf_bayes_13 &lt;- df_bayes %&gt;% filter(click_n == 13) %&gt;%\n  mutate(posterior = probability / sum(probability))\n\nsampling_idx &lt;- sample(\n  1:nrow(df_bayes_13), \n  size = 10000, \n  replace = TRUE, \n  prob = df_bayes_13$posterior\n)\n\nsampling_vals &lt;- df_bayes_13[sampling_idx, ]\n\n(df_bayes_ci &lt;- quantile(sampling_vals$click_prob, c(.025, .5, .975)))\n\n 2.5%   50% 97.5% \n0.079 0.135 0.212 \n\n\n\n\n\n\n\n\n\n\n\nYou can use a Bayesian model to estimate multiple parameters. Suppose you want to predict the water temperature in a lake on Jun 1 based on 5 years of prior water temperatures.\n\ntemp &lt;- c(19, 23, 20, 17, 23)\n\nYou model the water temperature as a normal distribution, \\(\\mathrm{N}(\\mu, \\sigma^2)\\) with a prior distribution \\(\\mu = \\mathrm{N}(18, 5^2)\\) and \\(\\sigma = \\mathrm{unif}(0, 10)\\) based on past experience.\nUsing the grid approximation approach, construct a grid of candidate \\(\\mu\\) values from 8 to 30 degrees incremented by .5 degrees, and candidate \\(\\sigma\\) values from .1 to 10 incremented by .1 - a 4,500 row data frame.\n\nmdl_grid &lt;- expand_grid(mu = seq(8, 30, by = 0.5),\n                        sigma = seq(.1, 10, by = 0.1))\n\nFor each combination of \\(\\mu\\) and \\(\\sigma\\), the prior probabilities are the densities from \\(\\mu = \\mathrm{N}(18, 5^2)\\) and \\(\\sigma = \\mathrm{unif}(0, 10)\\). The combined prior is their product. The likelihoods are the products of the probabilities of observing each temp given the candidate \\(\\mu\\) and \\(\\sigma\\) values.\n\nmdl_grid_2 &lt;- mdl_grid %&gt;%\n  mutate(\n    mu_prior = map_dbl(mu, ~dnorm(., mean = 18, sd = 5)),\n    sigma_prior = map_dbl(sigma, ~dunif(., 0, 10)),\n    prior = mu_prior * sigma_prior, # combined prior,\n    likelihood = map2_dbl(mu, sigma, ~dnorm(temp, .x, .y) %&gt;% prod()),\n    posterior = likelihood * prior / sum(likelihood * prior)\n  )\n\n\n\n\n\n\n\n\n\n\nCalculate a credible interval by drawing 10,000 samples from the grid with sampling probability equal to the calculated posterior probabilities. Use the quantile() function to estimate the median and .025 and .975 quantile values.\n\nsampling_idx &lt;- sample(1:nrow(mdl_grid), size = 10000, replace = TRUE, prob = mdl_grid$posterior)\nsampling_vals &lt;- mdl_grid[sampling_idx, c(\"mu\", \"sigma\")]\nmu_ci &lt;- quantile(sampling_vals$mu, c(.025, .5, .975))\nsigma_ci &lt;- quantile(sampling_vals$sigma, c(.025, .5, .975))\nci &lt;- qnorm(c(.025, .5, .975), mean = mu_ci[2], sd = sigma_ci[2])\n\ndata.frame(temp = seq(0, 30, by = .1)) %&gt;%\n  mutate(prob = map_dbl(temp, ~dnorm(., mean = ci[2], sd = sigma_ci[2])),\n         ci = if_else(temp &gt;= ci[1] & temp &lt;= ci[3], \"Y\", \"N\")) %&gt;%\n  ggplot(aes(x = temp, y = prob)) +\n  geom_area(aes(y = if_else(ci == \"N\", prob, 0)), \n            fill = \"firebrick\", show.legend = FALSE) +\n  geom_line() +\n  geom_vline(xintercept = ci[2], linetype = 2) +\n  theme_minimal() +\n  scale_x_continuous(breaks = seq(0, 30, 5)) +\n  theme(panel.grid.minor = element_blank()) +\n  labs(title = \"Posterior temperature probability\", \n       subtitle = glue(\"mu = {ci[2] %&gt;% scales::number(accuracy = .1)}, 95%-CI (\",\n       \"{ci[1] %&gt;% scales::number(accuracy = .1)}, \",\n       \"{ci[3] %&gt;% scales::number(accuracy = .1)})\"))\n\n\n\n\n\n\n\n\nWhat is the probability the temperature is at least 18?\n\npred_temp &lt;- rnorm(1000, mean = sampling_vals$mu, sampling_vals$sigma)\nscales::percent(sum(pred_temp &gt;= 18) / length(pred_temp))\n\n[1] \"56%\"\n\n\n\ngibbs_normal &lt;- function(y, mu_0, tau_0, a, b, n_iter){\n  n &lt;- length(y)\n  y_mean &lt;- mean(y)\n  \n  mu_sample &lt;- tau_sample &lt;- numeric(n_iter)\n  \n  # starting values\n  mu_sample[1] &lt;- mean(y)\n  tau_sample[1] &lt;- 1 / var(y)\n\n  # Gibbs sampler\n  for(i in 2:n_iter){\n    # mu\n    tau &lt;- tau_sample[i-1]\n    mean_mu &lt;- (n * y_mean * tau + mu_0 * tau_0) / (n * tau + tau_0)\n    precision_mu &lt;- n * tau + tau_0\n    mu_sample[i] &lt;- rnorm(1, mean_mu, 1 / sqrt(precision_mu))\n    # tau\n    mu &lt;- mu_sample[i-1]\n    tau_sample[i] &lt;- rgamma(1, a + n/2, b + .5 * sum((y - mu)^2))\n  }\n  \n  return(list(mu = mu_sample, tau = tau_sample))\n}\n\nset.seed(12345)\nsample_m &lt;- gibbs_normal(howell[howell$male == \"men\",]$height, 175, 1/5^2, .01, .01, 10^3)",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#gamma-poisson-and-estimating-counts",
    "href": "03-bayesian-statistics.html#gamma-poisson-and-estimating-counts",
    "title": "3  Bayesian Statistics",
    "section": "3.4 Gamma Poisson and Estimating Counts",
    "text": "3.4 Gamma Poisson and Estimating Counts\nThe gamma and Poisson distributions are used to model count data. Consider the following counts of weekday sandwich sales. What is the expected value of sales?\n\ny &lt;- c(50, 65, 72, 63, 70)\n\nCount data have a Poisson distribution, \\(y_i|\\lambda \\sim Pois(\\lambda)\\), with expected value \\(\\lambda\\) and PMF \\(f(y_i | \\lambda) = e^{-\\lambda}\\frac{\\lambda^{y_i}}{y_i!}\\). Using Bayes’ Theorem, the posterior distribution of \\(\\lambda\\) given evidence \\(\\textbf{y}\\) is the joint likelihood of \\(\\lambda\\) and \\(\\textbf{y}\\) divided by the likelihood of \\(\\textbf{y}\\).\n\\[\nf(\\lambda |\\textbf{y}) = \\frac{f(\\mathbf{y}|\\lambda) f(\\lambda)}{\\int_\\Lambda f(\\mathbf{y}|\\lambda) f(\\lambda) d\\lambda}\n\\]\nThe conditional likelihood, \\(f(\\textbf{y}|\\lambda)\\), is the sum-product of the Poisson distribution PMF.\n\\[\n\\begin{align}\nf(\\textbf{y}|\\lambda) = f(y_i,\\ldots, y_n | \\lambda) &= \\prod_i f(y_i | \\lambda) \\\\\n&= \\prod_i e^{-\\lambda}\\frac{\\lambda^{y_i}}{y_i!}\n\\end{align}\n\\]\nThe prior distribution, \\(f(\\lambda)\\), should take on only positive values. Model it with the gamma distribution, \\(\\lambda|a,b = \\mathrm{Gamma}(a,b)\\).\n\\[\nf(\\lambda) = f(\\lambda | a,b) = \\frac{b^a \\lambda^{a-1} e^{-b\\lambda}}{\\Gamma(a)}\n\\]\nwhere \\(\\Gamma\\) is the gamma function3. Substituting into Bayes’ Theorem and simplifying, you have this nightmare:\n\\[\nf(\\lambda |\\textbf{y}) = \\frac{\\lambda^{a + \\sum_i y_i-1}e^{-(b+n)\\lambda}}{\\int_0^\\infty \\lambda^{a + \\sum_i y_i-1}e^{-(b+n)\\lambda} d\\lambda}\n\\]\nHowever, there is good news. The integration in the denominator removes the dependence on \\(\\lambda\\), so \\(f(\\lambda |\\textbf{y}, a, b)\\) is proportional to the numerator up to a constant.\n\\[\nf(\\lambda |\\textbf{y}) \\propto f(\\textbf{y} | \\lambda) f(\\lambda)\n\\]\nSince \\(f(\\lambda |\\textbf{y})\\) is a PMF, it integrates (sums) to 1 and you can always figure out the constant later. What makes this good news is that this has the form of the PDF of the gamma distribution.\n\\[\n\\begin{equation}\n\\lambda | \\textbf{y}, a, b \\sim \\mathrm{Gamma}(a + \\sum_i y_i, b + n)\n(\\#eq:gamma-posterior)\n\\end{equation}\n\\]\nEquation @ref(eq:gamma-posterior) is the posterior distribution of \\(\\lambda\\). We combined a gamma prior with the Poisson likelihood of evidence, \\(\\textbf{y}\\), to produce a gamma posterior. We call priors that produce posteriors of the same form, conjugate priors for the likelihood. Conjugate priors are popular because of their computational convenience.\nReturn to the sandwich sales data. We need values to plug into Equation @ref(eq:gamma-posterior). For the gamma distribution, \\(E(X) = a / b\\) and \\(\\mathrm{Var}(X) = a / b^2\\). You might guess from intuition that mean daily sandwich sales are 70 +/- 5. Interpreting +/- 5 as a 95% CI and using the rule of thumb that a 95% CI is 2 SD, \\(\\mathrm{Var} = (2.5)^2 = 6.25\\). Solve for \\(a = 784\\) and \\(b = 11.2\\). We also have \\(\\sum_i y_i = 320\\) and \\(n = 5\\).\n\\[\n\\lambda | \\textbf{y}, a, b \\sim \\mathrm{Gamma}(784 + 320, 11.2 + 5) \\sim \\mathrm{Gamma}(1104, 16.2)\n\\]\nThe posterior \\(E(y) = 1104 / 16.2 = 68.1\\) and \\(\\mathrm{Var}(y) = 1104 / 16.2^2 = 4.2\\). Use the gamma distribution function to get the posterior 95% credible interval.\n\n# Prior distribution\nqgamma(p = c(.025, .975), 784, 11.2)\n## [1] 65.18520 74.98392\n\n# Posterior distribution\nqgamma(p = c(.025, .975), 784 + 320, 11.2 + 5)\n## [1] 64.18701 72.22621\n\nWhereas the prior expected mean daily sandwich sales was 70 (95% CI: 65, 75), the posterior is 68 (95% CI: 64, 72). Compare this to classical statistics: \\(E(y) = \\bar{y} = 64\\), \\(SE = \\sqrt{\\bar{y} / n} = 3.6\\):\n\n# Classical estimate\nqnorm(p = c(.025, .975), 64, 3.6)\n## [1] 56.94413 71.05587\n\nYou might think that the reasonable Bayesian outcome was predicated on good \\(a\\) and \\(b\\) priors, but no. Suppose \\(a = .01\\) and \\(b = .01\\). The posterior is still reasonable.\n\n# Informal prior\nqgamma(p = c(.025, .975), .01 + 320, .01 + 5)\n## [1] 57.06689 71.05964\n\n\ntibble(\n  lambda = seq(0, 80, .1),\n  `Gamma(.01, .01)` = dgamma(lambda, .01, .01),\n  `Gamma(.01 + 320, .01 + 5)` = dgamma(lambda, .01 + 320, .01 + 5),\n  `Gamma(784, 11.2)` = dgamma(lambda, 784, 11.2),\n  `Gamma(784 + 320, 11.2 + 5)` = dgamma(lambda, 784 + 320, 11.2 + 5)\n) %&gt;%\n  pivot_longer(-lambda) %&gt;%\n  mutate(name = fct_inorder(name)) %&gt;%\n  mutate(prior = if_else(str_detect(name, \"\\\\+\"), \"posterior\", \"prior\")) %&gt;%\n  ggplot(aes(x = lambda, y = value, color = name, linetype = prior)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(rep(\"seagreen\", 2), rep(\"firebrick\", 2))) +\n  labs(color = NULL, linetype = NULL, y = \"density\",\n       title = \"Posteriors from Conservative and Informed Priors.\")\n\n\n\n\n\n\n\n\nThe Bayesian posterior approaches the classical \\(\\bar{y}\\) with increasing sample size.\n\\[\nE(\\lambda|\\textbf{y}, a, b) = \\frac{a + \\sum_i y_i}{b + n} = \\frac{a + n \\bar{y}}{b + n}\n\\]\nTaking the limit, \\(\\lim_{n \\rightarrow \\infty} E(\\lambda|\\textbf{y}, a, b) = \\bar{y}\\).\nThe central credible interval is the standard Bayesian credible interval. But when the posterior distribution is not perfectly symmetric, the shortest credible interval capturing x% of the distribution might have different endpoints. Our example has a pretty symmetric distribution, but let’s calculate the highest density region (HDR) anyway.\n\npp &lt;- seq(0.01, .99, by = .0001)\nx &lt;- map_dbl(pp, ~qgamma(., 784 + 320, 11.2 + 5))\nhdrcde::hdr(x, prob = 95)$hdr\n##         [,1]     [,2]\n## 95% 64.40786 71.86587\n\nThe posterior predictive distribution of a predicted value, \\(\\tilde{y}\\) is\n\\[\nf(\\tilde{y} | x) = \\int f(\\tilde{y}|\\lambda) f(\\lambda | \\textbf{y}) d\\lambda\n\\]\nOur sandwich example has a well defined functional solution: the expected value from \\(\\mathrm{Gamma}(1104, 16.2)\\) is \\(1104/16.2 = 68\\). Had we not known this, we could have simulated posterior values (Monte Carlo simulation) and calculated the mean and variance. The procedure is to take a random sample of perhaps 1,000 \\(\\lambda\\) values from the gamma posterior distribution, then for each \\(\\lambda\\) draw a single random \\(\\tilde{y}\\) from the Poisson distribution.\n\na &lt;- 1104 \nb &lt;- 16.2 \n\nset.seed(1234)\n\n# random sample of lambdas, and a single random y_tilde for each lambda\nlambda_r &lt;- rgamma(1000, a, b)\ny_tilde &lt;- rpois(1000, lambda_r)\n\n# posterior predictive distribution\nmean(y_tilde)\n## [1] 68.252\nquantile(y_tilde, c(.025, .975))\n##   2.5%  97.5% \n## 50.975 85.000\n\nSo on any given day, the predicted value of sandwich sales is 68.3 with 95% prediction interval 51.0, 85.0. The probability of exceeding 80 sandwiches, \\(P(\\tilde{y} &gt; 80 | \\textbf{y})\\), is mean(y_tilde &gt; 80) = 8.3%, and 99% of the time, sandwich sales will be less than quantile(y_tilde, .99) = 89.\nYou can also predict individual weekdays. Suppose you take a \\(\\mathrm{Gamma}(700, 10)\\) distribution as your prior.\n\nday_tbl &lt;- tibble(\n  dow = fct_inorder(c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\")),\n  d = c(50, 65, 72, 63, 70)\n) %&gt;%\n  mutate(\n    post_a = 700 + d,\n    post_b = 10 + 1,\n    post_mean = post_a / post_b,\n    post_lci = qgamma(.025, post_a, post_b),\n    post_uci = qgamma(.975, post_a, post_b)\n  )\n\nday_tbl\n\n# A tibble: 5 × 7\n  dow       d post_a post_b post_mean post_lci post_uci\n  &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Mon      50    750     11      68.2     63.4     73.1\n2 Tue      65    765     11      69.5     64.7     74.6\n3 Wed      72    772     11      70.2     65.3     75.2\n4 Thu      63    763     11      69.4     64.5     74.4\n5 Fri      70    770     11      70       65.1     75.0\n\n\nWhat is the probability that Mon sales are less than Tue?\n\nset.seed(123)\nlambda_r_mon &lt;- rgamma(1000, 750, 11)\nlambda_r_tue &lt;- rgamma(1000, 765, 11)\n\n# posterior probability \nmean(lambda_r_mon &lt; lambda_r_tue)\n## [1] 0.664\n\nWhich day of the week has the highest sandwich sales?\n\nset.seed(12345)\n\nlambda_r &lt;- tibble(\n  r_mon = rgamma(1000, 750, 11),\n  r_tue = rgamma(1000, 765, 11),\n  r_wed = rgamma(1000, 772, 11),\n  r_thu = rgamma(1000, 763, 11),\n  r_fri = rgamma(1000, 770, 11),\n  r_dow = pmap(list(r_mon, r_tue, r_wed, r_thu, r_fri), \n                   function(m, t, w, r, f) c(m, t, w, r, f)),\n  max_dow_idx = map_dbl(r_dow, ~which.max(.)),\n  max_dow = map_chr(max_dow_idx, ~c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\")[.])\n)\n\nlambda_r %&gt;% janitor::tabyl(max_dow)\n##  max_dow   n percent\n##      Fri 248   0.248\n##      Mon  77   0.077\n##      Thu 188   0.188\n##      Tue 190   0.190\n##      Wed 297   0.297\n\nUse the Deviance Information Criterion (DIC) to evaluate whether the day means differ from each other.\n\\[\nDIC = p_D + \\overline{D(\\theta)}\n\\]\nwhere \\(p_D = \\overline{D(\\theta)} - D(\\hat{\\theta})\\) and \\(D(\\theta) = -2 \\log (f(y|\\theta)) + C\\).\nEvaluate \\(\\overline{D(\\theta)}\\) by producing samples from each distribution and evaluating the likelihoods of the data based on each realization and taking the mean of -2 log-likelihood.\n\n# Reset the example. Sandwich counts by dow.\ny &lt;- c(50, 65, 72, 63, 70)\n\n# Priors\na &lt;- .01\nb &lt;- .01\n\n# Posteriors\npost &lt;- list(\n  rgamma(10^3, a+y[1], b+length(y[1])),\n  rgamma(10^3, a+y[2], b+length(y[2])),\n  rgamma(10^3, a+y[3], b+length(y[3])),\n  rgamma(10^3, a+y[4], b+length(y[4])),\n  rgamma(10^3, a+y[5], b+length(y[5]))\n)\n\n# -2 * Mean log-likelihood\nll &lt;- \n  dpois(y[1], post[[1]], log = TRUE) +\n  dpois(y[2], post[[2]], log = TRUE) +\n  dpois(y[3], post[[3]], log = TRUE) +\n  dpois(y[4], post[[4]], log = TRUE) +\n  dpois(y[5], post[[5]], log = TRUE)\n(mean_D &lt;- mean(-2 * ll))\n\n[1] 34.89608\n\n# D(theta-bar) is the likelihood of the data based on the posterior means of p.\n(D_mean &lt;- -2 * (\n  dpois(y[1], (a+y[1]) / (b+length(y[1])), log = TRUE) +\n  dpois(y[2], (a+y[2]) / (b+length(y[2])), log = TRUE) +\n  dpois(y[3], (a+y[3]) / (b+length(y[3])), log = TRUE) +\n  dpois(y[4], (a+y[4]) / (b+length(y[4])), log = TRUE) +\n  dpois(y[5], (a+y[5]) / (b+length(y[5])), log = TRUE) \n))\n\n[1] 29.98793\n\n#p_D and DIC from equation\n(p_D &lt;- mean_D - D_mean)\n\n[1] 4.908155\n\n(DIC &lt;- p_D + mean_D)\n\n[1] 39.80424\n\n# Repeat these steps for a single model of all groups\npost_group &lt;- rgamma(10^3, a+sum(y), b+length(y))\nll_group &lt;- \n  dpois(y[1], post_group, log = TRUE) +\n  dpois(y[2], post_group, log = TRUE) +\n  dpois(y[3], post_group, log = TRUE) +\n  dpois(y[4], post_group, log = TRUE) +\n  dpois(y[5], post_group, log = TRUE)\n(mean_D_group &lt;- mean(-2 * ll_group))\n\n[1] 35.87018\n\n(D_mean_group &lt;- -2 * (\n  dpois(y[1], (a+sum(y)) / (b+length(y)), log = TRUE) +\n  dpois(y[2], (a+sum(y)) / (b+length(y)), log = TRUE) +\n  dpois(y[3], (a+sum(y)) / (b+length(y)), log = TRUE) +\n  dpois(y[4], (a+sum(y)) / (b+length(y)), log = TRUE) +\n  dpois(y[5], (a+sum(y)) / (b+length(y)), log = TRUE)\n))\n\n[1] 34.81027\n\n(p_D_group &lt;- mean_D_group - D_mean_group)\n\n[1] 1.059915\n\n(DIC_group &lt;- p_D_group + mean_D_group)\n\n[1] 36.9301\n\n\nThe DIC for the weekday specific model is 39.8042369 and for the one common group model it is 36.9300995. The DIC for one common group model is smaller, so we do not have enough statistical evidence for two groups.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#normal-and-estimating-means",
    "href": "03-bayesian-statistics.html#normal-and-estimating-means",
    "title": "3  Bayesian Statistics",
    "section": "3.5 Normal and Estimating Means",
    "text": "3.5 Normal and Estimating Means\n\n3.5.1 Population Estimate\nSuppose you have a sample, \\(\\textbf{y}\\), from a normally distribution population of unknown mean and precision, \\(\\mu\\) and \\(\\tau\\): \\(y_i|\\mu, \\tau \\sim N(\\mu, \\tau)\\).4 Assume a normal prior for \\(\\mu \\sim N(\\mu_0, \\tau_0)\\), and a gamma prior for \\(\\tau \\sim \\text{Gamma}(a, b)\\) since it takes only positive values. The PDF for \\(y_i\\) is \\(f(y_i | \\mu, \\tau) = \\frac{\\tau^{.5}}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\tau}{2} (y_i - \\mu)^2 \\right)\\). We’ll derive posterior distributions for \\(\\mu\\) and \\(\\tau\\) separately.\nUsing Bayes’ Theorem, the posterior distribution of \\(\\mu|y\\) is the joint likelihood of \\(y\\) and \\(\\mu\\) divided by the likelihood of \\(y\\),\n\\[\nf(\\mu|y) = \\frac{f(y|\\mu)f(\\mu)}{\\int_\\mu f(y|\\mu)f(\\mu)d\\mu}\n\\]\nThe conditional likelihood, \\(f(\\mu|y)\\), is the sum-product of the normal distribution PDF. We can take \\(\\tau\\) as given initially.\n\\[\n\\begin{align}\nf(y|\\mu) &= \\prod_i \\frac{\\tau^{(1/2)}}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\tau}{2} (y_i - \\mu)^2 \\right) \\\\\n&\\propto \\prod_i \\exp\\left(-\\frac{\\tau}{2} (y_i - \\mu)^2 \\right) \\\\\n&\\propto \\exp \\left( -\\frac{\\tau}{2} \\sum_i(y_i - \\mu)^2 \\right)\n\\end{align}\n\\]\nThe prior PDF for \\(\\mu\\) is the normal distribution. Again we take \\(\\tau\\) as given initially.\n\\[\n\\begin{align}\nf(\\mu) &= \\frac{\\tau_0^{1/2}}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\tau_0}{2} (\\mu - \\mu_0)^2 \\right) \\\\\n&\\propto \\exp\\left(-\\frac{\\tau_0}{2} (\\mu - \\mu_0)^2 \\right)  \n\\end{align}\n\\]\nSubstitute into Bayes’ Theorem. Since we are working with proportions, we can throw out the denominator and say \\(f(\\mu|y) \\propto f(y|\\mu)f(\\mu)\\). Plugging in and solving, we get\n\\[\n\\begin{equation}\n\\mu|y \\sim N\\left(\\frac{n\\tau\\bar{y} + \\tau_0\\mu_0}{n\\tau + \\tau_0}, n\\tau + \\tau_0 \\right)\n(\\#eq:mu-posterior)\n\\end{equation}\n\\]\nUsing Bayes’ Theorem, the posterior distribution of \\(\\tau|y\\) is the joint likelihood of \\(y\\) and \\(\\tau\\) divided by the likelihood of \\(y\\),\n\\[\nf(\\tau|y) = \\frac{f(y|\\tau)f(\\tau)}{\\int_\\tau f(y|\\mu)f(\\tau)d\\tau}\n\\]\nThe conditional likelihood, \\(f(\\tau|y)\\), is the sum-product of the gamma distribution PDF. This time we take \\(\\mu\\) as given.\n\\[\n\\begin{align}\nf(y|\\tau) &= \\prod_i \\frac{\\tau^{(1/2)}}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\tau}{2} (y_i - \\mu)^2 \\right) \\\\\n&= \\frac{\\tau^{n/2}}{(2\\pi)^{n/2}} \\exp\\left(-\\frac{\\tau}{2} \\sum_i (y_i - \\mu)^2 \\right) \\\\\n&\\propto \\tau^{n/2} \\exp \\left( -\\frac{\\tau}{2} \\sum_i(y_i - \\mu)^2 \\right)\n\\end{align}\n\\]\nThe prior PDF for \\(\\tau\\) is the gamma distribution. Pull the constant out to work with proportionality.\n\\[\n\\begin{align}\nf(\\tau) &= \\frac{b^a \\tau^{a-1} e^{-b\\tau}}{\\Gamma(a)} \\\\\n&\\propto \\tau^{a-1}e^{-b\\tau}\n\\end{align}\n\\]\nSubstitute into Bayes’ Theorem. Since we are working with proportions, we can throw out the denominator and say \\(f(\\tau|y) \\propto f(y|\\tau)f(\\tau)\\). Plugging in and solving, we get\n\\[\n\\begin{equation}\n\\tau|y \\sim \\text{Gamma}\\left(a + n/2, b + \\frac{1}{2} \\sum_i(y_i - \\mu)^2 \\right)\n(\\#eq:tau-posterior)\n\\end{equation}\n\\]\nWe have \\(y_i|\\mu,\\tau \\sim N(\\mu,\\tau)\\) with conjugate priors \\(\\mu \\sim N(\\mu_0, \\tau_0)\\) and \\(\\tau \\sim \\text{Gamma}(a,b)\\) and conditional posterior distributions shown in Eqns @ref(eq:mu-posterior) and @ref(eq:tau-posterior). Returning to Eqn @ref(eq:mu-posterior), you can see how \\(E[\\mu] \\rightarrow \\bar{y}\\) as the sample size grows. Below, the terms divided by \\(n\\) disappear, leaving just \\(\\bar{y}\\).\n\\[\n\\begin{align}\nE[\\mu|\\tau, y] &= \\frac{n\\tau\\bar{y} + \\tau_0\\mu_0}{n\\tau + \\tau_0} \\\\\n&= \\frac{\\bar{y}\\tau + \\mu_0\\tau_0/n}{\\tau + \\tau_0/n} \\\\\n&\\sim \\bar{y}\n\\end{align}\n\\]\nThe posterior mean estimator of \\(\\tau\\) is the ratio of the posterior gamma distribution parameters. Again, as the sample size increases, terms divided by \\(n\\) disappear.\n\\[\n\\begin{align}\nE[\\tau|\\mu,y] &= \\frac{a + n/2}{b + \\frac{1}{2} \\sum_i(y_i - \\mu)^2} \\\\\n&= \\frac{2a/n + 1}{2b/n + \\sum_i(y_i - \\mu)^2 / n} \\\\\n&\\sim \\frac{1}{\\sum_i(y_i - \\mu)^2}\n\\end{align}\n\\]\nThe problem here is that you never know \\(\\mu\\) or \\(\\tau\\), so you cannot use the posterior formulas directly. Instead, you need to use sampling. In particular, you use the Gibbs sampler. Set \\(\\mu\\) and \\(\\tau\\) to some initial values and use the posterior equations to estimate new values for \\(\\mu\\) and \\(\\tau\\), then repeat. This is called Markov Chain Monte Carlo (MCMC) simulation because you are chaining the simulations. The method of sampling from a conditional posterior is called the Gibbs sampler.\nLet’s apply this using anthropological data collected by Nancy Howell of human height.\n\n# downloaded this from \n# https://github.com/rmcelreath/rethinking/blob/master/data/Howell1.csv\nhowell &lt;- read_delim(\"input/Howell1.csv\", delim = \";\", show_col_types = FALSE) %&gt;%\n  filter(age &gt;= 18) %&gt;%\n  mutate(male = factor(male, labels = c(\"women\", \"men\")))\n\nhowell %&gt;%\n  ggplot(aes(sample = height, color = male)) +\n  stat_qq() +\n  geom_qq_line()\n\n\n\n\n\n\n\n\nFrom prior knowledge, we know average human height is about \\(175 \\pm 10\\) cm. Using the \\(\\pm\\) = 2SD, the variance \\(5^2\\). Use vague priors of \\(\\mu \\sim N(\\mu_0 = 175, \\tau_0 = 1/5^2)\\) and \\(\\tau = \\sim \\text{Gamma}(a = .01, b = .01)\\). Start by assigning starting values, \\(\\mu*\\) and \\(\\tau*\\)). Given \\(\\tau = \\tau*\\), sample a new value of \\(\\mu*\\) from the normal distribution. Given \\(\\mu = \\mu*\\), sample a new value of \\(\\tau*\\) from the gamma distribution. Then repeat.\n\ngibbs_normal &lt;- function(y, mu_0, tau_0, a, b, n_iter){\n  n &lt;- length(y)\n  y_mean &lt;- mean(y)\n  \n  mu_sample &lt;- tau_sample &lt;- numeric(n_iter)\n  \n  # starting values\n  mu_sample[1] &lt;- mean(y)\n  tau_sample[1] &lt;- 1 / var(y)\n\n  # Gibbs sampler\n  for(i in 2:n_iter){\n    # mu\n    tau &lt;- tau_sample[i-1]\n    mean_mu &lt;- (n * y_mean * tau + mu_0 * tau_0) / (n * tau + tau_0)\n    precision_mu &lt;- n * tau + tau_0\n    mu_sample[i] &lt;- rnorm(1, mean_mu, 1 / sqrt(precision_mu))\n    # tau\n    mu &lt;- mu_sample[i-1]\n    tau_sample[i] &lt;- rgamma(1, a + n/2, b + .5 * sum((y - mu)^2))\n  }\n  \n  return(list(mu = mu_sample, tau = tau_sample))\n}\n\nset.seed(12345)\nsample_m &lt;- gibbs_normal(howell[howell$male == \"men\",]$height, 175, 1/5^2, .01, .01, 10^3)\nsample_w &lt;- gibbs_normal(howell[howell$male == \"women\",]$height, 175, 1/5^2, .01, .01, 10^3)\n\n# posterior mu\nmean(sample_m$mu); quantile(sample_m$mu, c(.025, .975))\n## [1] 160.5146\n##     2.5%    97.5% \n## 159.6103 161.4231\nmean(sample_w$mu); quantile(sample_w$mu, c(.025, .975))\n## [1] 149.6363\n##     2.5%    97.5% \n## 148.9256 150.3641\n\n# posterior probability that men are taller than women on average\nmean(sample_m$mu &gt; sample_w$mu)\n## [1] 1\n\n# posterior probability that a random man is taller than a random woman\ntilde_m &lt;- rnorm(10^3, mean(sample_m$mu), sqrt(1/mean(sample_m$tau)))\ntilde_w &lt;- rnorm(10^3, mean(sample_w$mu), sqrt(1/mean(sample_w$tau)))\nmean(tilde_m &gt; tilde_w)\n## [1] 0.909\n\ntibble(\n  iter = rep(1:10^3, 2),\n  sex = c(rep(\"men\", 10^3), rep(\"women\", 10^3)),\n  mu = c(sample_m$mu, sample_w$mu),\n  tau = c(sample_m$tau, sample_w$tau),\n) %&gt;%\n  pivot_longer(cols = c(mu, tau)) %&gt;% \n  ggplot(aes(x = value, color = sex)) + \n  geom_density() + \n  facet_wrap(facets = vars(name), scales = \"free\") +\n  labs(title = \"Posterior Distributions\", x = NULL, color = NULL)\n\n\n\n\n\n\n\n\ntibble(\n  iter = rep(1:10^3, 2),\n  sex = c(rep(\"men\", 10^3), rep(\"women\", 10^3)),\n  tilde = c(tilde_m, tilde_w)\n) %&gt;%\n  ggplot(aes(x = tilde, color = sex)) + \n  geom_density() + \n  labs(title = \"Posterior Predictive Distributions\", x = NULL, color = NULL)\n\n\n\n\n\n\n\n\nIt may take some time to converge on a solution. This convergence is called burn-in and is often discarded when describing the posterior. Slow mixing may occur if there is high autocorrelation in the Gibbs sample, resulting in slow exploration of the sample space of the posterior.\n\n\n3.5.2 Regression\nThe linear model in Bayesian statistics is\nLikelihood:\n\\[\ny_i | \\mu_i, \\tau \\sim N(\\mu_i, \\tau)\n\\]\nwhere\n\\[\n\\mu_i | x_i, \\beta_0, \\beta_1 = \\beta_0 + \\beta_1 x\n\\]\nPriors:\n\\[\n\\begin{align}\n\\beta_0 & \\sim N(0, 10^{-8}) \\\\\n\\beta_1 & \\sim N(0, 10^{-8}) \\\\\n\\tau & \\sim \\text{Gamma}(.01, .01)\n\\end{align}\n\\]\nReturning to the Howell data, suppose you want to fit a linear model, \\(\\text{Weight}_i = a + b \\text{Height} + \\epsilon_i\\). In Bayesian regression, this is expressed as \\(\\text{Weight} | \\mu_i \\sim N(\\mu_i, \\tau)\\) where \\(\\mu_i = a + b\\text{Height}\\). You can construct a Gibbs sampler to estimate the model, but there is already a package for that, MCMCglmm.\n\nlibrary(MCMCglmm)\n\nset.seed(12345)\n\nmdl_1 &lt;- MCMCglmm(\n  weight ~ height, \n  data = howell,\n  family = \"gaussian\",\n  nitt = 11000, # iterations\n  burnin = 1000, # burn-in period to throw out\n  thin = 10, \n  # could omit this prior since it is non-informative\n  prior = list(B = list(mu = c(0, 0), V = c(100^2, 100^2)*diag(2))),\n  verbose = FALSE\n)\n\nsummary(mdl_1)\n\n\n Iterations = 1001:10991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: 2020.205 \n\n R-structure:  ~units\n\n      post.mean l-95% CI u-95% CI eff.samp\nunits     18.16    15.73    20.81     1000\n\n Location effects: weight ~ height \n\n            post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n(Intercept)  -52.5503 -61.9377 -44.0584   1000.0 &lt;0.001 ***\nheight         0.6309   0.5717   0.6874    912.8 &lt;0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Probability beta is &gt;0\nmean(mdl_1$Sol[, 2] &gt; 0)\n\n[1] 1\n\n# Posterior inference.\nnew_data &lt;- tibble(height = seq(130, 185, .1), weight = 0)\n\ncred_intvl &lt;- predict(mdl_1, newdata = , type = \"response\", interval = \"confidence\")\n\npred_intvl &lt;- predict(mdl_1, newdata = , type = \"response\", interval = \"prediction\")\n\nhowell %&gt;% \n  bind_cols(cred_intvl, pred_intvl, .name_repair = \"unique\") %&gt;% \n  ggplot(aes(x = height)) +\n  geom_ribbon(aes(ymin = `lwr...9`, ymax = `upr...10`), fill = \"lightgoldenrod\", alpha = .5) +\n  geom_ribbon(aes(ymin = `lwr...6`, ymax = `upr...7`), fill = \"goldenrod\", alpha = .5) +\n  geom_line(aes(y = `fit...5`), color = \"goldenrod\", linewidth = 1) +\n  geom_point(aes(y = weight)) +\n  labs(y = \"weight\", title = \"95% CI and PI.\")\n\n\n\n\n\n\n\n\nYou can extend this to multivariate models.\n\nset.seed(12345)\n\nmdl_2 &lt;- MCMCglmm(\n  weight ~ height*male, \n  data = howell,\n  family = \"gaussian\",\n  nitt = 11000, # iterations\n  burnin = 1000, # burn-in period to throw out\n  thin = 10, \n  #prior = list(B = list(mu = c(0, 0), V = c(100^2, 100^2)*diag(2))), \n  verbose = FALSE\n)\n\nBayesian statistics has its analog to Akaike’s Information Criterion (AIC) called Deviance Information Criterion (DIC).\n\\[\nDIC = p_D + \\overline{D(\\theta)}\n\\]\nwhere \\(p_D = \\overline{D(\\theta)} - D(\\hat{\\theta})\\) and \\(D(\\theta) = -2 \\log (f(y|\\theta)) + C\\). The value of DIC has no real meaning, but for comparison purposes, lower is better. A difference of at least 3 is considered sufficient evidence to choose one model over another. Here, mdl_1$DIC = 2020.2047497 and mdl_2$DIC = 2023.9678623. The first model is better, so conclude that there is no statistical evidence that the correlation between weight and height depends on sex (\\(\\Delta\\)DIC = 3.7631126).\n\nmdl_3 &lt;- MCMCglmm(\n  weight ~ age, \n  data = howell,\n  family = \"gaussian\",\n  nitt = 11000, # iterations\n  burnin = 1000, # burn-in period to throw out\n  thin = 10, \n  #prior = list(B = list(mu = c(0, 0), V = c(100^2, 100^2)*diag(2))), \n  verbose = FALSE\n)\nsummary(mdl_3)\n\n\n Iterations = 1001:10991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: 2306.323 \n\n R-structure:  ~units\n\n      post.mean l-95% CI u-95% CI eff.samp\nunits     40.94    35.44    47.38     1000\n\n Location effects: weight ~ age \n\n            post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n(Intercept)  47.85552 46.15454 49.74972     1000 &lt;0.001 ***\nage          -0.06938 -0.10614 -0.02511     1000 &lt;0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmdl_1$DIC\n\n[1] 2020.205\n\nmdl_3$DIC\n\n[1] 2306.323\n\n\n\n\n3.5.3 Generalized Linear Models\nThe generalized linear model in Bayesian statistics is\nLikelihood:\n\\[\ny_i | \\mu_i, \\tau \\sim D(\\mu_i)\n\\]\nwhere\n\\[\ng(\\mu_i | x_i, \\beta_0, \\beta_1) = \\beta_0 + \\beta_1 x\n\\]\nPriors:\n\\[\n\\begin{align}\n\\beta_0 & \\sim N(0, 10^{-8}) \\\\\n\\beta_1 & \\sim N(0, 10^{-8}) \\\\\n\\end{align}\n\\]\nConsider a binary response \\(y_i\\). You would typically model this with logistic regression:\n\\(y_i | p_i \\sim \\text{BIN}(1, p_i)\\) where \\(\\log \\left( \\frac{p_i}{1 - p_i} \\right) = \\beta_0 + \\beta_1 x_i\\). In bivariate statistics, if \\(x_i\\) perfectly predicts \\(y_i\\), separation of variables has occurred. Here’s an example of separation of variables. In the regression, the standard errors are huge, so the p.value is nearly 1. The classical regression framework has broken down.\n\nstudy &lt;- read_csv(\"input/hours_of_study_data.csv\", col_types = \"dc\") %&gt;%\n  mutate(y = factor(y)) %&gt;%\n  as.data.frame()\n\nstudy %&gt;% ggplot(aes(x = HoursOfStudy, y = y)) + geom_point()\n\n\n\n\n\n\n\n\nsummary(\n  glm(y ~ HoursOfStudy, data = study, family = \"binomial\")\n)\n## \n## Call:\n## glm(formula = y ~ HoursOfStudy, family = \"binomial\", data = study)\n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(&gt;|z|)\n## (Intercept)   -1303.9   442563.5  -0.003    0.998\n## HoursOfStudy     13.1     4448.4   0.003    0.998\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 6.8029e+01  on 49  degrees of freedom\n## Residual deviance: 1.6529e-08  on 48  degrees of freedom\n## AIC: 4\n## \n## Number of Fisher Scoring iterations: 25\n\nThe Bayesian framework performs better.\n\nset.seed(12345)\n\nsummary(\n m.bayes &lt;- MCMCglmm(y ~ HoursOfStudy, data = study, family = \"categorical\", verbose = FALSE)\n)\n\n\n Iterations = 3001:12991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: 2.652789 \n\n R-structure:  ~units\n\n      post.mean l-95% CI u-95% CI eff.samp\nunits     9.636 0.008661    44.84    24.55\n\n Location effects: y ~ HoursOfStudy \n\n             post.mean  l-95% CI  u-95% CI eff.samp  pMCMC    \n(Intercept)  -189.9191 -289.2550  -66.7212    1.966 &lt;0.001 ***\nHoursOfStudy    1.9036    0.6402    2.8894    1.889 &lt;0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEach hour of study is associated with an \\(\\exp (1.9036) \\sim 6.7\\)-fold increase in the odds of passing. The posterior probability that the association is positive is\n\nmean(m.bayes$Sol[, 2] &gt; 0)\n\n[1] 1\n\n\nLet’s try another example.\n\nchase &lt;- read_csv(\"input/TheChase.txt\", show_col_types = FALSE)\n\n# focus on Mark\nmark &lt;- chase %&gt;% filter(Chaser == \"Mark\")\n\nmark %&gt;% ggplot(aes(x = TeamScore, y = Win)) + geom_jitter(width = 0)\n\n\n\n\n\n\n\n\nNotice: most scores are between 10 and 25, winning is less common than losing, and winning is more common with higher scores. Fit the following model: \\(y_i \\sim \\text{Bin}(1, p_i)\\) where \\(\\text{logit}(p_i) = \\beta_0 + \\beta_1 x_i\\) and \\(x_i\\) is the mean score of game \\(i\\). Assume non-informative normal priors: \\(\\beta_0 \\sim N(0, 10^{-8})\\) and \\(\\beta_1 \\sim N(0, 10^{-8})\\).\n\nlibrary(rstanarm)\n\n\n# This will take ~1 min\nm1 &lt;- stan_glm(Win ~ TeamScore, data = mark, \n                 family = binomial(link = \"logit\"), \n                 prior = normal(location=0, scale=10^4),\n                 prior_intercept = normal(location=0, scale=10^4),\n                 chains=1, iter= 1500,\n                 seed = 12345, refresh=0)\n\n\nm1post &lt;- as.data.frame(m1)\npar(mfrow=c(2,2))\nplot(m1post[,1],ty='l',ylab=expression(beta[0]))\nplot(density(m1post[,1]),xlab=expression(beta[0]),main='')\nplot(m1post[,2],ty='l',ylab=expression(beta[1]))\nplot(density(m1post[,2]),xlab=expression(beta[1]),main='')\n\n\n\n\n\n\n\n\nThe traces look converged, and the estimated posterior densities look smooth.\n\ndf.summary &lt;- data.frame(\np.means = round(apply(m1post,2,mean),4),\np.ci.lo = round(apply(m1post,2,quantile,.025),4),\np.ci.hi = round(apply(m1post,2,quantile,.975),4))\n\nprint(df.summary)\n\n            p.means  p.ci.lo p.ci.hi\n(Intercept) -9.2615 -11.9893 -6.9141\nTeamScore    0.4351   0.3175  0.5711\n\n\nThere is a positive correlation between the Team Score and the odds of winning. Calculate the posterior probability.\n\nmean(m1post[, 2] &gt; 0)\n\n[1] 1\n\n\nCompare this to the classical result. They are pretty close.\n\nsummary(\n  m1c &lt;- glm(Win ~ TeamScore, data = mark, family = \"binomial\")\n)\n\n\nCall:\nglm(formula = Win ~ TeamScore, family = \"binomial\", data = mark)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -8.99425    1.28162  -7.018 2.25e-12 ***\nTeamScore    0.42199    0.06615   6.379 1.78e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 261.45  on 245  degrees of freedom\nResidual deviance: 195.35  on 244  degrees of freedom\nAIC: 199.35\n\nNumber of Fisher Scoring iterations: 5\n\n\nLet’s also plot the estimated model on a grid of possible Team Score values. Recall \\(p = \\frac{1}{1 + e^{-z}}\\),\n\n# setting a grid of values\nTeamScoreGrid &lt;- seq(0:30)\n\n# using posterior samples of beta0 and beta1\n# to produce a posterior sample of probabilities at each value of TeamScoreGrid\n\np.eval &lt;- function(Score,b0,b1){1/(1+exp(-(b0+b1*Score)))}\n\np.sample &lt;- sapply(TeamScoreGrid,p.eval,b0=m1post[,1],b1=m1post[,2])\n\n# evaluating posterior mean probability for each score:\np.post.mean &lt;- apply(p.sample,2,mean)\n\n# evaluating 95% CI for the probability for each score:\np.post.lo &lt;- apply(p.sample,2,quantile,.025)\np.post.hi &lt;- apply(p.sample,2,quantile,.975)\n\ndata.post &lt;- data.frame(TeamScore=TeamScoreGrid, p.mn=p.post.mean,\n                        p.lo=p.post.lo, p.hi=p.post.hi)\n\nggplot(data=mark,aes(x=TeamScore,y=jitter(Win)))+\n  geom_point()+\n  geom_ribbon(data=data.post,aes(x=TeamScore,y=p.mn,ymin=p.lo,ymax=p.hi),alpha=.5,fill='salmon') +\n  geom_line(data=data.post,aes(x=TeamScore,y=p.mn),col='red', linewidth=1.5)+\n  ylab('Outcome')+\n  scale_y_continuous(name='', breaks=c(0,1), labels=c('Lose','Win'),\n                     sec.axis=sec_axis(~., breaks=seq(0,1,.2),\n                                       name='Probability of Winning'))+\n  xlim(c(0,30))\n\n\n\n\n\n\n\ndata.post$TeamScore[which(data.post$ppp &gt;= .80)][1]\n\n[1] NA\n\n\nWhat is the posterior probability that a team score of 25 beats Mark?\n\np.eval(Score = 25, b0 = m1post[,1], b1 = m1post[,2]) %&gt;% mean()\n\n[1] 0.8270518\n\n\nWhat score do you need in order to win with 80% certainty, \\(P(y = 1|x) \\ge .8)\\). For each \\(x\\) on a grid, take the posterior sample for \\(p\\) and generate \\(y = \\text{Bern}(p)\\). Then get \\(prob(y == 1)\\).\n\n# simulating the game outcomes (y)\ny.sample &lt;- (array(runif(prod(dim(p.sample))),dim=dim(p.sample)) &lt; p.sample)*1\n\n# posterior predictive probabilities that y=1\ndata.post$ppp &lt;- apply(y.sample,2,mean)\n\nggplot(data=data.post,aes(x=TeamScore,y=ppp))+\n  geom_line(col='red',size=1.5)+\n  geom_hline(aes(yintercept=0.80),col='blue',size=1.2,lty=2)+\n  geom_vline(aes(xintercept=24),col='brown',size=1.1,lty=2)+\n  geom_vline(aes(xintercept=25),col='brown',size=1.1,lty=2)+\n  ylab('Post. Pred. Prob. of Winning')+\n  xlim(c(0,30))+theme_gray(base_size=18)\n\n\n\n\n\n\n\n\n\n\n3.5.4 Missing Data\nConsider a situation where 20 customers are surveyed to measure satisfaction. You can model this as \\(x_i | p \\sim \\text{Bin}(1, p)\\) where \\(p\\) is the probability of satisfaction. The conjugate prior for \\(p\\) is \\(p \\sim \\text{Beta}(a, b)\\). However, some observations are missing. You can divide the respondents into \\(x_{obs}\\) and \\(x_{miss}\\). Then\n\\[\nf(x|p) = \\prod_i f(x_i|p) = f(x_{obs}|p) f(x_{miss}|p)\n\\]\nWhen missingness is random, you can smiply discard missing observations. So if there were 4 missing responses, and 10 of the 16 completed surveys were satisfied, \\(p|x_{obs} \\sim \\text{Beta}(1 + 10, 1 + 6)\\). The Beta-bimomial conjugate model is\n\\[\n\\begin{align}\nx_i & \\sim \\text{Bin}(1, p) \\\\\np & \\sim \\text{Beta}(a, b)\n\\end{align}\n\\]\nwith posterior \\(p | x \\sim \\text{Beta} \\left( a + \\sum_i x_i, b + \\sum_i (1 - x_i) \\right)\\)\nBut if the data are not missing at random, you need to model the probability of participating. From past experience you might infer that participation rates are 30% for satisfied and 90% for dissatisfied.\n\\[\n\\begin{align}\nP(z_i = 1 | x_i = 1) &= .3 \\\\\nP(z_i = 1 | x_i = 0) &= .9\n\\end{align}\n\\]\nCombining them, you have \\(P(x_i = 1 | z_i = 0, p) = \\frac{7p}{6p + 1}\\). Set up a Gibbs sampler. Step 0: assign random prior values to the missing \\(x\\). Step 1: given \\(x\\), sample \\(p\\) from \\(\\text{Beta}(a + \\sum_i x_i, b + \\sum_i (1 - x_i))\\). Step 2: given \\(p\\), assign the missing \\(x\\) to 1 with probability \\(p|x_{obs} \\sim \\text{Beta}(1 + 10, 1 + 6)\\).\n\n# prior parameters\na &lt;- 1; b &lt;- 1\n# data\nx &lt;- rep(c(1,0,NA),c(10,6,4))\nz &lt;- rep(1:0,c(16,4))\n\n# initial values.\nx.sample &lt;- x; x.sample[is.na(x)] &lt;- sample(0:1,size=4,replace=T)\n\n# number of iterations\nITER &lt;- 10^4+500\n# and the monitor for recording the iterations of p\nmon.p &lt;- numeric(ITER)\n# ... and one of the missing observations\nmon.x20 &lt;- numeric(ITER)\n\n# Gibbs sampler:\n\nfor(iter in 1:ITER){\n  # sampling p\n  mon.p[iter] &lt;- p &lt;- rbeta(1,a+sum(x.sample),b+sum(1-x.sample))\n  # sampling (missing x)\n  x.sample[is.na(x)] &lt;- rbinom(sum(is.na(x)),1,7*p/(6*p+1))\n    mon.x20[iter] &lt;- x.sample[20]\n}\n\n\n# prior parameters\na &lt;- 1; b &lt;- 1\n# data: 40 satisfied, 10 not satisfied, 50 no-responses\nx &lt;- rep(c(1,0,NA),c(40,10,50))\nz &lt;- rep(1:0,c(50,50))\n# what if all 50 were satisfied?\nx &lt;- rep(c(1,0,1),c(40,10,50))\nz &lt;- rep(1:0,c(50,50))\n# what if all 50 were like the other 50?\nx &lt;- rep(c(1,0,1,0),c(40,10,40,10))\nz &lt;- rep(1:0,c(50,50))\n\n# initial values.\nx.sample &lt;- x; x.sample[is.na(x)] &lt;- sample(0:1,size=50,replace=T)\n\n# number of iterations\nITER &lt;- 10^4+500\n# and the monitor for recording the iterations of p\nmon.p &lt;- numeric(ITER)\n# ... and one of the missing observations\nmon.x20 &lt;- numeric(ITER)\n\n# Gibbs sampler:\n\nfor(iter in 1:ITER){\n  # sampling p\n  mon.p[iter] &lt;- p &lt;- rbeta(1,a+sum(x.sample),b+sum(1-x.sample))\n  # sampling (missing x)\n  x.sample[is.na(x)] &lt;- rbinom(sum(is.na(x)),1,7*p/(6*p+1))\n    mon.x20[iter] &lt;- x.sample[20]\n}\n\n# Posterior mean probability of being satisfied.\nmean(mon.p[501:10500])\n\n[1] 0.7947594\n\n# 95% CI\nquantile(mon.p[501:10500], c(.025, .975))\n\n     2.5%     97.5% \n0.7122337 0.8661632 \n\n\n\n\n3.5.5 Change Point Regression\nLet’s try another example. The Nile data set contains Nile flow by year. We want to ask whether the trend changed after 1897. Compare an intercept-only model, \\(y_t \\sim N(\\mu_t, \\tau)\\) where \\(\\mu_t = \\alpha\\) is a constant, to a linear time trend model where \\(\\mu_t = \\alpha + \\beta \\text{Year}\\). Use conjugate non-informative priors, \\(\\alpha \\sim N(0, 10^{-10})\\) and \\(\\tau \\sim \\text{Gamma}(.01, .01)\\).\n\ndata(\"Nile\")\n\nmy_nile &lt;- tibble(year = time(Nile), flow = Nile, after = as.numeric(year&gt;1897))\n\n# intercept-only\nm0 &lt;- MCMCglmm(flow ~ 1, data = my_nile, \n               nitt = 1500, burnin = 500, thin = 1,\n               prior = list(B = list(mu = 0, V = 10^10)),\n               verbose = FALSE)\n\n# Trend\nm1 &lt;- MCMCglmm(flow ~ year, data = my_nile, \n               nitt = 1500, burnin = 500, thin = 1,\n               prior = list(B = list(mu = c(0, 0), V = diag(2)*10^10)),\n               verbose = FALSE)\n\n# flow has been decreasing by 2.7 per year (95% CI, 1.6 - 3.7)\nsummary(m1)$solutions\n##               post.mean    l-95% CI    u-95% CI eff.samp pMCMC\n## (Intercept) 6180.699732 4183.400324 8268.137317     1000 0.001\n## year          -2.739952   -3.865672   -1.741701     1000 0.001\n\n# posterior probability of negative trend\nmean(m1$Sol[, 2] &lt; 0)\n## [1] 1\n\n# Change Point\nm2 &lt;- MCMCglmm(flow ~ after, data = my_nile, \n               nitt = 1500, burnin = 500, thin = 1,\n               prior = list(B = list(mu = c(0, 0), V = diag(2)*10^10)),\n               verbose = FALSE)\n\n# Flow fell 244 from 1098.\nsummary(m2)$solutions\n##             post.mean  l-95% CI  u-95% CI eff.samp pMCMC\n## (Intercept) 1097.3780 1048.3385 1143.4094     1000 0.001\n## after       -243.8701 -300.7758 -193.1304     1000 0.001\n\n# Compare the DIC. m2 has smallest DIC.\nm0$DIC\n## [1] 1313.057\nm1$DIC\n## [1] 1290.783\nm2$DIC\n## [1] 1261.396\n\nThis isn’t quite how you would want to do it, however. Instead, you’d like to determine which year the change point occurred. Define \\(\\mu_t = \\alpha_0\\) for \\(t&lt;t^*\\), and \\(\\alpha_1\\) for \\(t \\ge t^*\\). Use conjugate non-informative priors for both, \\(\\alpha_0 = \\alpha_1 \\sim N(0, 10^{-8})\\) and \\(\\tau \\sim \\text{Gamma}(.01, .01)\\) and a uniform prior for \\(t^* \\sim U(1871.5, 1969.5\\).\nThe posterior conditional distributions for \\(\\alpha_0\\) and \\(\\alpha_1\\) are from Eqns @ref(eq:mu-posterior).\n\\[\n\\begin{align}\n\\alpha_0 | y,t^*,\\tau & \\sim N \\left( \\frac{\\sum_{t&lt;t^*} y_t \\tau}{\\sum_{t&lt;t^*} 1 \\tau + 10^{-8}}, \\sum_{t&lt;t^*} 1 \\tau + 10^{-8} \\right) \\\\\n\\alpha_1 | y,t^*,\\tau & \\sim N \\left( \\frac{\\sum_{t\\ge t^*} y_t \\tau}{\\sum_{t\\ge t^*} 1 \\tau + 10^{-8}}, \\sum_{t\\ge t^*} 1 \\tau + 10^{-8} \\right)\n\\end{align}\n\\]\nThe posterior conditional distribution for \\(\\tau\\) needs to be derived from Bayes’ formula.\n\\[\n\\tau|x, t^*, \\alpha_0, \\alpha_1 \\sim \\text{Gamma} \\left( .01 + \\frac{n}{2}, .01 + .5 \\sum_{t&lt;t^*} (x_t - \\alpha_0)^2 + .5 \\sum_{t \\ge t^*} (x_t - \\alpha_1)^2 \\right)\n\\]\nIt is not possible to derive a posterior conditional distribution for \\(t^*\\), so use the Metropolis-Hastings algorithm. Given \\(\\alpha_0\\), \\(\\alpha_1\\), \\(\\tau\\), and \\(t^*\\), propose a new value from the normal distribution centered at \\(t^*\\): \\(t^{*'} \\sim N(t^*, \\delta)\\) and accept the new value with probability \\(min{1, R}\\),\n\\[\nR = \\frac{f(y|\\alpha_0, \\alpha_1, t^{*'})f(t^{*'})}{f(y|\\alpha_0, \\alpha_1, t^*)} \\frac{q(t^*|t^{*'})}{q(t^{*'}|t^*)}\n\\]\nThe proposal distribution is symmetric, so you can drop the \\(q()\\) functions from the ratio (Metropolis algorithm).\nLet’s start with a toy example to check the code.\n\n# Create toy data set.\nset.seed(12345)\nALPHA_0 &lt;- 0\nALPHA_1 &lt;- 1\nTAU &lt;- 1 / .1^2\nCHGPT &lt;- 25.5\ndat &lt;- tibble(t = 1:100, y = rnorm(100, ALPHA_0 + ALPHA_1*(t&gt;CHGPT), 1 / sqrt(TAU)))\n\n# Quick look at the data. A clear change point!\ndat %&gt;% ggplot(aes(x = t, y = y)) + geom_line()\n\n\n\n\n\n\n\n\n# Set up a 1,500 iteration MCMC\nITER &lt;- 1500\nchgpt_delta &lt;- .5\n\n# Create monitors for each of the posterior distributions\nmon_alpha_0 &lt;- mon_alpha_1 &lt;- mon_tau &lt;- mon_chgpt &lt;- numeric(ITER)\n\n# Set initial values\nn &lt;- nrow(dat)\nalpha_0 &lt;- alpha_1 &lt;- mean(dat$y); tau &lt;- 1 / var(dat$y); chgpt &lt;- median(dat$t)\n\nfor(iter in 1:ITER) {\n  # Gibbs step\n  alpha_0 &lt;- rnorm(1, sum(dat$y[dat$t &lt;  chgpt]) * tau / (sum(dat$t &lt;  chgpt) * tau + 10^(-8)),\n                   1 / sqrt(sum(dat$t &lt;  chgpt) * tau + 10^(-8)))\n  alpha_1 &lt;- rnorm(1, sum(dat$y[dat$t &gt;= chgpt]) * tau / (sum(dat$t &gt;= chgpt) * tau + 10^(-8)),\n                   1 / sqrt(sum(dat$t &gt;= chgpt) * tau + 10^(-8)))\n  tau &lt;- rgamma(1, .01 + n/2, \n                .01 + \n                  .5 * sum(((dat$y - alpha_0)^2)[dat$t &lt;  chgpt]) +\n                  .5 * sum(((dat$y - alpha_1)^2)[dat$t &gt;= chgpt]))\n  # c(alpha_0, alpha_1, tau, chgpt)\n  # Metropolis step\n  chgpt_new &lt;- rnorm(1, chgpt, sd = chgpt_delta)\n  log_R &lt;- # difference in log-likelihoods =\n    # log-likelihood of new\n    (sum(dnorm(dat$y[dat$t &lt;  chgpt_new], alpha_0, 1 / sqrt(tau), log = TRUE)) +\n     sum(dnorm(dat$y[dat$t &gt;= chgpt_new], alpha_1, 1 / sqrt(tau), log = TRUE))) -\n    # log-likelihood of curr\n    (sum(dnorm(dat$y[dat$t &lt;  chgpt],     alpha_0, 1 / sqrt(tau), log = TRUE)) +\n     sum(dnorm(dat$y[dat$t &gt;= chgpt],     alpha_1, 1 / sqrt(tau), log = TRUE))) \n  log_U &lt;- log(runif(1, 0, 1))\n  if(log_U &lt; log_R) { chgpt &lt;- chgpt_new}\n  # update monitors\n  mon_alpha_0[iter] &lt;- alpha_0 \n  mon_alpha_1[iter] &lt;- alpha_1\n  mon_tau[iter] &lt;- tau\n  mon_chgpt[iter] &lt;- chgpt\n}\n# mine &lt;- c(alpha_0, alpha_1, tau, chgpt, chgpt_new, log_R, log_U)\n\n# Check for convergence\nmon_tibble &lt;- tibble(index = 1:ITER, alpha_0 = mon_alpha_0, alpha_1 = mon_alpha_1, \n       tau = mon_tau, chgpt = mon_chgpt) \nmon_tibble_longer &lt;-\n  mon_tibble %&gt;%\n  pivot_longer(cols = -index)\n\nmon_tibble_longer %&gt;% \n  ggplot(aes(x = index, y = value)) + \n  geom_line() + \n  labs(y = NULL) +\n  facet_wrap(facets = vars(name), scales = \"free_y\")\n\n\n\n\n\n\n\n\n# Convergence after 500 iterations, so throw them out.\n# Posterior distributions\nmon_tibble_longer %&gt;% \n  filter(index &gt; 500) %&gt;%\n  mutate(name = if_else(name == \"tau\", \"sigma\", name),\n         value = if_else(name == \"sigma\", 1 / sqrt(value), value)) %&gt;%\n  summarize(\n    .by = name,\n    M = mean(value),\n    SD = sd(value),\n    LCI = quantile(value, .025),\n    UCI = quantile(value, .975)\n  )\n## # A tibble: 4 × 5\n##   name           M      SD     LCI     UCI\n##   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1 alpha_0  0.00100 0.0225  -0.0431  0.0462\n## 2 alpha_1  1.03    0.0125   1.01    1.06  \n## 3 sigma    0.113   0.00822  0.0986  0.130 \n## 4 chgpt   25.5     0.287   25.0    26.0\n\n# You can summarize the values by t to average the models.\n# Recall the model is mu_t = alpha + beta*Year where alpha = alpha_0 or alpha_1\nmon_tibble %&gt;%\n  head(-500) %&gt;%\n  mutate(\n    series = pmap(list(alpha_0, alpha_1, chgpt), function(a0, a1, c) {\n      t &lt;- 1:100\n      y &lt;- if_else(t &lt; c, a0, a1)\n      rs &lt;- tibble(t, y)\n      rs\n    })\n  ) %&gt;%\n  select(series) %&gt;%\n  unnest(series) %&gt;%\n  summarize(.by = t, y = mean(y), lci = quantile(y, .025), uci = quantile(y, .975)) %&gt;%\n  ggplot(aes(x = t)) +\n  geom_line(aes(y = y)) +\n  geom_ribbon(aes(ymin = lci, ymax = uci))\n\n\n\n\n\n\n\n\nNow let’s apply what we’ve learned to the Nile data set. I’ll set the initial change point value at 1900 since that is around where the change seems to have occurred.\n\ndat &lt;- my_nile %&gt;% rename(t = year, y = flow)\n\n# Quick look at the data. A clear change point!\ndat %&gt;% ggplot(aes(x = t, y = y)) + geom_line()\n\n\n\n\n\n\n\n\n# Set up a 1,500 iteration MCMC\nITER &lt;- 1500\nchgpt_delta &lt;- .5\n\n# Create monitors for each of the posterior distributions\nmon_alpha_0 &lt;- mon_alpha_1 &lt;- mon_tau &lt;- mon_chgpt &lt;- numeric(ITER)\n\n# Set initial values\nn &lt;- nrow(dat)\nalpha_0 &lt;- alpha_1 &lt;- mean(dat$y); tau &lt;- 1 / var(dat$y); chgpt &lt;- 1900\n\nfor(iter in 1:ITER) {\n  # Gibbs step\n  alpha_0 &lt;- rnorm(1, sum(dat$y[dat$t &lt;  chgpt]) * tau / (sum(dat$t &lt;  chgpt) * tau + 10^(-8)),\n                   1 / sqrt(sum(dat$t &lt;  chgpt) * tau + 10^(-8)))\n  alpha_1 &lt;- rnorm(1, sum(dat$y[dat$t &gt;= chgpt]) * tau / (sum(dat$t &gt;= chgpt) * tau + 10^(-8)),\n                   1 / sqrt(sum(dat$t &gt;= chgpt) * tau + 10^(-8)))\n  tau &lt;- rgamma(1, .01 + n/2, \n                .01 + \n                  .5 * sum(((dat$y - alpha_0)^2)[dat$t &lt;  chgpt]) +\n                  .5 * sum(((dat$y - alpha_1)^2)[dat$t &gt;= chgpt]))\n  # c(alpha_0, alpha_1, tau, chgpt)\n  # Metropolis step\n  chgpt_new &lt;- rnorm(1, chgpt, sd = chgpt_delta)\n  log_R &lt;- # difference in log-likelihoods =\n    # log-likelihood of new\n    (sum(dnorm(dat$y[dat$t &lt;  chgpt_new], alpha_0, 1 / sqrt(tau), log = TRUE)) +\n     sum(dnorm(dat$y[dat$t &gt;= chgpt_new], alpha_1, 1 / sqrt(tau), log = TRUE))) -\n    # log-likelihood of curr\n    (sum(dnorm(dat$y[dat$t &lt;  chgpt],     alpha_0, 1 / sqrt(tau), log = TRUE)) +\n     sum(dnorm(dat$y[dat$t &gt;= chgpt],     alpha_1, 1 / sqrt(tau), log = TRUE))) \n  log_U &lt;- log(runif(1, 0, 1))\n  if(log_U &lt; log_R) { chgpt &lt;- chgpt_new}\n  # update monitors\n  mon_alpha_0[iter] &lt;- alpha_0 \n  mon_alpha_1[iter] &lt;- alpha_1\n  mon_tau[iter] &lt;- tau\n  mon_chgpt[iter] &lt;- chgpt\n}\n# mine &lt;- c(alpha_0, alpha_1, tau, chgpt, chgpt_new, log_R, log_U)\n\n# Check for convergence\nmon_tibble &lt;- tibble(index = 1:ITER, alpha_0 = mon_alpha_0, alpha_1 = mon_alpha_1, \n       tau = mon_tau, chgpt = mon_chgpt) \nmon_tibble_longer &lt;-\n  mon_tibble %&gt;%\n  pivot_longer(cols = -index)\n\nmon_tibble_longer %&gt;% \n  ggplot(aes(x = index, y = value)) + \n  geom_line() + \n  labs(y = NULL) +\n  facet_wrap(facets = vars(name), scales = \"free_y\")\n\n\n\n\n\n\n\n\n# Convergence after 500 iterations, so throw them out.\n# Posterior distributions\nmon_tibble_longer %&gt;% \n  filter(index &gt; 500) %&gt;%\n  mutate(name = if_else(name == \"tau\", \"sigma\", name),\n         value = if_else(name == \"sigma\", 1 / sqrt(value), value)) %&gt;%\n  summarize(\n    .by = name,\n    M = mean(value),\n    SD = sd(value),\n    LCI = quantile(value, .025),\n    UCI = quantile(value, .975)\n  )\n## # A tibble: 4 × 5\n##   name        M     SD   LCI   UCI\n##   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 alpha_0 1097. 24.3   1049. 1144.\n## 2 alpha_1  850. 15.8    819.  881.\n## 3 sigma    130.  9.31   113.  150.\n## 4 chgpt   1898.  0.728 1896. 1899.\n\n# You can summarize the values by t to average the models.\n# Recall the model is mu_t = alpha + beta*Year where alpha = alpha_0 or alpha_1\nmon_tibble %&gt;%\n  head(-500) %&gt;%\n  mutate(\n    series = pmap(list(alpha_0, alpha_1, chgpt), function(a0, a1, c) {\n      t &lt;- 1:100\n      y &lt;- if_else(t &lt; c, a0, a1)\n      rs &lt;- tibble(t, y)\n      rs\n    })\n  ) %&gt;%\n  select(series) %&gt;%\n  unnest(series) %&gt;%\n  summarize(.by = t, y = mean(y), lci = quantile(y, .025), uci = quantile(y, .975)) %&gt;%\n  ggplot(aes(x = t)) +\n  geom_line(aes(y = y)) +\n  geom_ribbon(aes(ymin = lci, ymax = uci))\n\n\n\n\n\n\n\n\n\n\n3.5.6 Cluster Analysis\nYou can use Bayes for mixtures. Suppose you have a mixture of \\(z_i \\in [1, 2, 3]\\) types of grains with mean diameters of 3.8, 5, and 8mm. Given a grain of diameter \\(x_i\\), what is its class, \\(z_i\\)?\n\ncinderella &lt;- tibble(\n  z = c(rep(1, 200), rep(2, 100), rep(3, 300)),\n  x = c(rnorm(200, 3.8, .25), rnorm(100, 5, .5), rnorm(300, 8, 1))\n)\n\nYou might start with the assumption that \\((x_i|z_i, \\mu_{z_i}, \\tau_{z_i}) \\sim N(\\mu_{z_i}, \\tau_{z_i})\\) and assign conjugate priors \\(\\mu_k \\sim N(\\mu_{k0}, \\tau_{k0})\\) and \\(\\tau_k \\sim \\text{Gamma}(a_k, b_k)\\) for \\(k = 1, \\ldots, 3\\). To estimate the class probabilities of each grain, you need to start with a prior. \\(Pr(z_i = k) = 1/K = 1/3\\) is a good prior.\nThe problem becomes\n\\[\n\\begin{align}\nPr(z_i = k|x_i, \\mu_k, \\tau_k) &= \\frac{f(x_i|z_i = k, \\mu_k, \\tau_k) Pr(z_i = k)}{\\sum_k f(x_i|z_i = k, \\mu_k, \\tau_k) Pr(z_i = k)} \\\\\n&= \\frac{f(x_i|z_i = k, \\mu_k, \\tau_k)}{\\sum_k f(x_i|z_i = k, \\mu_k, \\tau_k)}\n\\end{align}\n\\]\nNMixMCMC() assigns initial values for \\(\\mu s\\), \\(\\tau s\\) and \\(z_i s\\). Given \\(\\mu s\\) and \\(\\tau s\\), it samples \\(z_i s\\) from the assumed distribution. For each group, \\(k\\), sample \\(\\mu_k\\) and then \\(\\tau_k\\) from the conjugate conditional posterior distribution. Then repeat until convergence.\n\nlibrary(mixAK)\n\nmdl_mix &lt;- NMixMCMC(\n  y0 = cinderella$x,\n  nMCMC = c(burn = 1000, keep = 1000, thin = 1, info = 100),\n  prior = list(priorK = \"fixed\", Kmax = 3)\n)\n## \n## Chain number 1\n## ==============\n## MCMC sampling started on Tue Dec 30 14:50:12 2025.\n## Burn-in iteration 100\b\b\b200\b\b\b300\b\b\b400\b\b\b500\b\b\b600\b\b\b700\b\b\b800\b\b\b900\b\b\b1000\n## Iteration 1100\b\b\b\b1200\b\b\b\b1300\b\b\b\b1400\b\b\b\b1500\b\b\b\b1600\b\b\b\b1700\b\b\b\b1800\b\b\b\b1900\b\b\b\b2000\n## MCMC sampling finished on Tue Dec 30 14:50:13 2025.\n## \n## Chain number 2\n## ==============\n## MCMC sampling started on Tue Dec 30 14:50:13 2025.\n## Burn-in iteration 100\b\b\b200\b\b\b300\b\b\b400\b\b\b500\b\b\b600\b\b\b700\b\b\b800\b\b\b900\b\b\b1000\n## Iteration 1100\b\b\b\b1200\b\b\b\b1300\b\b\b\b1400\b\b\b\b1500\b\b\b\b1600\b\b\b\b1700\b\b\b\b1800\b\b\b\b1900\b\b\b\b2000\n## MCMC sampling finished on Tue Dec 30 14:50:13 2025.\n## \n## Computation of penalized expected deviance started on Tue Dec 30 14:50:13 2025.\n## Computation of penalized expected deviance finished on Tue Dec 30 14:50:14 2025.\n\n# posterior means mu\nc(mdl_mix[[1]]$poster.mean.mu * sd(cinderella$x)) + mean(cinderella$x)\n## [1] 3.767875 4.914559 8.100875\n\n# posterior means for SD\nsqrt(c(unlist(mdl_mix[[1]]$poster.mean.Sigma)))*sd(cinderella$x)\n##        j1        j2        j3 \n## 0.2573165 0.6120158 0.9945381\n\n# estimated class frequency distribution\nround(mdl_mix[[1]]$poster.mean.w, 2)\n##   w1   w2   w3 \n## 0.31 0.20 0.49\n\n# estimated probability per class of first few seeds\nmdl_mix[[1]]$poster.comp.prob_u %&gt;% head()\n##       [,1]  [,2]  [,3]\n## [1,] 0.951 0.049 0.000\n## [2,] 0.697 0.303 0.000\n## [3,] 0.932 0.068 0.000\n## [4,] 0.916 0.084 0.000\n## [5,] 0.477 0.522 0.001\n## [6,] 0.921 0.079 0.000\n\n# Marginal plot\nNMixPredDensMarg(mdl_mix[[1]], lgrid = 150) %&gt;% plot()\n\n\n\n\n\n\n\n\nIn this case we new how many classes were in the data. If that was unknown, you could use reversible-jump MCMC which produces a posterior distribution for the number of components.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#beta-binomial-and-estimating-proportions",
    "href": "03-bayesian-statistics.html#beta-binomial-and-estimating-proportions",
    "title": "3  Bayesian Statistics",
    "section": "3.6 Beta Binomial and Estimating Proportions",
    "text": "3.6 Beta Binomial and Estimating Proportions\nSuppose \\(y = 35\\) of \\(n = 50\\) seeds germinate within 72hrs. What is the expected germination probability of a single seed? Seed germination can be modeled as \\(n\\) Bernoulli trials where events occur with probability, \\(p\\), and the number of observed events is \\(y = \\sum_i^n y_i\\). The question is estimating the \\(p\\) parameter in the Bernoulli generating process.\nThe classical approach is to construct a 95% CI around \\(p\\) with a one-sample proportion test.\n\ny &lt;- 35\nn &lt;- 50\n\nprop.test(y, n)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  y out of n, null probability 0.5\nX-squared = 7.22, df = 1, p-value = 0.00721\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.5521660 0.8171438\nsample estimates:\n  p \n0.7 \n\n\nThe Bayesian approach is to posit an expected distribution of \\(p\\) prior to observing the data, then update the distribution based on the relative likelihood of observing the data given the values in the distribution. The likelihood of \\(y\\) events in \\(n\\) trials follows the binomial distribution, \\(y|p \\sim \\text{Bin}(n, p)\\).\n\\[\nf(y|p) = {n \\choose y} p^y (1-p)^{n-y}\n\\]\nStart with a uniform prior - all values of \\(p\\) are equally likely. To get a feel for the approach, try this with discrete \\(p\\) values first.\n\n# Explore the parameter space [0,1] in discrete .01 increments.\np &lt;- seq(0, 1, by = 0.01)\n\n# Prior distribution is uniform, 1/101 for all p's.\nprior &lt;- rep(1/length(p), length(p))\n\n# Binomial likelihood of each p given 35/50 successes.\nlikelihood &lt;- dbinom(35, 50, p)\n\n# Bayes' Theorem: posterior = joint density / marginal density.\njoint_density &lt;- likelihood * prior\nmarginal_density &lt;- sum(joint_density)\nposterior &lt;- joint_density / marginal_density\n\n# 95% credible interval\n(pi &lt;- sum(posterior * p) / sum(posterior))\n## [1] 0.6923077\n(ci &lt;- p[c(min(which(cumsum(posterior) &gt; .025)),\n          max(which(cumsum(posterior) &lt; .975)))])\n## [1] 0.56 0.80\n\ntibble(p, prior, update = likelihood / marginal_density / 101, posterior) %&gt;%\n  pivot_longer(c(prior, update, posterior)) %&gt;%\n  mutate(name = factor(name, levels = c(\"prior\", \"update\", \"posterior\"))) %&gt;%\n  ggplot(aes(x = p)) +\n  geom_line(aes(y = value, color = name)) +\n  geom_area(data = tibble(p, posterior, y = if_else(p &lt;= ci[1], posterior, NA_real_)),\n            aes(y = y), fill = \"#619CFF\") +\n  geom_area(data = tibble(p, posterior, y = if_else(p &gt;= ci[2], posterior, NA_real_)),\n            aes(y = y), fill = \"#619CFF\") +\n  geom_vline(aes(xintercept = pi), color = \"#619CFF\") +\n  scale_x_continuous(breaks = round(c(seq(0, 1, 1), ci, pi), 4)) +\n  labs(y = \"density\", color = NULL, title = \"From Prior to Posterior\",\n       subtitle = \"Data: y=35, n=50. Posterior equals update.\")\n\n\n\n\n\n\n\n\nThis was good, but we could have done better. The discrete values for the uniform prior limited the precision of the 95% CI. The better path is to model continuous values with the beta distribution, \\(p \\sim \\text{Beta}(a, b)\\). The PDF of the beta distribution is\n\\[\n\\begin{align}\nf(p) &= \\frac{1}{\\text{B}(a,b)} p^{a-1} (1-p)^{b-1} \\\\\n&\\propto p^{a-1} (1 - p)^{b -1}\n(\\#eq:beta-prior)\n\\end{align}\n\\]\nwhere \\(a\\) is the success count, \\(b\\) the failure count, and \\(\\text{B} = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Equation @ref(eq:beta-prior) is called the beta prior. The beta prior is a conjugate prior, meaning the posterior distribution is also a beta distribution, so the \\(\\frac{1}{\\text{B}(a,b)}\\) cancels out and the proportional form is all you need. The uniform prior distribution would be modeled with \\(\\text{Beta}(1, 1)\\).\nThe likelihood of observing \\(y\\) successes in \\(n\\) trials given \\(p\\) follows the binomial PMF. The constant binomial coefficient can be discarded.\n\\[\n\\begin{align}\nf(y|p) &= {n \\choose y} p^y (1-p)^{n-y} \\\\\n&\\propto p^y (1-p)^{n-y}\n(\\#eq:beta-likelihood)\n\\end{align}\n\\]\nThe product of the prior and likelihood is the joint density. The marginal density is the integral of the joint density over all \\(p\\).\n\\[\n\\begin{equation}\n\\int_{p=0}^1f(y|p) f(p) dp = \\frac{\\text{B}(a + y, b + (n-y))}{\\text{B}(a, b)}\n(\\#eq:beta-marginal)\n\\end{equation}\n\\]\nUsing the proportional forms, the denominator of Bayes’ Theorem can be discarded, so the posterior distribution is just the joint density.\n\\[\n\\begin{align}\nf(p|y) & \\propto f(y|p)f(p) \\\\\n& \\propto p^y (1-p)^{n-y} p^{a-1} (1 - p)^{b -1} \\\\\n& \\propto p^{a+y-1}(1-p)^{b+n-y-1} \\\\\n& \\sim \\text{Beta}(a + y, b + (n - y))\n(\\#eq:beta-posterior)\n\\end{align}\n\\]\nThe expected value of the beta distribution is \\(a / (a + b)\\). Updated with the observed data, the expected value is\n\\[\nE(p|y) = \\frac{a+y}{(a+y)+(b+(n-y))} = \\frac{a + y}{a + b + n} = \\frac{a + n \\bar{y}}{a + b + n}\n\\]\nAs the sample size increases, the \\(a\\) and \\(b\\) prior parameter values become less important and \\(E(p|y)\\) converges on the classical result of \\(\\bar{y}\\). The code chunk below repeats the exercise above. This time that we can calculate a continuous 95% CI. Notice also that the marginal density never actually factored into the solution.\n\n# These discrete p's are for illustrating the distributions now.\np &lt;- seq(0, 1, by = 0.001)\n\n# The prior distribution is uniform, Beta(1, 1).\na &lt;- 1\nb &lt;- 1\nprior &lt;- dbeta(p, a, b)\n\n# Instead of calculating the likelihood, joint density, marginal density, and\n# finally the posterior, we can go straight to the posterior.\nposterior &lt;- dbeta(p, a + y, b + (n - y))\n\n# 95% credible interval. This time we don't need p - we can go straight to the soln.\n(pi &lt;- (a + y) / ((a + y) + (b + (n - y))))\n## [1] 0.6923077\n(ci &lt;- qbeta(c(.025, .975), a + y, b + (n - y)))\n## [1] 0.5617113 0.8088960\n\n# Construct the components anyway, just to graph them.\nlikelihood &lt;- dbinom(y, n, p)\njoint_density &lt;- likelihood * prior\nmarginal_density &lt;- sum(joint_density)\n# Trickery to get discretely calculated joint and marginal densities to sum to\n# same area as prior and posterior distributions.\nupdate &lt;- likelihood / (sum(likelihood) / sum(posterior))\n\ntibble(p, prior, update, posterior) %&gt;%\n  pivot_longer(c(prior, update, posterior)) %&gt;%\n  mutate(name = factor(name, levels = c(\"prior\", \"update\", \"posterior\"))) %&gt;%\n  ggplot(aes(x = p)) +\n  geom_line(aes(y = value, color = name)) +\n  geom_area(data = tibble(p, posterior, y = if_else(p &lt;= ci[1], posterior, NA_real_)),\n            aes(y = y), fill = \"#619CFF\") +\n  geom_area(data = tibble(p, posterior, y = if_else(p &gt;= ci[2], posterior, NA_real_)),\n            aes(y = y), fill = \"#619CFF\") +\n  geom_vline(aes(xintercept = pi), color = \"#619CFF\") +\n  scale_x_continuous(breaks = round(c(seq(0, 1, 1), ci, pi), 4)) +\n  labs(y = \"density\", color = NULL, title = glue(\"From Prior to Posterior, using Beta({a}, {b}) prior.\"),\n       subtitle = \"Data: y=35, n=50.\")\n\n\n\n\n\n\n\n\nSuppose your prior was better. You had taken a small sample of 10 and 7 seeds had germinated. The corroborating evidence centers on 70% and the credible interval tightens.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#zero-inflation-and-latent-variables",
    "href": "03-bayesian-statistics.html#zero-inflation-and-latent-variables",
    "title": "3  Bayesian Statistics",
    "section": "3.7 Zero-Inflation and Latent Variables",
    "text": "3.7 Zero-Inflation and Latent Variables\nSuppose 100 persons report the number of days per week they consume alcohol (0 - 7). What is the posterior estimated probability of a person having a drink on any given day? Drinking days should follow a binomial distribution, so you should be able to estimate \\(p\\) using a \\(\\text{Beta}(1, 1)\\) prior. The beta posterior would be \\(\\text{Beta}(252, 450)\\).\n\ndays &lt;- 0:7\nrespondents &lt;- c(22, 6, 18, 23, 18, 10, 3, 0)\ny &lt;- rep(days, respondents)\n\n# Total events\n(drinking_days &lt;- sum(y))\n## [1] 251\n\n# Possible events\n(n &lt;- 7 * 100)\n## [1] 700\n\n# Beta posterior\n(a &lt;- 1 + drinking_days)\n## [1] 252\n(b &lt;- 1 + (n - drinking_days))\n## [1] 450\n\n# Posterior mean and 95% CI.\na / (a + b)\n## [1] 0.3589744\nqbeta(c(.025, .975), a, b)\n## [1] 0.3239070 0.3948028\n\nThe predictive distribution of \\(\\tilde{y}\\) is \\(f(\\tilde{y}|y) = \\int f(\\tilde{y}|p) f(p|y) dp\\). The way you would normally solve this is to run a simulation. Sample a thousand \\(p\\)’s from the posterior beta distribution, then use them to sample 100 respondents from the binomial distribution.\n\nset.seed(12345)\n\np_given_y &lt;- rbeta(10^3, a, b)\n\n# For each p, simulate 7 draws from binomial distribution for the 100 respondents.\nsims &lt;- map(p_given_y, ~rbinom(100, 7, .))\n\n# Count the number of times y == [0,7]. Start by converting the 10^3 sims x 100 \n# participants list into an 8 days x 10^3 sims list. The three metrics are \n# vectors of length 8.\nsim_y_per_days &lt;- map(days, function(x) map_int(sims, ~sum(. == x)))\nmeans &lt;- map_dbl(sim_y_per_days, mean)\nlcl &lt;- map_dbl(sim_y_per_days, ~quantile(.x, .025))\nucl &lt;- map_dbl(sim_y_per_days, ~quantile(.x, .975))\n\ntibble(days, respondents, means, lcl, ucl) %&gt;%\n  ggplot(aes(x = days)) +\n  geom_col(aes(y = respondents)) +\n  geom_point(aes(y = means)) +\n  geom_errorbar(aes(ymin = lcl, ymax = ucl), width = .2) +\n  scale_x_continuous(breaks = 0:7)\n\n\n\n\n\n\n\n\nUh oh! The problem is that the number of drinking days only follows a binomial distribution for drinkers - abstainers have \\(p\\) = 0. This phenomena is called zero-inflation. The solution is to model \\(p\\) conditional on the probability the person drinks, \\(\\omega\\). Let \\(z_i = 1\\) if respondent \\(i\\) drinks alcohol at all. Then \\((y_i|z_i = 1, p) \\sim \\text{Bin}(7, p)\\), otherwise \\(P(y_i =0|z_i = 0) = 1\\). Model the probability of \\(z_i = 0\\) with the Bernoulli distribution, \\(z_i|\\omega \\sim \\text{Bern}(\\omega)\\) where \\(\\omega \\sim \\text{Beta}(a_\\omega, b_\\omega)\\).\nImplement a Gibbs sampler with uniform priors for \\(p \\sim \\text{Beta}(a = 1, b = 1)\\) and \\(\\omega \\sim \\text{Beta}(a_\\omega = 1, b_\\omega = 1)\\). Start with the assumption that if \\(y_i = 0\\) then \\(z_i = 0\\), so for each respondent\n\\[\n\\begin{align}\nP(z_i = 1| y_i &gt; 0, p, \\omega) &= 1 \\\\\nP(z_i = 1| y_i = 0, p, \\omega) &= \\frac{(1-p)^7 \\omega}{(1-\\omega) + (1-p)^7 \\omega}\n\\end{align}\n\\]\n\nset.seed(12345)\n\n# Start with assumption that if they reported 0, they _never_ drink (y_i=0 -&gt; z_i=0).\nz &lt;- as.numeric(y &gt;= 1)\n\n# Run 1,000 iterations, updating p, omega, and z each time.\nITER &lt;- 10^3\n\n# Create monitors to track convergence.\nsim_p &lt;- numeric(ITER)\nsim_omega &lt;- numeric(ITER)\nsim_z &lt;- matrix(nrow = length(y), ncol = ITER)\n\n# Gibbs sampler.\nfor(iter in 1:ITER) {\n  # Uniform Beta(1,1) prior for probability the person is a drinker. Posterior \n  # is based on count of non-zero z's.\n  omega &lt;- rbeta(1, 1 + sum(z), 1 + (length(z) - sum(z)))\n  \n  # Uniform Beta(1,1) prior for probability of drinking on any given day. Posterior\n  # is based on reported drinking days and number of people who are drinkers.\n  p &lt;- rbeta(1, 1 + sum(y), 1 + (7 * sum(z) - sum(y)))\n  \n  # Updated probability that respondent is a drinker. \n  # P(z=1|y&gt;0) = 1 or P(z=1|y=0, p, omega).\n  prob_z_eq_1 &lt;- if_else(y &gt;= 1, 1, \n                         ((1 - p)^7 * omega) / ((1 - omega) + ((1 - p)^7 * omega)))\n\n  # Update z.\n  z &lt;- rbinom(100, 1, prob_z_eq_1)\n  \n  # update monitors\n  sim_p[iter] &lt;- p\n  sim_omega[iter] &lt;- omega\n  sim_z[, iter] &lt;- z\n}\n\n# Estimated probability of being an alcohol drinker.\nmean(sim_omega)\n## [1] 0.7863099\nquantile(sim_omega, c(.025, .975))\n##      2.5%     97.5% \n## 0.7051111 0.8581847\n\n# Of the alcohol drinkers, the probability of drinking on any given day.\nmean(sim_p)\n## [1] 0.4533135\nquantile(sim_p, c(.025, .975))\n##      2.5%     97.5% \n## 0.4121130 0.4949042\n\n# mean and 95% CI predicted number of [0,7] drinking days.\nz_post_pred &lt;- map(1:ITER, ~rbinom(100, 1, sim_omega))\nx_post_pred &lt;- map(1:ITER, ~rbinom(100, 7, sim_p))\n# Override the probability with zero when z == 0.\nx_post_pred &lt;- map2(x_post_pred, z_post_pred, ~ if_else(.y == 0, 0, .x))\n# Count the number of times [0,7] comes up. Average this across the 10^3 experiments.\nmeans &lt;- map_dbl(days, function(x) map_int(x_post_pred, ~sum(. == x)) %&gt;% mean())\nlcl &lt;- map_dbl(days, function(x) map_int(x_post_pred, ~sum(. == x)) %&gt;% quantile(.025))\nucl &lt;- map_dbl(days, function(x) map_int(x_post_pred, ~sum(. == x)) %&gt;% quantile(.975))\n\ntibble(days, respondents, means, lcl, ucl) %&gt;%\n  ggplot(aes(x = days)) +\n  geom_col(aes(y = respondents)) +\n  geom_point(aes(y = means)) +\n  geom_errorbar(aes(ymin = lcl, ymax = ucl), width = .2) +\n  scale_x_continuous(breaks = 0:7)\n\n\n\n\n\n\n\n\nMuch better. Let’s try another example of modeling with zero inflation. 94 tourists report how many fish they caught during their visit. Estimate the distribution of fish caught. Start with a vague prior, \\(\\lambda \\sim \\text{Gamma}(a = .1, b = .1)\\). The posterior distribution of \\(\\lambda|y \\sim \\text{Gamma}(a + \\sum_i{y_i}, b + n)\\)\n\nfish &lt;- readr::read_csv(\"input/fish.csv\", col_types = \"i\") %&gt;% filter(!is.na(catch))\n\n# Simulate 10^3 samples.\nset.seed(12345)\n\n# Uniform gamma(a, b) prior.\na &lt;- .01\nb &lt;- .01\n\n# Sample gamma 10^3 times from the posterior distribution\nsampled_lambda &lt;- rgamma(10^3, a + sum(fish$catch), b + nrow(fish))\ny_tilde &lt;- rpois(10^3, sampled_lambda)\n\n# mean and 95% CI predicted number of expected value of fish caught.\nmean(y_tilde)\n## [1] 2.875\nquantile(y_tilde, c(.025, .975))\n##  2.5% 97.5% \n##     0     6\n\n# mean and 95% CI predicted number of [0, 9] fish caught.\n# For 10^3 lambdas, create 94 samples from Poisson dist. \nsims &lt;- map(sampled_lambda, ~rpois(nrow(fish), .))\n# Count the number of times [0,10] comes up. Average this across the 10^3 experiments. \ncatch &lt;- 0:max(fish$catch)\nmeans &lt;- map_dbl(catch, function(x) map_int(sims, ~sum(. == x)) %&gt;% mean())\nlcl &lt;- map_dbl(catch, function(x) map_int(sims, ~sum(. == x)) %&gt;% quantile(.025))\nucl &lt;- map_dbl(catch, function(x) map_int(sims, ~sum(. == x)) %&gt;% quantile(.975))\n\ntibble(catch, means, lcl, ucl) %&gt;%\n  left_join(fish %&gt;% count(catch, name = \"y\"), by = join_by(catch)) %&gt;%\n  ggplot(aes(x = catch)) +\n  geom_col(aes(y = y)) +\n  geom_point(aes(y = means)) +\n  geom_errorbar(aes(ymin = lcl, ymax = ucl), width = .2) +\n  scale_x_continuous(breaks = 0:10) +\n  labs(title = \"Zero inflation in fish caught.\")\n\n\n\n\n\n\n\n\nThis doesn’t look good. The probability of 27 people catching 0 fish when the expected number of fish is 2.9 is less than .001.\n\n# probability of 27 people with catching 0 fish given lambda = 2.9 is &lt;.001.\n(lambda_est &lt;- (a + sum(fish$catch)) / (b + 94))\n\n[1] 2.925327\n\nppois(sum(fish$catch == 0), lambda = means[1], lower.tail = FALSE)\n\n[1] 1.064884e-12\n\n\nAdd a binary latent variable to the model describing whether or not the person was fishing Assign a uniform prior to the probability that the person was fishing Derive posterior conditional distributions and construct a Gibbs sampler to estimate your model\n\nset.seed(12345)\n\n# Reported number of fish caught by 94 respondents.\ny &lt;- fish$catch\n\n# Start with assumption that if they caught 0, they did not fish (y_i=0 -&gt; z_i=0).\nz &lt;- as.numeric(y &gt;= 1)\n\n# Run 1,000 iterations, updating p, omega, and z each time.\nITER &lt;- 10^3\n\n# Create monitors to track convergence.\nsim_lambda &lt;- numeric(ITER)\nsim_omega &lt;- numeric(ITER)\nsim_z &lt;- matrix(nrow = length(y), ncol = ITER)\n\n# Gibbs sampler.\nfor(iter in 1:ITER) {\n  # Uniform Beta(1,1) prior probability the person fished. Posterior is based on\n  # count of non-zero z's.\n  omega &lt;- rbeta(1, 1 + sum(z), 1 + (length(y) - sum(z)))\n  \n  # Vague Gamma(.01,.01) prior for number of fish caught. Posterior is based on\n  # reported catch and number of believed fishers.\n  lambda &lt;- rgamma(1, .01 + sum(y), .01 + sum(z))\n  \n  # Updated probability that respondent fishes.\n  # E(z=1|x) = 1 or P(1|x=0, p, omega).\n  prob_y_eq_0 &lt;- exp(-lambda) * lambda^0 / factorial(0)\n  prob_z_eq_1 &lt;- if_else(y &gt;= 1, 1,\n                         (prob_y_eq_0 * omega) / ((1 - omega) + (prob_y_eq_0 * omega)))\n\n  # Update z.\n  z &lt;- rbinom(length(y), 1, prob_z_eq_1)\n\n  # update monitors\n  sim_lambda[iter] &lt;- lambda\n  sim_omega[iter] &lt;- omega\n  sim_z[, iter] &lt;- z\n}\n\n# Estimate of tourists who fished. Throw out first 100 as burn-in.\nmean(sim_omega[-c(1:100)])\n## [1] 0.7219762\nquantile(sim_omega[-c(1:100)], c(.025, .975))\n##      2.5%     97.5% \n## 0.6281519 0.8081336\n\n# Of those who fished, the expected number caught. Throw out burn-in again.\n# tibble(x = 1:1000, y = sim_lambda) %&gt;% ggplot(aes(x = x, y = y)) + geom_point()\nmean(sim_lambda[-c(1:100)])\n## [1] 4.048745\nquantile(sim_lambda[-c(1:100)], c(.025, .975))\n##     2.5%    97.5% \n## 3.573121 4.598533\n# or is it this (E(X) = a/b? Not this either.\n(.01 + sum(y)) / (.01 + sum(z))\n## [1] 4.104014\n\n# mean and 95% CI predicted number of [0,9] fish caught.\nz_post_pred &lt;- map(1:ITER, ~rbinom(length(z), 1, sim_omega))\ny_post_pred &lt;- map(1:ITER, ~rpois(length(y), sim_lambda))\n# Override the count with zero when z == 0.\ny_post_pred &lt;- map2(y_post_pred, z_post_pred, ~ if_else(.y == 0, 0, .x))\n# Count the number of times [0,9] comes up. Average this across the 10^3 experiments.\nmeans &lt;- map_dbl(0:9, function(x) map_int(y_post_pred, ~sum(. == x)) %&gt;% mean())\nlcl &lt;- map_dbl(0:9, function(x) map_int(y_post_pred, ~sum(. == x)) %&gt;% quantile(.025))\nucl &lt;- map_dbl(0:9, function(x) map_int(y_post_pred, ~sum(. == x)) %&gt;% quantile(.975))\n\n# Probability of 27 of 94 people with a catch of 0. Sample the posterior \n# predictive distribution.\nposterior_pred &lt;- matrix(rpois(ITER * length(y), rep(sim_lambda, length(y))), ncol = ITER) * sim_z\nposterior_zeros &lt;- map_int(1:ITER, ~sum(posterior_pred[, .] == 0))\nmean(posterior_zeros[100:ITER] &gt;= sum(y==0))\n## [1] 0.6492786\n\ntibble(catch = 0:9, means, lcl, ucl) %&gt;%\n  left_join(fish %&gt;% count(catch, name = \"y\"), by = join_by(catch)) %&gt;%\n  ggplot(aes(x = catch)) +\n  geom_col(aes(y = y)) +\n  geom_point(aes(y = means)) +\n  geom_errorbar(aes(ymin = lcl, ymax = ucl), width = .2) +\n  scale_x_continuous(breaks = 0:10)",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#dic",
    "href": "03-bayesian-statistics.html#dic",
    "title": "3  Bayesian Statistics",
    "section": "3.8 DIC",
    "text": "3.8 DIC\nUse the Deviance Information Criterion (DIC) to compare group means.\n\\[\nDIC = p_D + \\overline{D(\\theta)}\n\\]\nwhere \\(p_D = \\overline{D(\\theta)} - D(\\hat{\\theta})\\) and \\(D(\\theta) = -2 \\log (f(y|\\theta)) + C\\).\nEvaluate \\(\\overline{D(\\theta)}\\) by producing samples from each distribution and evaluating the likelihoods of the data based on each realization and taking the mean of -2 log-likelihood.\n\n# Two samples with success rates 35/50 and 15/20\ny &lt;- c(35, 15)\nn &lt;- c(50, 20)\n\n# Priors\na &lt;- 1\nb &lt;- 1\n\n# Posteriors\npost &lt;- list(\n  rbeta(10^3, a+y[1], b+n[1]-y[1]),\n  rbeta(10^3, a+y[2], b+n[2]-y[2])\n)\n\n# -2 * Mean log-likelihood\nll &lt;- \n  dbinom(y[1], n[1], post[[1]], log = TRUE) +\n  dbinom(y[2], n[2], post[[2]], log = TRUE)\n(mean_D &lt;- mean(-2 * ll))\n\n[1] 9.287665\n\n# D(theta-bar) is the likelihood of the data based on the posterior means of p.\n(D_mean &lt;- -2 * (\n  dbinom(y[1], n[1], (a+y[1]) / (a+y[1] + b+n[1]-y[1]), log = TRUE) +\n  dbinom(y[2], n[2], (a+y[2]) / (a+y[2] + b+n[2]-y[2]), log = TRUE)\n))\n\n[1] 7.46448\n\n#p_D and DIC from equation\n(p_D &lt;- mean_D - D_mean)\n\n[1] 1.823185\n\n(DIC &lt;- p_D + mean_D)\n\n[1] 11.11085\n\n# Repeat these steps for a single model of both groups\npost_group &lt;- rbeta(10^3, a+sum(y), b+sum(n)-sum(y))\nll_group &lt;- \n  dbinom(y[1], n[1], post_group, log = TRUE) +\n  dbinom(y[2], n[2], post_group, log = TRUE)\n(mean_D_group &lt;- mean(-2 * ll_group))\n\n[1] 8.576659\n\n(D_mean_group &lt;- -2 * (\n  dbinom(y[1], n[1], (a+sum(y)) / (a+sum(y) + b+sum(n)-sum(y)), log = TRUE) +\n  dbinom(y[2], n[2], (a+sum(y)) / (a+sum(y) + b+sum(n)-sum(y)), log = TRUE)\n))\n\n[1] 7.587449\n\n(p_D_group &lt;- mean_D_group - D_mean_group)\n\n[1] 0.9892094\n\n(DIC_group &lt;- p_D_group + mean_D_group)\n\n[1] 9.565868\n\n\nThe DIC for the two group model is 11.1108506 and for the one common group model it is 9.5658681. The DIC for one common group model is smaller, so we do not have enough statistical evidence for two groups. If the DIC for the group-specific model is at least 3 units smaller than that for the common model, there is sufficient statistical evidence for difference between groups.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#monte-carlo-integration",
    "href": "03-bayesian-statistics.html#monte-carlo-integration",
    "title": "3  Bayesian Statistics",
    "section": "3.9 Monte Carlo Integration",
    "text": "3.9 Monte Carlo Integration\nMonte Carlo integration is an empirical way to solve the integrals related to the posterior mean and variance. The population expectation, \\(E[X] = \\int_{-\\infty}^\\infty x f(x) dx\\), and variance \\(Var(X) = E(X-EX)^2 = \\int_{-\\infty}^\\infty (x - EX)^2f(x)dx\\), are both integrals.\nYou can use Monte Carlo to evaluate an integral such as \\(A=\\int_0^1 20x(1-x)^3dx\\). If you randomly select \\(n\\) points from a defined space \\(D\\), the number \\(z\\) enclosed by the integral will follow a binomial distribution, \\(Z \\sim \\text{Bin} (n, p)\\) with \\(E[Z] = np = n \\frac{A}{D}\\) and variance \\(Var[Z] = np(1-p) = n \\frac{A}{D} \\left(1-\\frac{A}{D}\\right)\\). If you know the enclosing area, then you can infer the integral area,\n\\[\n\\begin{equation}\n\\hat{A} = \\frac{z}{n} D\n(\\#eq:monte-carlo-est)\n\\end{equation}\n\\]\nThe variance of \\(Var(\\hat{A}) = Var\\left(\\frac{z}{n} D\\right) = Var(Z) \\left(\\frac{z}{n}\\right)^2 = \\frac{A(D-A)}{n}\\). Of course, you do not know \\(A\\), so you replace it with \\(\\hat{A}\\). Solve this for the Monte Carlo standard error.\n\\[\n\\begin{equation}\n\\widehat{s.e.} = \\frac{D}{\\sqrt{n}} \\sqrt{\\frac{z}{n}\\left(1 - \\frac{z}{n} \\right)}\n(\\#eq:monte-carlo-se)\n\\end{equation}\n\\]\nNotice how the Monte Carlo standard error increases with D and decreases with \\(n\\). Let’s try it. Generate 1,000 points uniformly in the domain [0,1] x [0, 3], then check whether they are below the f() curve.\n\nset.seed(12345) \n\nf &lt;- function(x) {20*x*(1 - x)^3}\n\n# Defined area\nD &lt;- 1 * 3\n\n# n random points in defined area.\nn &lt;- 1000\nx &lt;- runif(n, 0, 1)\ny &lt;- runif(n, 0, 3)\n\nis_under &lt;- y &lt;= f(x)\nz &lt;- sum(is_under)\n\n# Area is percent of points under the curve\n(A_hat &lt;- z / n * D)\n## [1] 0.918\n(se &lt;- D / sqrt(n) * sqrt(z/n * (1 - z/n)))\n## [1] 0.04371814\n\ntibble(x, f = f(x), rand_y = y, is_under) %&gt;% \n  ggplot(aes(x = x)) + \n  geom_area(aes(y = f)) + \n  geom_point(aes(y = rand_y, color = is_under), show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n3.9.1 Inverse Sampling\nIn Bayesian analysis, you do not always have a pre-defined distribution to sample from. In these cases, you may be able to use inverse sampling. Given \\(f(x)\\), the corresponding CDF is \\(F(x) = \\int_0^x f(x)dx\\). Derive its inverse by solving \\(F(x)\\) for \\(x\\). To inverse sample, sample from \\(U(0,1)\\) and evaluate \\(x = F^{-1}(u)\\).\nHere is an example. Suppose \\(f(x) = 2x\\) on \\(x \\in [0,1]\\) and 0 otherwise. Then \\(F(x) = x^2 = u\\) and solving \\(F(x)\\) for \\(x\\), \\(F^{-1}(u) = \\sqrt{u}\\).\n\nset.seed(12345)\n\nu &lt;- runif(10^4)\nx &lt;- sqrt(u)\n\ntibble(x, c = 2*x) %&gt;% ggplot(aes(x = x)) + geom_density(color = \"salmon\") + geom_line(aes(y = c))\n\n\n\n\n\n\n\n\nSuppose \\(f(x) = \\lambda e^{-\\lambda x}\\) on \\(x \\in [0,1]\\) and 0 otherwise. Then \\(F(x) = 1 - e^{-\\lambda x} = u\\) and \\(F^{-1}(u) = - \\frac{1}{\\lambda} \\ln [1-u]\\).\n\nset.seed(12345)\n\nu &lt;- runif(10^4)\n\nlambda &lt;- 2\n\nx &lt;- - (1 / lambda) * log(1 - u)\n\ntibble(x, c = 2 * exp(-2*x)) %&gt;% ggplot(aes(x = x)) + geom_density(color = \"salmon\") + \n  geom_line(aes(y = c))\n\n\n\n\n\n\n\n\n\n\n3.9.2 Rejection Sampling\nThe problem is that inverse sampling only works when \\(F(x)\\) is invertible. Another option is rejection sampling. Suppose you cannot sample from \\(f_X(x)\\) but you can from \\(g_X(x)\\) and the importance ratio \\(\\frac{f_X(x)}{g_X(x)} &lt;= M\\) for all \\(x\\). Then you can sample \\(x\\) from \\(g_X(x)\\), then draw from \\(u \\sim U(0,1)\\) and accept \\(y = x\\) with probability \\(\\frac{f_X(x)}{M g_X(x)}\\), i.e., if accepts if \\(u \\ge \\frac{f_X(x)}{M g_X(x)}\\).\nReturn to the example where \\(f(x) = 2x\\) on \\(x \\in [0,1]\\). Consider \\(g(x) = 1\\) on \\(x \\in [0,1]\\), the pdf of uniform distribution. The ratio \\({f(x)}{g(x)} = 2x \\le 2\\) for \\(x \\in [0,1]\\). So it is bounded by \\(M = 2\\). Accept \\(x\\) with probability \\(\\frac{f_X(x)}{M g_X(x)} = \\frac{2x}{2 \\cdot 1} = x\\).\n\nset.seed(12345)\n\n# g(x) is uniform dist\nx &lt;- runif(10^4)\n\n# probability of acceptance = x\np_acc &lt;- x\n\n# Draw from u\nu &lt;- runif(10^4)\nis_in &lt;- u &lt; p_acc\n\n# Keep the accepted ones\nmy_sample &lt;- x[is_in]\n\n# Only kept a little more than half - no very efficient.\nlength(my_sample)\n\n[1] 5017\n\n\nSuppose \\(f(x) = 6x(1-x)\\) on \\(x \\in [0,1]\\). Consider \\(g(x) = 1\\) on \\(x \\in [0,1]\\), the pdf of uniform distribution. The ratio \\({f(x)}{g(x)} = 6x(1-x) \\le 1.5\\) for \\(x \\in [0,1]\\). So it is bounded by \\(M = 1.5\\). Accept \\(x\\) with probability \\(\\frac{f_X(x)}{M g_X(x)} = \\frac{6x(1-x)}{1.5 \\cdot 1} = 4x(1 - x)\\).\n\nset.seed(12345)\n\n# g(x) is uniform dist\nx &lt;- runif(10^4)\n\n# probability of acceptance = \np_acc &lt;- 4 * x * (1 - x)\n\n# Draw from u\nu &lt;- runif(10^4)\nis_in &lt;- u &lt; p_acc\n\n# The overall acceptance probability \nmean(is_in)\n\n[1] 0.6728\n\n# Keep the accepted ones\nmy_sample &lt;- x[is_in]\n\n# Only kept a little more than half - no very efficient.\nlength(my_sample)\n\n[1] 6728\n\n\n\n\n3.9.3 Importance Sampling\nImportance sampling allows to substitute sampling from a “difficult” distribution with sampling from an “easy” one. Suppose you have a random variable \\(x\\) with PDF \\(f(x)\\). The expected value of a function of \\(x\\), \\(h(x)\\) is defined by \\(E(h(x)) = \\int h(x)f(x)dx\\). Using the law of large numbers, you can approximate \\(E(h(x))\\) by its average value, \\(\\frac{1}{n} \\sum_i h(x_i)\\). So you would sample from \\(f(x)\\), multiply by \\(h(x)\\), and take the average.\nWhat would you do if you did not know how to sample from \\(f(x)\\)? Instead you could identify a function you could sample from, and evaluate the integral of the ratio, \\(E(h(x)) = \\int\\left[ h(x) \\frac{f(x)}{g(x)}\\right] g(x) dx\\). With the law of large numbers, \\(E(h(x)) = \\frac{1}{n}\\sum_i\\left[h(x_i) \\frac{f(x_i)}{g(x_i)} \\right]\\). The ratios \\(w(x_i) = \\frac{f(x_i)}{g(x_i)}\\) are called importance weights. Importance weights tell you how useful each observation is.\nSuppose you have a random variable \\(x\\) with PDF \\(f(x) = 25xe^{-5x} = \\text{Gamma}(2,5)\\) for \\(X&gt;0\\). If you wanted to know the expected value of \\(h(x) = x\\) could sample straight from rgamma() and take the average.\n\nmean(rgamma(10^5, 2, 5))\n\n[1] 0.4011863\n\n\nGreat, if rgamma() wasn’t an option, how would you evaluate \\(\\int_0^\\infty x f(x)dx = \\int_0^\\infty 25x^2e^{-5x}dx\\)? Let \\(g(x) = 5e^{-5x}\\). Then \\(E(h(x)) = \\frac{1}{n}\\sum_i\\left[x \\frac{25xe^{-5x}}{5e^{-5x}} \\right] = \\frac{1}{n}\\sum_i 5x_i^2\\)\n\nset.seed(12345)\n\ng &lt;- rexp(10^5, 5)\n\nmean(5*g^2)\n\n[1] 0.3986298\n\n\nGreat, if rgamma() wasn’t an option, how would you evaluate \\(\\int_0^\\infty x f(x)dx = \\int_0^\\infty 25x^2e^{-5x}dx\\)? Let \\(g(x) = 5e^{-5x}\\). Then \\(E(h(x)) = \\frac{1}{n}\\sum_i\\left[x \\frac{25xe^{-5x}}{5e^{-5x}} \\right] = \\frac{1}{n}\\sum_i 5x_i^2\\)\n\nset.seed(12345)\n\ng &lt;- rexp(10^5, 5)\n\nmean(5*g^2)\n\n[1] 0.3986298\n\n\nLet’s try another one. Suppose you want to empirically estimate \\(\\int_0^1 x^5(1-x)^5dx\\). First, use the simple Monte Carlo method to estimate the integral.\n\nset.seed(12345)\n\nf &lt;- function(x) {x^5*(1 - x)^5}\n\n# Set the defined area. Plot f(x) over the range of x to set the appropriate limits.\nx_lim &lt;- c(0, 1)\ny_lim &lt;- c(0, 10^-3)\nD &lt;- (x_lim[2] - x_lim[1]) * (y_lim[2] - y_lim[1])\n\n# Sample from D.\nn &lt;- 10^3\nx &lt;- runif(n, x_lim[1], x_lim[2])\ny &lt;- runif(n, y_lim[1], y_lim[2])\n\n# Area is percent of points under the curve\nis_under &lt;- y &lt;= f(x)\nz &lt;- sum(is_under)\n(A_hat &lt;- z / n * D)\n\n[1] 0.000366\n\n(se &lt;- D / sqrt(n) * sqrt(z/n * (1 - z/n)))\n\n[1] 1.523299e-05\n\ntibble(x, f = f(x), rand_y = y, is_under) %&gt;% \n  ggplot(aes(x = x)) + \n  geom_area(aes(y = f)) + \n  geom_point(aes(y = rand_y, color = is_under), show.legend = FALSE)\n\n\n\n\n\n\n\n\nNow let’s do it with direct sampling. \\(x^5(1-x)^5\\) is almost like the beta function. \\(\\int_0^1 x^5(1-x)^5dx = \\int_0^1 \\frac{x}{1260} 1260x^4(1-x)^5dx = \\int_0^1 \\frac{x}{1250} g(x)dx\\).\n\nset.seed(12345)\n(A_hat &lt;- mean(rbeta(n, 5, 6) / 1260))\n\n[1] 0.0003606394\n\n\nNow let’s do it with importance sampling. Just define \\(\\int_0^1 x^5(1-x)^5dx = \\int_0^1 x^5(1-x)^5g(x)dx\\) where \\(g(x) = 1\\) is the uniform pdf.\n\nset.seed(12345)\n\ng &lt;- runif(10^3)\n\nmean(g^5*(1-g)^5)\n\n[1] 0.0003651211",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#metropolis-hastings-1",
    "href": "03-bayesian-statistics.html#metropolis-hastings-1",
    "title": "3  Bayesian Statistics",
    "section": "3.10 Metropolis-Hastings",
    "text": "3.10 Metropolis-Hastings\nFor any model with likelihood \\(f(y|\\theta)\\) and prior \\(f(\\theta)\\), you can use the Metropolis-Hastings step to estimate \\(\\theta\\). Start with an initial \\(\\theta = \\theta_0\\). Propose a new \\(\\theta'\\) from a proposed distribution \\(q(\\theta'|\\theta)\\) and evaluate the acceptance ratio,\n\\[\nR = \\frac{f(y|\\theta')f(\\theta')}{f(y|\\theta)f(\\theta)} \\frac{q(\\theta|\\theta')}{q(\\theta'|\\theta)}\n\\]\nAccept the new value with probability \\(\\min(R, 1)\\), then repeat until convergence. Notice that if the proposed distribution is symmetric, then the second term drops out and \\(R\\) is just the ratio of posterior distributions. The symmetric version is called Metrolopolis instead of Metropolis-Hastings.\nIf \\(\\theta \\in \\mathbb{R}\\) then the normal is a good proposal distribution, \\(\\theta'|\\theta \\sim N(\\theta, \\delta^{-2})\\). The normal distribution is symmetric, so the Metropolis acceptance ratio will work.\nSuppose you have a normal data generating process with unknown mean \\(\\mu\\) and precision \\(\\tau\\). Your conjugate priors are \\(y_i \\sim N(\\mu, \\tau)\\), \\(\\mu \\sim N(\\mu_0, \\tau_0)\\), and \\(\\tau \\sim \\text{Gamma}(a, b)\\). The conditional distributions are those in Eqns @ref(eq:mu-posterior) and @ref(eq:tau-posterior).\n\\[\n\\begin{align}\n\\mu|y & \\sim N\\left(\\frac{n\\tau\\bar{y} + \\tau_0\\mu_0}{n\\tau + \\tau_0}, n\\tau + \\tau_0 \\right) \\\\\n\\tau|y & \\sim \\text{Gamma}\\left(a + n/2, b + \\frac{1}{2} \\sum_i(y_i - \\mu)^2 \\right)\n\\end{align}\n\\]\nLet’s replace the Gibbs step for \\(\\mu\\) with the Metropolis step. Propose a new value \\(\\mu^*\\) from the normal distribution centered around the current \\(\\mu\\), \\(\\mu' \\sim N(\\mu, \\delta^{-2})\\) and evaluate the acceptance ratio as\n\\[\nR = \\frac{f(y|\\mu', \\tau) f(\\mu'|\\mu_0, \\tau_0)}{f(y|\\mu, \\tau) f(\\mu|\\mu_0, \\tau_0)}\n\\]\naccepting the new value with probability \\(\\min (R, 1)\\).\nSuppose your data is \\(n = 100\\) values from a \\(N(\\mu = 2, \\tau = 1/4)\\) distribution.\n\nset.seed(123)\n\nn &lt;- 100\ny &lt;- rnorm(n, 2, 2)\n\n# Use vague priors\nmu_0 &lt;- 0\ntau_0 &lt;- 10^(-4)\na &lt;- .01\nb &lt;- .01\n\n# Here we go: Metropolis for mu, Gibbs for tau\nITER &lt;- 10^3\n\n# monitors\nmon_mu &lt;- numeric(ITER)\nmon_tau &lt;- numeric(ITER)\n\n# initialize the algorithm\nmu &lt;- mean(y)\ntau &lt;- 1 / var(y)\n\n# width of proposal distribution for mu\ndelta &lt;- .01\n\nfor(i in 1:ITER) {\n  # Mu step.\n  mu_new &lt;- rnorm(1, mu, sd = delta)\n  \n  # log of the acceptance ratio\n  logR &lt;- sum(dnorm(y, mu_new, 1/sqrt(tau), log = T)) - # new likelihood\n          sum(dnorm(y, mu    , 1/sqrt(tau), log = T)) + # old likelihood\n          dnorm(mu_new,mu_0, 1/sqrt(tau_0), log = T)  - # new prior\n          dnorm(mu    ,mu_0, 1/sqrt(tau_0), log = T)    # old prior\n  \n  # accept with probability min(R,1)\n  # draw U from uniform(0,1) and accept if logU &lt; logR\n  # Note: larger delta results in algorithm proposes candidates outside the main\n  # support of the posterior and acceptance rate will be low.\n  logU &lt;- log(runif(1,0,1))\n  if(logU &lt; logR){mu &lt;- mu_new}\n  \n  #### STEP for TAU\n  tau &lt;- rgamma(1, a + n / 2, b + .5 * sum((y - mu)^2))\n  \n  #### UPDATING THE MONITORS:\n  mon_mu[i] &lt;- mu\n  mon_tau[i] &lt;- tau\n}\n\n# Note that if you set delta to .01, there was a lot of autocorrelation in mu\n# and it did not converge. But if you set it to .1 it does a little better.\ntibble(mon_mu, x = 1:ITER) %&gt;% ggplot(aes(x = x, y = mon_mu)) + geom_point()\n\n\n\n\n\n\n\n\nSuppose a study estimates the sex-ratio of bird chicks. From prior studies, you settle on a beta prior \\(p \\sim \\text{Beta}(20, 20)\\) that a chick is female. From a batch of eggs, 5 are male and 1 is female. The number of expected females is \\(x|p \\sim \\text{Bin}(n, p)\\). Using the simple beta-binomial model, the posterior mean for \\(p = \\frac{(a + y)}{(a+y) + (b + (n - y))} = .456\\).\n\n(20 + 1) / ((20 + 1) + (20 + (6 - 1)))\n\n[1] 0.4565217\n\n\nIn this case, the \\(n\\) is also uncertain since some eggs may have been lost. From prior studies you expect \\(n \\sim \\text{Pois}(12)\\). Use MCMC to estimate posterior distributions of \\(p\\) and \\(n\\).\n\nset.seed(12345)\n\n# Data: 5 males and 1 female\ny &lt;- 1\nn &lt;- 6\n\n# Prior distributions: beta(20, 20) for p; derived for n.\na &lt;- 20\nb &lt;- 20\nlambda &lt;- 12\n\n# MCMC algorithm\nITER &lt;- 10^3\np_monitor &lt;- numeric(ITER)\nn_monitor &lt;- numeric(ITER)\n\nfor(i in 1:ITER) {\n  # Sample p.\n  p &lt;- rbeta(1, a + y, b + (n - y))\n  \n  # Sample n\n  n_vals &lt;- 6:25\n  # This distribution was derived for me.\n  n_prob &lt;- (lambda * (1 - p))^n_vals / (factorial(n_vals - 1))\n  n &lt;- sample(n_vals, size = 1, replace = TRUE, n_prob)\n  \n  # Update priors\n  p_monitor[i] &lt;- p\n  n_monitor[i] &lt;- n\n}\n\n# Drop the first 500 observations as burn-in.\n# Posterior mean for n\ntable(n_monitor[501:ITER]) %&gt;% which.max()\n## 8 \n## 3\nmax(table(n_monitor[501:ITER])) / (ITER-501)\n## [1] 0.1923848\n# Posterior mean for p\nmean(p_monitor)\n## [1] 0.4349155\n\n# Check for convergence.\n# p\np1 &lt;- tibble(index = 1:ITER, p = p_monitor) %&gt;% ggplot(aes(x = index, y = p)) + geom_line()\np2 &lt;- tibble(p = p_monitor) %&gt;% ggplot(aes(x = p)) + geom_density()\n# n\np3 &lt;- tibble(index = 1:ITER, n = n_monitor) %&gt;% ggplot(aes(x = index, y = n)) + geom_line()\np4 &lt;- tibble(p = n_monitor) %&gt;% ggplot(aes(x = p)) + geom_histogram(binwidth = 1)\n\n(p1+p2)/(p3+p4)",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#mixed-effects-linear-regression",
    "href": "03-bayesian-statistics.html#mixed-effects-linear-regression",
    "title": "3  Bayesian Statistics",
    "section": "3.11 Mixed Effects Linear Regression",
    "text": "3.11 Mixed Effects Linear Regression\n\nbp &lt;- read_csv(\"./input/BP.csv\", col_types = c(\"iicd\"))\n\nThe basic mixed effects regression model is\n\\[\n\\text{BP}_i = \\beta_0 + \\beta_1 \\text{G}_i + \\xi_{\\text{PID}_i} + \\epsilon_i\n\\]\nwhere \\(G_i\\) is the before/after dummy. \\(\\beta_0\\) is the expected BP before the treatment, \\(\\beta_1\\) is the average population effect, \\(\\xi_{\\text{PID}_i}\\) is the patient-specific deviation in BP from the population mean, and \\(\\epsilon_i\\) is random error. You can group the terms as \\(\\text{BP}_i = (\\beta_0 + \\xi_{\\text{PID}_i}) + \\beta_1 \\text{G}_i + \\epsilon_i\\). You can rewrite this in Bayesian form, \\(\\text{BP}_i | \\mu_i, \\tau_i \\sim N(\\mu_i, \\tau_i)\\) where \\(\\mu_i = \\beta_0 + \\xi_{\\text{PID}_i} + \\beta_1 \\text{G}_i\\).\nIn abscense of other information, use vague priors with large variance, \\(\\beta_0, \\beta_1 \\sim N(0, 10^{-8})\\), and \\(\\tau \\sim \\text{Gamma}(a,b)\\) with \\(a=.01\\) and \\(b = .01\\). What about \\(\\xi\\)? The deviation can be any value, positive or negative, so go with a normal distribution with zero expected value, \\(\\xi_j \\sim N(0, \\tau_\\xi)\\) where \\(j\\) is the patient id with \\(\\tau_\\xi \\sim \\text{Gamma}(a_\\xi, b_\\xi)\\).\n\nlibrary(MCMCglmm)\n\n\nm1 &lt;- MCMCglmm(BP ~ Group, random = ~PID, data = bp, verbose = FALSE)\n\nsummary(m1)\n\n\n Iterations = 3001:12991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: 49.09769 \n\n G-structure:  ~PID\n\n    post.mean l-95% CI u-95% CI eff.samp\nPID     12.69    3.754    26.49    796.7\n\n R-structure:  ~units\n\n      post.mean l-95% CI u-95% CI eff.samp\nunits    0.4678   0.1236    1.002    821.8\n\n Location effects: BP ~ Group \n\n            post.mean l-95% CI u-95% CI eff.samp  pMCMC    \n(Intercept)   138.775  136.322  141.196     1000 &lt;0.001 ***\nGroupBefore     2.251    1.671    2.825     1000 &lt;0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe posterior mean estimated difference in the blood pressure is 2.25 mmHg higher before the treatment than after (95% CI 1.642, 2.917). The pMCMC is not really a p-value (see documentation). Instead, you can get the posterior probability that \\(\\beta_1 &gt; 0\\).\n\nmean(m1$Sol[, 2] &gt; 0)\n\n[1] 1\n\n\nYou can report The treatment was estimated to lower the blood pressure by an average 2.25 mmHg, 95%CI: (1.642, 2.917), P&gt;0.999.\nConvergence diagnostics:\n\nplot(m1$Sol)\n\n\n\n\n\n\n\n\nThe random effects \\(\\xi_{PID}\\) are usually not of interest and not retained. This much was a sloppy, out-of-the-box, fit. You should be explicit about priors, iterations, burn-in, etc.\n\nprior&lt;-list(\n      # mean and variance-covariance matrix for the normal prior on fixed coefficients\n      B=list(mu=c(0,0), V=matrix(c(1000,0,0,1000),2,2)),\n      # and for the residual variance tau and random effect variance tau.xi\n      # this package uses Wishart distribution (not inverse Gamma)\n      R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))\n\nm2 &lt;- MCMCglmm(BP ~ Group, random=~PID, data=bp, verbose=F,\n               nitt=15000, thin = 10, burnin=5000, # iterations, thinning and burn-in\n               pr=TRUE, # save random effects\n               DIC=TRUE, # evaluate the DIC\n               prior=prior\n               )\n\nYou can see the random effects now.\n\ndim(m2$Sol)\n\n[1] 1000   12\n\ntibble(\n  PID = factor(1:10),\n  xi_mean = apply(m2$Sol[, 3:12], 2, mean),\n  xi_lci = apply(m2$Sol[,3:12], 2, quantile, .025),\n  xi_uci = apply(m2$Sol[,3:12], 2, quantile, .975)\n) %&gt;%\n  ggplot(aes(x = PID)) +\n  geom_segment(aes(y = xi_lci, yend = xi_uci, xend = PID)) +\n  geom_point(aes(y = xi_mean)) +\n  geom_abline(aes(intercept = 0, slope = 0), color = \"red\") +\n  labs(title = str_wrap(\n    \"Patient-specific posterior means and credible intervals for deviations in BP from population mean\",\n    80)\n  )\n\n\n\n\n\n\n\n\nYou might now ask how certain we are that participant 2 had a lower BP than participant 4, \\(P(\\xi_2 &lt; \\xi_4 | \\text{data})\\)?\n\nmean(m2$Sol[, 2+2] &lt; m2$Sol[, 2+4])\n\n[1] 1\n\n\nIt’s nearly certain. How about your certainty that participant 2 is the lowest?\n\n# Remove first 2 cols. Apply which.min() to rows. How often is col 2 the min?\nmean(apply(m2$Sol[, -c(1:2)], 1, which.min) == 2)\n\n[1] 0.946",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#appendix-bayes-factors",
    "href": "03-bayesian-statistics.html#appendix-bayes-factors",
    "title": "3  Bayesian Statistics",
    "section": "3.12 Appendix: Bayes Factors",
    "text": "3.12 Appendix: Bayes Factors\nThe Bayes Factor (BF) is a measure of the relative evidence of one model over another. Take another look at Bayes’ formula:\n\\[P(\\theta|D) = \\frac{P(D|\\theta)P(\\theta)}{P(D)}.\\]\nSuppose you want to compare how two models explain and observed data outcome, \\(D\\). Model \\(M_1:f_1(D|\\theta_1)\\) says the observed data \\(D\\) was produced by a generative model with pdf \\(f_1\\) parameterized by \\(\\theta_2\\). Model \\(M_2:f_2(D|\\theta_2)\\) says it was produced by a generative model with pdf \\(f_2\\) parameterized by \\(\\theta_2\\). In each model you specify a prior probability distribution for the parameter\nIf you take the ratio of the posterior probabilities, the posterior odds, the \\(P(D)\\) terms cancel and you have\n\\[\\frac{P(\\theta_1|D)}{P(\\theta_2|D)} = \\frac{P(D|\\theta_1)}{P(D|\\theta_2)} \\cdot \\frac{P(\\theta_1)}{P(\\theta_2)}\\]\nThe posterior odds equals the ratio of the likelihoods multiplied by the prior odds. That likelihood ratio is the Bayes Factor (BF). Rearranging, BF is the odds ratio of the posterior and prior odds.\n\\[BF = \\frac{P(D|\\theta_1)}{P(D|\\theta_2)} = \\mathrm{\\frac{Posterior Odds}{Prior Odds}}\\]\nReturn to the example of observing \\(D\\) = 7 ones and 3 zeros. You can compare an hypothesized \\(\\theta\\) of .5 to a completely agnostic model where \\(\\theta\\) is uniform over [0, 1]. The likelihood of observing \\(D\\) when \\(\\theta\\) = .5 is \\(P(D|\\theta_1) = 5^7(1-.5)^3\\) = 0.117. The likelihood of observing \\(D\\) where \\(\\theta\\) is uniform on [0, 1] is \\(P(D|\\theta_2) = \\int_0^1 \\binom{10}{3}q^7(1-q)^3dq\\)\n\n.5^1 * .5^1\n\n[1] 0.25\n\ndbinom(1, 1, .5)\n\n[1] 0.5\n\ndbinom(11, 11, .5)\n\n[1] 0.0004882812\n\nbeta(11, 11)\n\n[1] 2.577402e-07\n\n\nwith a uniform Beta(1, 1) prior (i.e., complete agnosticism).\nThe Bayes factor at \\(\\theta\\) = .7 quantifies how much the odds of H0: \\(\\theta\\) = .7 over H1: \\(\\hat{\\theta}\\) = .7.\n\nprior &lt;- function(theta, alpha, beta) {\n  (1 / beta(alpha, beta)) * theta^(alpha-1) * (1-theta)^(beta-1)\n}\nposterior &lt;- function(theta, alpha, beta, a, b) {\n  (1 / beta(alpha + a, beta + b)) * theta^(alpha-1+a) * (1-theta)^(beta-1+b)\n}\n\nprior(.5, 115, 85) \n\n[1] 1.164377\n\nposterior(.5, 1, 1, 10, 10)\n\n[1] 3.700138\n\nposterior(.5, 1, 1, 10, 10) / prior(.5, 1, 1) \n\n[1] 3.700138\n\n1 / beta(115, 85)\n\n[1] 4.677704e+59\n\n# Posterior Distribution \n1/beta(1+10, 1+10) * .5^(1-1+10) * (1-.5)^(1-1+10)\n\n[1] 3.700138\n\ndbeta(.5, 11, 11)\n\n[1] 3.700138\n\n# Prior Beta Distributions\n1/beta(1, 1) * .5^(1-1) * (1-.5)^(1-1)\n\n[1] 1\n\ndbeta(.5, 1, 1)\n\n[1] 1\n\ndbeta(.5, 115, 85)\n\n[1] 1.164377\n\n\nThe Bayes factor measures how much your prior belief is altered by the evidence. It is the ratio of the likelihoods at some hypothesized value before and after observing the data. In this case, our confidence increased by a factor of…\n\ntheta &lt;- 0.5\n\nalpha &lt;- 1\nbeta &lt;- 1\na &lt;- 10\nb &lt;- 10\n\n(prior_likelihood &lt;- (1 / beta(alpha, beta)) * theta^(alpha-1) * (1-theta)^(beta-1))\n## [1] 1\n(posterior_likelihood &lt;- (1 / beta(alpha + a, beta + b)) * theta^(alpha-1+a) * (1-theta)^(beta-1+b))\n## [1] 3.700138\n(bayes_factor &lt;- posterior_likelihood / prior_likelihood)\n## [1] 3.700138\n\n# 3.7 on alpha = beta = 1\n# 1.91 on alpha = beta = 4",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#further-reading",
    "href": "03-bayesian-statistics.html#further-reading",
    "title": "3  Bayesian Statistics",
    "section": "3.13 Further Reading",
    "text": "3.13 Further Reading\nMost of my notes are from the two course Bayesian Statistics Using R certificate program instructed by Elena Moltchanova. Elena recommends two books as standard reading material for serious Bayesian students. Bayesian Data Analysis (Gelman 2013) is considered the definitive textbook on the topic. Statistical rethinking: A Bayesian course with examples in R and Stan (McElreath 2020) is a more friendly introduction to Bayesian statistics.\n\n\n\n\n\n\nGelman, Andrew. 2013. Bayesian Data Analysis. 3rd ed. Chapman & Hall. https://www.amazon.com/Bayesian-Analysis-Chapman-Statistical-Science-ebook-dp-B00I60M6H6/dp/B00I60M6H6/ref=mt_other?_encoding=UTF8&me=&qid=.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and STAN. 2nd ed. Chapman & Hall. https://xcelab.net/rm/statistical-rethinking/.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "03-bayesian-statistics.html#footnotes",
    "href": "03-bayesian-statistics.html#footnotes",
    "title": "3  Bayesian Statistics",
    "section": "",
    "text": "dbinom(seq(1, 100, 1), 100, .5) sums to 1, but dnorm(seq(0,50,.001), 10, 10) sums to 841.↩︎\nSome of these notes are from DataCamp course Fundamentals of Bayesian Data Analysis in R.↩︎\nThe gamma function is a generic function, just like sin, cos, etc., and is a kind of generalized factorial.↩︎\nIn Bayesian statistics, the normal distribution is parameterized with the inverse of variance, called the precision, \\(\\tau = 1 / \\sigma^2\\).↩︎",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html",
    "href": "04-one-sample.html",
    "title": "4  One-Sample",
    "section": "",
    "text": "4.1 One-Sample Mean z Test\nUse one-sample tests to either describe a single variable’s frequency or central tendency, or to compare the frequency or central tendency to a hypothesized distribution or value.\nIf the data generating process produces continuous outcomes (interval or ratio), and the outcomes are symmetrically distributed, the sample mean, \\(\\bar{x}\\), is a random variable centered at the population mean, \\(\\mu\\). You can then use a theoretical distribution (normal or student t) to estimate a 95% confidence interval (CI) around \\(\\mu\\), or compare \\(\\bar{x}\\) to an hypothesized population mean, \\(\\mu_0\\). If you (somehow) know the population variance, or the Central Limit Theorem (CLT) conditions hold, you can assume the random variable is normally distributed and use the z-test, otherwise assume the random variable has student t distribution and use the t-test.1 If the data generating process produces continuous outcomes that are not symmetrically distributed, use a non-parametric test like the Wilcoxon median test.\nIf the data generating process produces discrete outcomes (counts), the sample count, \\(x\\), is a random variable from a Poisson, binomial, normal, or multinomial distribution, or a random variable from a theoretical outcome. Whatever the source of the expected values, you use either the chi-squared goodness-of-fit test or G test to test whether the observed values fit the expected values from the distribution. In the special case of binary outcomes with small (n &lt; 1,000), you can use Fisher’s exact test instead. The discrete variable tests are discussed in PSU STATS 504.\nThe z test is also called the normal approximation z test. It only applies when the sampling distribution of the population mean is normally distributed with known variance, and there are no significant outliers. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem. The t test returns similar results, plus it is valid when the variance is unknown, and that is pretty much always. For that reason, you probably will never use this test.\nUnder the normal approximation method, the measured mean \\(\\bar{x}\\) approximates the population mean \\(\\mu\\), and the sampling distribution has a normal distribution centered at \\(\\mu\\) with standard error \\(se_\\mu = \\frac{\\sigma}{\\sqrt{n}}\\) where \\(\\sigma\\) is the standard deviation of the underlying population. Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm z_{(1 - \\alpha) {/} 2} se_\\mu\\), or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}\\).",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#one-sample-mean-z-test",
    "href": "04-one-sample.html#one-sample-mean-z-test",
    "title": "4  One-Sample",
    "section": "",
    "text": "Example\nThe mtcars data set is a sample of n = 32 cars. The mean fuel economy is \\(\\bar{x} \\pm s\\) = 20.1 \\(\\pm\\) 6.0 mpg. The prior measured overall fuel economy for vehicles was \\(\\mu_0 \\pm \\sigma\\) = 18.0 \\(\\pm\\) 6.0 mpg. Has fuel economy improved?\nThe sample size is \\(\\ge\\) 30, so the sampling distribution of the population mean is normally distributed. The population variance is known, so use the z test.\n\\(H_0: \\mu = 16.0\\), and \\(H_a: \\mu &gt; 16.0\\) - a right-tail test. The test statistic is \\(Z = \\frac{\\bar{x} - \\mu_0}{se_\\mu}=\\) 1.97 where \\(se_{\\mu_0} = \\frac{\\mu_0}{\\sqrt{n}} =\\) 1.06. \\(P(z &gt; Z) =\\) 0.0244, so reject \\(H_0\\) at the \\(\\alpha =\\) 0.05 level of significance.\n\n\n\n\n\n\n\n\n\nThe 95% confidence interval for \\(\\mu\\) is \\(\\bar{x} \\pm z_{(1 - \\alpha){/}2} se_\\mu\\) where \\(z_{(1 - \\alpha){/}2} =\\) 1.96. \\(\\mu =\\) 20.09 \\(\\pm\\) 2.08 (95% CI 18.01 to 22.17).",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#one-sample-mean-t-test",
    "href": "04-one-sample.html#one-sample-mean-t-test",
    "title": "4  One-Sample",
    "section": "4.2 One-Sample Mean t Test",
    "text": "4.2 One-Sample Mean t Test\nThe one-sample t test applies when the sampling distribution of the population mean is normally distributed and there are no significant outliers. Unlike the z test, the population variance can be unknown. The sampling distribution is normally distributed when the underlying population is normally distributed, or when the sample size is large \\((n &gt;= 30)\\), as follows from the central limit theorem.\nUnder the t test method, the measured mean, \\(\\bar{x}\\), approximates the population mean, \\(\\mu\\). The sample standard deviation, \\(s\\), estimates the unknown population standard deviation, \\(\\sigma\\). The resulting sampling distribution has a t distribution centered at \\(\\mu\\) with standard error \\(se_\\bar{x} = \\frac{s}{\\sqrt{n}}\\). Define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} se_\\bar{x}\\) and/or test \\(H_0: \\mu = \\mu_0\\) with test statistic \\(T = \\frac{\\bar{x} - \\mu_0}{se_\\bar{x}}\\).\n\nExample\nA researcher recruits a random sample of n = 40 people to participate in a study about depression intervention. The researcher measures the participants’ depression level prior to the study. The mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population ‘normal’ depression score of 4.0. The null hypothesis is that the sample is representative of the overall population. Should you reject \\(H_0\\)?\n\ndep %&gt;% gtsummary::tbl_summary(statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n\n\nCharacteristic\nN = 401\n\n\n\n\ndep_score\n3.72 (0.74)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\n\nConditions\nThe one-sample t test applies when the variable is continuous and the observations are independent. Additionally, there are two conditions related to the data distribution. If either condition fails, try the suggested work-arounds or use the non-parametric [Wilcoxon 1-Sample Median Test for Numeric Var] instead.\n\nOutliers. There should be no significant outliers. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data.\nNormality. Values should be nearly normally distributed (“nearly” because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data.\n\n\nOutliers\nAssess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually. The boxplot shows no outliers.\n\n\n\n\n\n\n\n\n\nIf the outliers might are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you have a couple options before reverting to Wilcoxon.\n\nTransform the variable. Don’t do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult.\nLeave it in if it doesn’t affect the conclusion (compared to taking it out).\n\n\n\nNormality\nAssume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, asses a Q-Q plot, skewness and kurtosis values, or a histogram. If you still don’t feel confident about normality, run a [Shapiro-Wilk Test].\nThe data set has n = 40 observations, so you can assume normality. Here is a QQ plot anyway. The QQ plot indicates normality.\n\ndep %&gt;%\n  ggplot(aes(sample = dep_score)) +\n  stat_qq() +\n  stat_qq_line(col = \"goldenrod\") +\n  theme_minimal() +\n  labs(title = \"Normal Q-Q Plot\")\n\n\n\n\n\n\n\n\nHere is the Shapiro-Wilk normality test. It fails to reject the null hypothesis of a normally distributed population.\n\nshapiro.test(dep$dep_score)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dep$dep_score\nW = 0.98446, p-value = 0.8474\n\n\nIf the data is not normally distributed, you still have a couple options before reverting to Wilcoxon.\n\nTransform the dependent variable.\nCarry on regardless - the one-sample t-test is fairly robust to deviations from normality.\n\n\n\n\nResults\nConduct the t-test. To get a 95% CI around the difference (instead of around the estimate), run the test using the difference, \\(\\mu_0 - \\bar{x}\\), and leave mu at its default of 0.\n\n(dep_95ci &lt;- t.test(x = mu_0 - dep$dep_score, alternative = \"two.sided\", conf.level = .95))\n\n\n    One Sample t-test\n\ndata:  mu_0 - dep$dep_score\nt = 2.3811, df = 39, p-value = 0.02224\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.04176615 0.51323385\nsample estimates:\nmean of x \n   0.2775 \n\n\nThe difference is statistically different from 0 at the p = .05 level. The effect size, called Cohen’s d, is defined as \\(d = |M_D| / s\\), where \\(|M_D| = \\bar{x} - \\mu_0\\), and \\(s\\) is the sample standard deviation. \\(d &lt;.2\\) is considered trivial, \\(.2 \\le d &lt; .5\\) small, and \\(.5 \\le d &lt; .8\\) large.\n\n(d &lt;- rstatix::cohens_d(dep, dep_score ~ 1, mu = 4) %&gt;% pull(effsize) %&gt;% abs())\n\nCohen's d \n0.3764788 \n\n\nCohen’s d is 0.38, a small effect.\nMake a habit of constructing a plot, just to make sure your head is on straight.\n\n\n\n\n\n\n\n\n\nNow you are ready to report the results.\n\nA one-sample t-test was run to determine whether depression score in recruited subjects was different from normal, as defined as a depression score of 4.0. Depression scores were normally distributed, as assessed by Shapiro-Wilk’s test (p &gt; .05) and there were no outliers in the data, as assessed by inspection of a boxplot. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Mean depression score (3.72 \\(\\pm\\) 0.74) was lower than the population “normal” depression score of 4.00, a statistically significant difference of 0.28 (95% CI, 0.04 to 0.51), t(39) = 2.38, p = 0.022, d = 0.38.\n\n\n\nAppendix: Deciding Sample Size\nDetermine the sample size required for a maximum error \\(\\epsilon\\) in the estimate by solving the confidence interval equation, \\(\\bar{x} \\pm t_{(1 - \\alpha){/}2} \\frac{s}{\\sqrt{n}}\\) for \\(n=\\frac{{t_{\\alpha/2,n-1}^2se^2}}{{\\epsilon^2}}\\) . Unfortunately, \\(t_{\\alpha/2,n-1}^2\\) is dependent on \\(n\\), so replace it with \\(z_{\\alpha/2}^2\\). What about \\(s^2\\)? Estimate it from the literature, a pilot study, or using the empirical rule that 95% of the range falls within two standard deviations, \\(s=range / 4\\).\nFor example, if the maximum tolerable error is* \\(\\epsilon\\) = 3, and \\(s\\) is approximately 10, what sample size produces an \\(\\alpha\\) =0.05 confidence level?\n\nceiling(qnorm(.975)^2 * 10^2 / 3^2)\n\n[1] 43",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#one-sample-median-wilcoxon-test",
    "href": "04-one-sample.html#one-sample-median-wilcoxon-test",
    "title": "4  One-Sample",
    "section": "4.3 One-Sample Median Wilcoxon Test",
    "text": "4.3 One-Sample Median Wilcoxon Test\nThe Wilcoxon one-sample median test (aka Wilcoxon signed rank test) is a non-parametric alternative to the t-test for cases when the the sampling distribution of the population mean is not normally distributed, but is at least symmetric.\nUnder the Wilcoxon test, the measured median, \\(\\eta_x\\), approximates the population median, \\(\\eta\\). The method calculates the difference between each value and the hypothesized median, \\(\\eta_0\\), ranks the difference magnitudes, then sums the ranks for the negative and the positive differences, \\(W+\\) and \\(W-\\). The test compares the smaller of the two sums to a table of critical values.\nHere is a case study. A store claims their checkout wait times are \\(\\le\\) 4 minutes. You challenge the claim by sampling 6 checkout experiences. The mean wait time was 4.6, but the data may violate normality.\n\ndata.frame(wait = wait) %&gt;%\n  ggplot(aes(sample = wait)) +\n  stat_qq() +\n  stat_qq_line(col = \"goldenrod\") +\n  theme_minimal() +\n  labs(title = \"Normal Q-Q Plot\")\n\n\n\n\n\n\n\n\nShapiro-Wilk rejects the null hypothesis of a normally distributed population.\n\nshapiro.test(wait)\n\n\n    Shapiro-Wilk normality test\n\ndata:  wait\nW = 0.75105, p-value = 0.0204\n\n\nUse the Wilcoxon test instead.\n\n(wt &lt;- wilcox.test(wait, mu = 4, alternative = \"greater\"))\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  wait\nV = 14.5, p-value = 0.2309\nalternative hypothesis: true location is greater than 4\n\n\n\nA Wilcoxon Signed-Ranks Test indicated that wait times were not statistically significantly higher than the 4-minute claim, z = 14.5, p = 0.231.",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#chi-squared-goodness-of-fit-test",
    "href": "04-one-sample.html#chi-squared-goodness-of-fit-test",
    "title": "4  One-Sample",
    "section": "4.4 Chi-Squared Goodness-of-Fit Test",
    "text": "4.4 Chi-Squared Goodness-of-Fit Test\nUse the chi-squared goodness-of-fit test to test whether the observed frequency counts, \\(O_j\\), of the \\(J\\) levels of a categorical variable differ from the expected frequency counts, \\(E_j\\). \\(H_0\\) is \\(O_j = E_j\\). You can use this test for dichotomous, nominal, or ordinal variables. There are only two conditions to use this test:\n\nthe observations are independent, meaning either random assignment or random sampling without replacement from &lt;10% of the population, and\nthe expected frequency in each group is &gt;=5.\n\nThe Pearson goodness-of-fit test statistic is\n\\[X^2 = \\sum \\frac{(O_j - E_j)^2}{E_j}\\]\nwhere \\(O_j = p_j n\\) and \\(E_j = \\pi_j n\\). The sampling distribution of \\(X^2\\) approaches the \\(\\chi_{J-1}^2\\) as the sample size \\(n \\rightarrow \\infty\\). The assumption that \\(X^2\\) is distributed \\(\\sim \\chi^2\\) is not quite correct, so you will see researchers subtract .5 from the differences to increase the p-value, the so-called Yates Continuity Correction.\n\\[X^2 = \\sum \\frac{(O_j - E_j - 0.5)^2}{E_j}\\]\n\\(X^2 \\rightarrow 0\\) as the saturated model (the observed data represent the fit of the saturated model, the most complex model possible with the data) proportions approach the expected proportions, \\(p_j \\rightarrow \\pi_j\\). The chi-squared test calculates the probability of the occurrence of \\(X^2\\) at least as extreme given that it is a chi-squared random variable with degrees of freedom equal to the number of levels of the variable minus one, \\(J-1\\).\n\nExample with Theoretical Values\nA researcher crosses tall cut-leaf tomatoes with dwarf potato-leaf tomatoes, then classifies the n = 1,611 offspring’s phenotype. The four phenotypes should occur with relative frequencies 9:3:3:1. The observed frequencies constitute a one-way table.\nIf you only care about one level (or if the variable is binary) of if, conduct a one-proportion Z-test or an exact binomial test. Otherwise, conduct an exact multinomial test (recommended when n &lt;= 1,000), Pearson’s chi-squared goodness-of-fit test, or a G-test.\n\n\n\n\n\n\n\n\n\n\n\nConditions\nThis is a randomized experiment. The minimum expected frequency was 100, so the chi-squared test of independence is valid.\nHad the data violated the \\(\\ge\\) 5 condition, you could run an exact test (like the binomial, or in this case, the multinomial), or lump some factor levels together.\n\n\nResults\nYou can calculate \\(X^2\\) by hand, and find the probability of a test statistic at least as extreme using the \\(\\chi^2\\) distribution with 4-1 = 3 degrees of freedom.\n\n(pheno_x2 &lt;- sum((pheno_obs - pheno_exp)^2 / pheno_exp))\n## [1] 9.54652\n(pheno_p &lt;- pchisq(q = pheno_x2, df = length(pheno_type) - 1, lower.tail = FALSE))\n## [1] 0.02284158\n\nThat is what chisq.test() does. The function applies the Yates continuity correction by default, so I had to specify correct = FALSE to exclude it. In this case, setting it to TRUE has almost no effect because the sample size is large.\n\n(pheno_chisq_test &lt;- chisq.test(pheno_obs, p = pheno_pi, correct = FALSE))\n\n\n    Chi-squared test for given probabilities\n\ndata:  pheno_obs\nX-squared = 9.5465, df = 3, p-value = 0.02284\n\n\nAs always, plot the distribution.\n\n\n\n\n\n\n\n\n\nAt this point you can report,\n\nOf the 1,611 offspring produced from the cross-fertiliation, 956 were tall cut-leaf, 258 were tall potato-leaf, 293 where dwarf cut-leaf, and 104 were dwarf potato-leaf. A chi-square goodness-of-fit test was conducted to determine whether the offspring had the same proportion of phenotypes as the theoretical distribution. The minimum expected frequency was 101. The chi-square goodness-of-fit test indicated that the number of tall cut-leaf, tall potato-leaf, dwarf cut-leaf, and dwarf potato-leaf offspring was statistically significantly different from the proportions expected in the theoretical distribution (\\(X^2\\)(3) = 9.547, p = 0.023).\n\nIf you reject \\(H_0\\), inspect the residuals to learn which differences contribute most to the rejection. Notice how \\(X^2\\) is a sum of squared standardized cell differences, or “Pearson residuals”,\n\\[r_i = \\frac{o_j - e_j}{\\sqrt{e_j}}\\]\nCells with the largest \\(|r|\\) contribute the most to the total \\(X^2\\).\n\npheno_chisq_test$residuals^2 / pheno_chisq_test$statistic\n\n    tall cut-leaf  tall potato-leaf    dwarf cut-leaf dwarf potato-leaf \n       0.28682269        0.67328098        0.02848093        0.01141540 \n\n\nThe two “tall” cells contributed over 95% of the \\(X^2\\) test statistic, with the tall potato-leaf accounting for 67%. This aligns with what you’d expect from the bar plot.\n\n\nExample with Theoretical Distribution\nYou need to reduce the degrees of freedom (df) in the chi-squared goodness-of-fit test by 1 if you test whether the data conform to a particular distribution instead of a set of theoretical values.\n\nj &lt;- c(0:5)\no &lt;- c(19, 26, 29, 13, 10, 3)\nchildr_n &lt;- as.character(0:5)\n\nSuppose you sample n = 100 families and count the number of children. The count of children is a Poisson random variable, \\(J\\), with maximum likelihood estimate \\(\\hat{\\lambda} = \\sum{j_i O_i} / \\sum{O_i}\\). Test whether the observed values can be described as samples from a Poisson random variable. The probabilities for each possible count are\n\\[f(j; \\lambda) = \\frac{e^{-\\hat{\\lambda}} \\hat{\\lambda}^j}{j!}.\\]\n\n\n\n\n\n\n\n\n\n\n\nConditions\nThis is random sampling. The minimum expected frequency was 2, so the data violates the \\(\\ge\\) 5 rule. Lump the last two categories into “4-5”.\n\n\n\n\n\n\n\n\n\nThe minimum expected frequency was 6, so now the chi-squared test of independence is valid.\n\n\nResults\nCompare the expected values to the observed values with the chi-squared goodness of fit test, but in this case \\(df = 5 - 1 - 1\\) because the estimated parameter \\(\\lambda\\) reduces df by 1. You cannot set df in chisq.test(), so perform the test manually.\n\n(X2 &lt;- sum((o - e)^2 / e))\n## [1] 7.092968\n(p.value &lt;- pchisq(q = X2, df = length(j) - 1 - 1, lower.tail = FALSE))\n## [1] 0.06899286\n\n\n\n\n\n\n\n\n\n\nAt this point you can report,\n\nOf the 100 families sampled, 19 had no children, 26 had one child, 29 had two children, 13 had three children, and 13 had 4 or 5 children. A chi-square goodness-of-fit test was conducted to determine whether the observed family sizes follow a Poisson distribution. The minimum expected frequency was 13. The chi-square goodness-of-fit test indicated that the number of children was not statistically significantly different from the proportions expected in the Poisson distribution (\\(X^2\\)(3) = 7.093, p = 0.069).",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#g-test",
    "href": "04-one-sample.html#g-test",
    "title": "4  One-Sample",
    "section": "4.5 G-Test",
    "text": "4.5 G-Test\nThe G-test is a likelihood-ratio statistical significance test increasingly used instead of chi-squared tests. The test statistic is defined\n\\[G^2 = 2 \\sum O_j \\log \\left[ \\frac{O_j}{E_j} \\right]\\]\nwhere the 2 multiplier asymptotically aligns with the chi-squared test formula. G is distributed \\(\\sim \\chi^2\\), with the same number of degrees of freedom as in the corresponding chi-squared test. In fact, the chi-squared test statistic is a second order Taylor expansion of the natural logarithm around 1.\nReturning to the phenotype case study in the chi-squared goodness-of-fit test section, you can calculate the \\(G^2\\) test statistic and probability by hand.\n\n(pheno_g2 &lt;- 2 * sum(pheno_obs * log(pheno_obs / pheno_exp)))\n## [1] 9.836806\n(pchisq(q = pheno_g2, df = length(pheno_type) - 1, lower.tail = FALSE))\n## [1] 0.02000552\n\nThis is pretty close to the \\(X^2\\) = 9.547, p = 0.023 using the chi-squared goodness-of-fit test. The DescTools::GTest() function to conducts a G-test.\n\nDescTools::GTest(pheno_obs, p = pheno_pi)\n\n\n    Log likelihood ratio (G-test) goodness of fit test\n\ndata:  pheno_obs\nG = 9.8368, X-squared df = 3, p-value = 0.02001\n\n\nAccording to the function documentation, the G-test is not usually used for 2x2 tables.\n\nEMT::multinomial.test(o, f, useChisq = TRUE)\n\n\nchisq.test(o, e)\n\n\n    Pearson's Chi-squared test\n\ndata:  o and e\nX-squared = 15, df = 12, p-value = 0.2414",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#one-sample-poisson-test",
    "href": "04-one-sample.html#one-sample-poisson-test",
    "title": "4  One-Sample",
    "section": "4.6 One-Sample Poisson Test",
    "text": "4.6 One-Sample Poisson Test\nIf \\(X\\) is the number of successes in \\(n\\) (many) trials when the probability of success \\(\\lambda / n\\) is small, then \\(X\\) is a random variable with a Poisson distribution, and the probability of observing \\(X = x\\) successes is\n\\[f(x;\\lambda) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\hspace{1cm} x \\in (0, 1, ...), \\hspace{2mm} \\lambda &gt; 0\\]\nwith \\(E(X)=\\lambda\\) and \\(Var(X) = \\lambda\\) where \\(\\lambda\\) is estimated by the sample \\(\\hat{\\lambda}\\),\n\\[\\hat{\\lambda} = \\sum_{i=1}^N x_i / n.\\]\nPoisson sampling is used to model counts of events that occur randomly over a fixed period of time. You can use the Poisson distribution to perform an exact test on a Poisson random variable.\n\nExample\nYou are analyzing goal totals from a sample consisting of the 95 matches in the first round of the 2002 World Cup. The average match produced a mean/sd of 1.38 \\(\\pm\\) 1.28 goals, lower than the 1.5 historical average. Should you reject the null hypothesis that the sample is representative of typical values?\n\n\nConditions\n\nThe events must be independent of each other. In this case, the goal-count in one match has no effect on goal-counts in other matches.\nThe expected value of each event must be the same (homogeneity). In this case, the expected goal-count of each match is the same regardless of which teams are playing. This assumption is often dubious, causing the distribution variance to be larger than the mean, a conditional called over-dispersion.\n\nYou might also check whether the data is consistent with a Poisson model. This is random sampling, but the data violates the \\(\\ge\\) 5 rule because the minimum expected frequency was 0. To comply with the minimum frequency rule, lump the last six categories into “3-8”.\n\n\n\n\n\n\n\n\n\nThe minimum expected frequency was 15, so now the chi-squared test of independence is valid. Compare the expected values to the observed values with the chi-squared goodness of fit test, but in this case \\(df = 4 - 1 - 1\\) because the estimated parameter \\(\\lambda\\) reduces the df by 1. You cannot set df in chisq.test(), so perform the test manually.\n\n(X2 &lt;- sum((o - e)^2 / e))\n## [1] 0.8618219\n(p.value &lt;- pchisq(q = X2, df = length(j) - 1 - 1, lower.tail = FALSE))\n## [1] 0.6499168\n\n\n\n\n\n\n\n\n\n\n\nOf the 95 World Cup matches, 23 had no goals, 37 had one goal, 20 had two goals, and 15 had 3-8 goals. A chi-square goodness-of-fit test was conducted to determine whether the observed goal counts follow a Poisson distribution. The minimum expected frequency was 15. The chi-square goodness-of-fit test indicated that the number of goals scored was not statistically significantly different from the frequencies expected from a Poisson distribution (\\(X^2\\)(2) = 0.862, p = 0.650).\n\n\n\nResults\nThe conditions for the exact Poisson test were met, so go ahead and run the test.\n\n(pois_val &lt;- poisson.test(\n  x = sum(dat_pois$goals * dat_pois$freq), \n  T = sum(dat_pois$freq), \n  r = 1.5)\n)\n\n\n    Exact Poisson test\n\ndata:  sum(dat_pois$goals * dat_pois$freq) time base: sum(dat_pois$freq)\nnumber of events = 131, time base = 95, p-value = 0.3567\nalternative hypothesis: true event rate is not equal to 1.5\n95 percent confidence interval:\n 1.152935 1.636315\nsample estimates:\nevent rate \n  1.378947 \n\n\nConstruct a plot showing the 95% CI around the hypothesized value. For a Poisson distribution, I built the distribution around the expected value, \\(n\\lambda\\), not the rate, \\(\\lambda\\).\n\n\n\n\n\n\n\n\n\nI think you could report these results like this.\n\nA one-sample exact Poisson test was run to determine whether the number of goals scored in the first round of the 2002 World Cup was different from past World Cups, 1.5. A chi-square goodness-of-fit test indicated that the number of goals was not statistically significantly different from the counts expected in the Poisson distribution (\\(X^2\\)(2) = 0.862, p = 0.650). Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Mean goals scored (1.38 \\(\\pm\\) 1.28) was lower than the historical mean of 1.50, but was not statistically significantly different (95% CI, 1.15 to 1.64), p = 0.357.",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#exact-binomial-test",
    "href": "04-one-sample.html#exact-binomial-test",
    "title": "4  One-Sample",
    "section": "4.7 Exact Binomial Test",
    "text": "4.7 Exact Binomial Test\nThe Clopper-Pearson exact binomial test is precise, but theoretically complicated in that it inverts two single-tailed binomial tests (No theory here - I’ll just rely on the software). Use the exact binomial test if you have a small sample size or an extreme success/failure probability that invalidates the chi-square and G tests. The exact binomial also applies when you have a one-tail test. The exact binomial test has two conditions:\n\nindependence, and\nat least \\(n\\pi \\ge 5\\) successes or \\(n(1−\\pi)\\ge 5\\) failures.\n\nYou can use this test for multinomial variables too, but the test only compares a single level’s proportion to a hypothesized value.\n\nExample\nA pharmaceutical company claims its drug reduces fever in &gt;60% of cases. In a random sample of n = 40 cases the drug reduces fever in 20 cases. Do you reject the claim?\nYou are testing \\(P(x \\le 20)\\) in n = 40 trials when p = 60%, a one-tail test. The sample is a random assignment experiment with 20&gt;5 successes and 20&gt;5 failures, so it meets the conditions for the exact binomial test.\n\nbinom.test(20, 40, p = 0.6, alternative = \"greater\")\n\n\n    Exact binomial test\n\ndata:  20 and 40\nnumber of successes = 20, number of trials = 40, p-value = 0.9256\nalternative hypothesis: true probability of success is greater than 0.6\n95 percent confidence interval:\n 0.3610917 1.0000000\nsample estimates:\nprobability of success \n                   0.5 \n\n\nThe exact binomial test uses the “method of small p-values”, in which the probability of observing a proportion \\(p\\) as far or further from \\(\\pi_0\\) is the sum of all \\(P(X=p_i)\\) where \\(p_i &lt;= p\\).\n\nmap_dbl(dbinom(0:20, 40, 0.6), ~if_else(. &lt;= 0.5, ., 0)) %&gt;% sum()\n\n[1] 0.1297657\n\n\nThat is what pbinom() does.\n\npbinom(q = 20, size = 40, p = 0.6, lower.tail = TRUE)\n\n[1] 0.1297657\n\n\nA 95% confidence interval means 95% of confidence intervals constructed from a random sample of the population will contain the true population proportion. There are several methods to calculate a binomial confidence interval2 binom.test() uses the Clopper-Pearson interval. This method calculates lower (\\(P_L\\)) and upper (\\(P_U\\)) limits that satisfy\n\\[\n\\begin{eqnarray}\n\\sum_{x=n_1}^n \\binom{n}{x} p_L^x(1 - p_L)^{n-x} &=& \\alpha/2\\\\\n\\sum_{x=0}^{n_1} \\binom{n}{x} p_U^x(1 - p_U)^{n-x} &=& \\alpha/2\n\\end{eqnarray}\n\\]\nwhere \\(n_i\\) is the measured successes in \\(n\\) trials. For a one-tail test, the confidence interval is calculated with the right side equaling 0 and \\(/alpha\\) instead of \\(\\alpha/2\\). A right-tailed 95% confidence interval means 95% of confidence intervals will contain a lower limit that is less than the true population proportion. If you wanted to construct a confidence interval around the population proportion, use a two-sided test.\n\nbinom.test(20, 40, p = 0.6, alternative = \"two.sided\")\n\n\n    Exact binomial test\n\ndata:  20 and 40\nnumber of successes = 20, number of trials = 40, p-value = 0.2007\nalternative hypothesis: true probability of success is not equal to 0.6\n95 percent confidence interval:\n 0.3380178 0.6619822\nsample estimates:\nprobability of success \n                   0.5 \n\n\nIf you just wanted to know whether 20 successes in 40 trials is compatible with a population proportion of 60%, then you could use the chi-squared goodness-of-fit test.\n\nchisq.test(x = c(20, 20), p = c(0.6, 0.4), correct = FALSE)\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(20, 20)\nX-squared = 1.6667, df = 1, p-value = 0.1967",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#one-sample-proportion-z-test",
    "href": "04-one-sample.html#one-sample-proportion-z-test",
    "title": "4  One-Sample",
    "section": "4.8 One-Sample Proportion z Test",
    "text": "4.8 One-Sample Proportion z Test\nThe z-test uses the sample proportion of group \\(j\\), \\(p_j\\), as an estimate of the population proportion \\(\\pi_j\\) to evaluate an hypothesized population proportion \\(\\pi_{0j}\\) and/or construct a \\((1−\\alpha)\\%\\) confidence interval around \\(p_j\\) to estimate \\(\\pi_j\\) within a margin of error \\(\\epsilon\\).\nThe z-test is intuitive to learn, but it only applies when the central limit theorem conditions hold:\n\nthe sample is independently drawn, meaning random assignment (experiments), or random sampling without replacement from &lt;10% of the population (observational studies),\nthere are at least 5 successes and 5 failures,\nthe sample size is &gt;=30, and\nthe expected probability of success is not extreme, between 0.2 and 0.8.\n\nIf these conditions hold, the sampling distribution of \\(\\pi\\) is normally distributed around \\(p\\) with standard error \\(se_p = \\frac{s_p}{\\sqrt{n}} = \\frac{\\sqrt{p(1−p)}}{\\sqrt{n}}\\). The measured values \\(p\\) and \\(s_p\\) approximate the population values \\(\\pi\\) and \\(\\sigma_\\pi\\). You can define a \\((1 − \\alpha)\\%\\) confidence interval as \\(p \\pm z_{\\alpha / 2}se_p\\). Test the hypothesis of \\(\\pi = \\pi_0\\) with test statistic \\(z = \\frac{p − \\pi_0}{se_{\\pi_0}}\\) where \\(se_{\\pi_0} = \\frac{s_{\\pi_0}}{\\sqrt{n}} = \\frac{\\sqrt{{\\pi_0}(1−{\\pi_0})}}{\\sqrt{n}}\\).\n\nExample\nA machine is supposed to randomly churn out prizes in 60% of boxes. In a random sample of n = 40 boxes there are prizes in 20 boxes. Is the machine flawed?\n\nprop.test(20, 40, 0.6, \"two.sided\", correct = FALSE)\n\n\n    1-sample proportions test without continuity correction\n\ndata:  20 out of 40, null probability 0.6\nX-squared = 1.6667, df = 1, p-value = 0.1967\nalternative hypothesis: true p is not equal to 0.6\n95 percent confidence interval:\n 0.3519953 0.6480047\nsample estimates:\n  p \n0.5 \n\n\nThe first thing you’ll notice is that prop.test() performs a chi-squared goodness-of-fit test, not a one-proportion Z-test!\n\nchisq.test(c(20, 40-20), p = c(.6, .4), correct = FALSE)\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(20, 40 - 20)\nX-squared = 1.6667, df = 1, p-value = 0.1967\n\n\nIt turns out \\(P(\\chi^2 &gt; X^2)\\) equals \\(2 \\cdot P(Z &gt; z).\\) Here is the manual calculation of the chi-squared test statistic \\(X^2\\) and resulting p-value on 1 dof.\n\npi_0 &lt;- .6\np &lt;- 20 / 40\n\nobserved &lt;- c(p, 1-p) * 40\nexpected &lt;- c(pi_0, 1-pi_0) * 40\n\nX2 &lt;- sum((observed - expected)^2 / expected)\npchisq(X2, 1, lower.tail = FALSE)\n\n[1] 0.1967056\n\n\nAnd here is the manual calculation of the Z-test statistic \\(z\\) and resulting p-value.\n\nse &lt;- sqrt(pi_0*(1-pi_0)) / sqrt(40)\nz &lt;- (p - pi_0) / se\npnorm(z, lower.tail = TRUE) * 2\n\n[1] 0.1967056\n\n\nThe 95% CI presented by prop.test() is also not the \\(p \\pm z_{\\alpha / 2}se_p\\) Wald interval; it is the Wilson interval!\n\nDescTools::BinomCI(20, 40, method = \"wilson\")\n\n     est    lwr.ci    upr.ci\n[1,] 0.5 0.3519953 0.6480047\n\n\nThere are a lot of methods (see ?DescTools::BinomCI), and Wilson is the one Agresti-Coull recommends. If you want Wald, use DescTools::BinomCI() with method = \"wald\".\n\nDescTools::BinomCI(20, 40, method = \"wald\")\n\n     est    lwr.ci    upr.ci\n[1,] 0.5 0.3450512 0.6549488\n\n\nThis matches the manual calculation below.\n\nz_crit = qnorm(1 - .05/2)\nse &lt;- sqrt(p*(1-p)) / sqrt(40)\n\n(CI &lt;- c(p - z_crit*se, p + z_crit*se))\n\n[1] 0.3450512 0.6549488\n\n\nprop.test() (and chissq.test()) reported a p-value of 0.1967056, so you cannot reject the null hypothesis that \\(\\pi = 0.6\\). It’s good practice to plot this out to make sure your head is on straight.\n\n\n\n\n\n\n\n\n\nIncidentally, if you have a margin of error requirement, you can back into the required sample size to achieve it. Just solve the margin of error equation \\(\\epsilon  = z_{\\alpha/2}^2 = \\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}\\) for \\(n = \\frac{z_{\\alpha/2}^2 \\pi_0(1-\\pi_0)}{\\epsilon^2}.\\)",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#sample-t-test-for-categorical-var",
    "href": "04-one-sample.html#sample-t-test-for-categorical-var",
    "title": "4  One-Sample",
    "section": "4.9 1 sample t Test for Categorical Var",
    "text": "4.9 1 sample t Test for Categorical Var\nThis test applies when you do not know the population variance.",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#wilcoxon-1-sample-median-test-for-categorical-var",
    "href": "04-one-sample.html#wilcoxon-1-sample-median-test-for-categorical-var",
    "title": "4  One-Sample",
    "section": "4.10 Wilcoxon 1-Sample Median Test for Categorical Var",
    "text": "4.10 Wilcoxon 1-Sample Median Test for Categorical Var\nThis test applies when the variable is not normally distributed.",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#multivariate-statistics",
    "href": "04-one-sample.html#multivariate-statistics",
    "title": "4  One-Sample",
    "section": "4.11 Multivariate Statistics",
    "text": "4.11 Multivariate Statistics\nThe t-tests and analysis of variance tests have multivariate analogs. Multivariate statistics apply when multiple variables are simultaneously analyzed. Hotellings’s T^2 extends the independent samples t-test and MANOVA extends ANOVA to cases where there are two or more dependent variables (e.g., do math, science, and reading scores depend on students’ anxiety level?).\nThe mean of variable \\(j\\) is the average of row vector \\(X_j\\), \\(\\bar{x}_j = \\frac{1}{n} \\sum_{i = 1}^n X_{ij}\\). \\(\\bar{x}_j\\) estimates the population mean, \\(\\mu_j = E(X_j)\\). The collection of means is a column vector, \\(\\bar{\\mathbf{x}}\\) estimating \\(\\boldsymbol{\\mu}\\).\nThe variance of variable \\(j\\) is the average squared difference from the mean for row vector \\(X_j\\), \\(s_j^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar{x}_j)^2\\). It estimates the population variance, \\(\\sigma_j^2 = E(X_j - \\mu_j)^2\\). The collection of variances is a column vector, \\(\\mathbf{s}^2\\) estimating \\(\\boldsymbol{\\sigma}^2\\).\nThe covariance of variables \\(j\\) and \\(k\\) is the average product of differences from their respective means, \\(s_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar{x}_j) (X_{ik} - \\bar{x}_k)\\). It estimates the population covariance, \\(\\sigma_{jk} = E\\{ (X_{ij} - \\mu_j) (X_{ik} - \\mu_k)\\}\\). The generalization across the entire matrix is the variance-covariance matrix, \\(\\textbf{S}\\) which estimates \\(\\boldsymbol{\\Sigma}\\).\n\\(\\bar{\\mathbf{x}}\\) is a function of random data, so it is also a random vector with a sampling distribution mean and variance-covariance matrix. The variance of the sample mean is \\(V(\\bar{\\mathbf{x}}) = \\frac{\\textbf{S}}{n}\\). It estimates the variance of the population mean, \\(V(\\bar{\\mathbf{x}}) = \\frac{\\boldsymbol{\\Sigma}}{n}\\). If the samples are taken from a normal distribution or the sample size is large, the sampling distribution is approximately normal, \\(\\bar{\\textbf{x}} \\sim N \\left(\\boldsymbol{\\mu}, \\frac{\\boldsymbol{\\Sigma}}{n} \\right)\\).\nThe joint estimate of confidence intervals (CIs) around a multivariate set of population means is complicated by how the individual variables are treated.\n\nOne at a time intervals. The \\(1 - \\alpha\\) CI is \\(\\bar{x}_j \\pm t_{n-1}(\\alpha / 2) \\frac{s_j}{\\sqrt{n}}\\).\nBonferroni method. A family of confidence intervals has a family-wide error rate of at least one CI not capturing its population mean equal to the sum of the individual error rates. The Bonferroni method divides \\(\\alpha\\) by the \\(p\\) variables in the family, so the \\(1 - \\alpha\\) CI is \\(\\bar{x}_j \\pm t_{n-1}(\\alpha / 2p) \\frac{s_j}{\\sqrt{n}}\\).\nSimultaneous confidence region. This method considers the family of all possible linear combinations of the population means. The \\(1 - \\alpha\\) CI is \\(\\bar{x}_j \\pm \\sqrt{\\frac{p(n-1)}{n-p} F_{p, n-p}(\\alpha)} \\frac{s_j}{\\sqrt{n}}\\).\n\nQuick Example.\n\n# Suppose you have p = 3 variables with mean and sd as follows.\np &lt;- 3\nn &lt;- c(25, 25, 25)\nM &lt;- c(.84390, 1.79268, .70440)\nSD &lt;- c(.11402, .28347, .10756)\nSE &lt;- SD / sqrt(n)\n\n# One at a time margins of error\n(prob &lt;- 1 - .05/2)\n## [1] 0.975\n(mult &lt;- qt(prob, n-1))\n## [1] 2.063899 2.063899 2.063899\n(ME &lt;- mult * SE)\n## [1] 0.04706514 0.11701067 0.04439859\n\n# Bonferonni\n(prob &lt;- 1 - .05/(2*p))\n## [1] 0.9916667\n(mult &lt;- qt(prob, n-1))\n## [1] 2.573641 2.573641 2.573641\n(ME &lt;- mult * SE)\n## [1] 0.05868931 0.14591000 0.05536417\n\n# Simultaneous\n(mult &lt;- sqrt((p * (n-1) / (n-p)) * qf(.95, p, n-p)))\n## [1] 3.158948 3.158948 3.158948\n(ME &lt;- mult * SE)\n## [1] 0.07203666 0.17909342 0.06795530",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "04-one-sample.html#footnotes",
    "href": "04-one-sample.html#footnotes",
    "title": "4  One-Sample",
    "section": "",
    "text": "The t-test returns nearly the same result as the z-test when the CLT holds, so in practice no one bothers with the z-test except as an aid to teach the t-test.↩︎\nWikipedia.↩︎",
    "crumbs": [
      "Point Estimates",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-Sample</span>"
    ]
  },
  {
    "objectID": "pt1-group-differences.html",
    "href": "pt1-group-differences.html",
    "title": "Group Differences",
    "section": "",
    "text": "This section discusses statistical tests of comparison. Select the test that based on the data structure.\nContinuous (interval or ratio) and Ordinal Outcomes\n\nCompare a continuous dependent variable between the two levels of a binomial independent variable with an independent samples t-test (5.1 Independent Samples t-Test). Revert to the nonparametric Wilcoxon rank sum test (5.2 Wilcoxon Rank Sum Test) if the t-test assumptions fail.\nA special case arises when samples are paired. Paired samples are more like one-sample tests where the dependent variable is the difference between the pairs. Use the Paired Samples t-test (6  Paired Samples t-Test) or the nonparametric Wilcoxon signed-rank test (6.1 Wilcoxon Signed-Rank Test).\nIf the independent categorical variable is multinomial, conduct an ANOVA (7.1 One-way ANOVA) test or the nonparametric Kruskal-Wallis test (7.2 Kruskal–Wallis Test).\n\nDiscrete (count) Outcomes\n\nCompare the proportions of a binomial outcome between two levels of a nominal independent variable with a two-sample z-test (8.1 Two Proportion Z-Test), chi-squared test of homogeneity (8.2 Chi-Square Test of Homogeneity), or Fisher’s Exact test (8.3 Fisher’s Exact Test).\nThe Chi-square test of homogeneity (9.1 Chi-Square Test of Homogeneity) is the main way to compare a discrete dependent variable among the levels of a binomial or multinomial independent categorical variable. Revert to the nonparametric Fisher’s Exact Test (9.2 Fisher’s Exact Test) if the sample size is small. Handle the special case of paired samples with the Pairwise Prop Test (10.1 Pairwise Prop Test) or the nonparametric McNemar’s test (10.2 McNemar’s Test).",
    "crumbs": [
      "Group Differences"
    ]
  },
  {
    "objectID": "05-continuous-binomial.html",
    "href": "05-continuous-binomial.html",
    "title": "5  Continuous ~ Binomial",
    "section": "",
    "text": "5.1 Independent Samples t-Test\nIf a population measure X is normally distributed with mean \\(\\mu_X\\) and variance \\(\\sigma_X^2\\), and a population measure Y is normally distributed with mean \\(\\mu_Y\\) and variance \\(\\sigma_Y^2\\), then their difference is normally distributed with mean \\(d = \\mu_X - \\mu_Y\\) and variance \\(\\sigma_{XY}^2 = \\sigma_X^2 + \\sigma_Y^2\\). By the CLT, as sample sizes grow, non-normally distributed X and Y approach normality, and so do their difference.\nThe independent samples t-test compares an hypothesized difference, \\(d_0\\) (H0: \\(d = d_0\\)), with a sample means difference, \\(\\hat{d} = \\bar{x} - \\bar{y}\\), or constructs a (1 - \\(\\alpha\\))% confidence interval around \\(\\hat{d}\\) to estimate \\(d\\) within a margin of error, \\(\\epsilon\\).\nIn principal, you can evaluate \\(\\hat{d}\\) with either a z-test or a t-test. Both require independent samples and approximately normal sampling distributions. Sampling distributions are normal if the underlying populations are normally distributed, or if the sample sizes are large (\\(n_X\\) and \\(n_Y\\) \\(\\ge\\) 30). However, the z-test additionally requires known sampling distribution variances, \\(\\sigma^2_X\\) and \\(\\sigma^2_Y\\). These variances are never known, so always use the t-test.\nThe z-test assumes \\(d\\) is normally distributed around \\(\\hat{d} = d\\) with standard error \\(SE = \\sqrt{\\frac{\\sigma_X^2}{n_X} + \\frac{\\sigma_Y^2}{n_Y}}.\\) The test statistic for H0: \\(d = d_0\\) is \\(Z = \\frac{\\hat{d} - d_0}{SE}\\). The (1 - \\(\\alpha\\))% CI is \\(d = \\hat{d} \\pm z_{(1 - \\alpha {/} 2)} SE\\).\nThe t-test assumes \\(d\\) has a t-distribution around \\(\\hat{d} = d\\) with standard error \\(SE = \\sqrt{\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}}.\\) The test statistic for H0: \\(d = d_0\\) is \\(T = \\frac{\\hat{d} - d_0}{SE}\\). The (1 - \\(\\alpha\\))% CI iss \\(d = \\hat{d} \\pm t_{(1 - \\alpha / 2), (n_X + n_Y - 2)} SE\\).\nThere is a complication with the t-test SE and degrees of freedom. If the sample sizes are small and the standard deviations from each population are similar (the ratios of \\(s_X\\) and \\(s_Y\\) are &lt;2), pool the variances, \\(s_p^2 = \\frac{(n_X - 1) s_X^2 + (n_Y-1) s_Y^2}{n_X + n_Y-2}\\), so that \\(SE = s_p \\sqrt{\\frac{1}{n_X} + \\frac{1}{n_Y}}\\) and the degrees of freedom (df) = \\(n_X + n_Y - 2\\) (the pooled variances t-test). Otherwise, \\(SE = \\sqrt{\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}}\\), but you reduce df using the Welch-Satterthwaite correction, \\(df = \\frac{\\left(\\frac{s_X^2}{n_X} + \\frac{s_Y^2}{n_Y}\\right)^2}{\\frac{s_X^4}{n_X^2\\left(N_X-1\\right)} + \\frac{s_Y^4}{n_Y^2\\left(N_Y-1\\right)}}\\) (the separate variance t-test, or Welch’s t-test).",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous ~ Binomial</span>"
    ]
  },
  {
    "objectID": "05-continuous-binomial.html#sec-wilcoxonranksum",
    "href": "05-continuous-binomial.html#sec-wilcoxonranksum",
    "title": "5  Continuous ~ Binomial",
    "section": "5.2 Wilcoxon Rank Sum Test",
    "text": "5.2 Wilcoxon Rank Sum Test\nThe Wilcoxon rank sum test1 is a nonparametric alternative to the independent-samples t-test. Use the the test when the samples are not normally distributed or when the response variables are ordinal rather continuous. In the first case where the normality assumption fails, the test evaluates H0 that the two samples are from the same population distribution. In the second case where the response variables are ordinal, the test evaluates the difference in medians.\nThe Wilcoxon Rank Sum test ranks the response values, then sums the ranks for the reference group, \\(W = \\sum R_1\\). The test statistic is \\(U = W - \\frac{n_2(n_2 + 1)}{2}\\) where \\(n_2\\) is the number of observations in the test group. \\(U\\) will equal 0 if there is complete separation between the groups, and \\(n_1 n_2\\) if there is complete overlap. Reject H0 if \\(U\\) is sufficiently small.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous ~ Binomial</span>"
    ]
  },
  {
    "objectID": "05-continuous-binomial.html#case-study",
    "href": "05-continuous-binomial.html#case-study",
    "title": "5  Continuous ~ Binomial",
    "section": "5.3 Case Study",
    "text": "5.3 Case Study\nA company shows an advertisement to \\(n_M\\) = 20 males and \\(n_F\\) = 20 females, then measures their engagement with a survey. Do the groups’ mean engagement scores differ?\nLaerd has two data sets for this example. One meets the conditions for a t-test, and the other fails the normality test, forcing you to use the Mann-Whitney U test.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe t-test data set has the following summary statistics.\n\n(ind_num$t_gt &lt;- ind_num$t_dat %&gt;% \n  gtsummary::tbl_summary(\n    by = c(gender), \n    statistic = list(all_continuous() ~ \"{mean} ({sd})\")\n  ))\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMale\nN = 201\nFemale\nN = 201\n\n\n\n\nengagement\n5.56 (0.29)\n5.30 (0.39)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\nThere were 20 male and 20 female participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. The advertisement was more engaging to male viewers, 5.56 (0.29), than female viewers, 5.30 (0.39).\n\nThe Mann-Whitney data set has the following summary statistics.\n\n(ind_num$mw_gt &lt;- ind_num$mw_dat %&gt;% \n  gtsummary::tbl_summary(\n    by = c(gender), \n    statistic = list(all_continuous() ~ \"{mean} ({sd})\")\n  ))\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMale\nN = 201\nFemale\nN = 201\n\n\n\n\nengagement\n5.56 (0.35)\n5.43 (0.53)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\nThere were 20 male and 20 female participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. The advertisement was more engaging to male viewers, 5.56 (0.35), than female viewers, 5.43 (0.53).\n\n\nConditions\nThe independent samples t-test and Mann-Whitney U test apply when 1) the response variable is continuous, 2) the independent variable is binomial, and 3) the observations are independent. The decision between the t-test and Mann-Whitney stems from two additional conditions related to the data distribution - if both conditions hold, use the t-test; otherwise use Mann-Whitney.\n\nOutliers. There should be no outliers in either group. Outliers exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them or transform the data.\nNormality. Values should be nearly normally distributed. The t-test is robust to normality, but this condition is important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data.\n\nIf the data passes the two conditions, use the t-test, but now you need to check a third condition related to the variances to determine which flavor of the t-test to use.\n\nHomogeneous Variances. Use pooled-variances if the variances are homogeneous; otherwise use the separate variances method. Test with Levene’s test of equality of variances.\n\nIf the data does not pass the first two conditions, use Mann-Whitney, but now you need to check a third condition here as well. The condition does not affect how to perform the test, but rather how to interpret the results.\n\nDistribution shape. If the distributions have the same shape, interpret the Mann-Whitney result as a comparison of the medians; otherwise interpret the result as a comparison of the mean ranks.\n\n\nChecking for Outliers\nAssess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually.\n\n\n\n\n\n\n\n\n\nFor the t test data set,\n\nThere were no outliers in the data, as assessed by inspection of a boxplot.\n\nand for the Mann-Whitney data set,\n\nThere was one outlier in the data, as assessed by inspection of a boxplot.\n\nIf the outliers are data entry errors or measurement errors, fix or discard them. If the outliers are genuine, you have a couple options before reverting to the Mann-Whitney U test.\n\nLeave it in if it doesn’t affect the conclusion (compared to taking it out).\nTransform the variable. Don’t do this unless the variable is also non-normal. Transformation also has the downside of making interpretation more difficult.\n\n\n\nChecking for Normality\nAssume the population is normally distributed if n \\(\\ge\\) 30. Otherwise, assess a Q-Q plot, skewness and kurtosis values, or a histogram. If you still don’t feel confident about normality, run a Shapiro-Wilk test.\nThere are only \\(n_M\\) = 20 male and \\(n_F\\) = 20 female observations, so you need to test normality. The QQ plot indicates normality in the t-test data set, but not in the Mann-Whitney data set.\n\nbind_rows(\n  `t-test` = ind_num$t_dat,\n  `Mann-Whitney` = ind_num$mw_dat,\n  .id = \"set\"\n) %&gt;%\n  ggplot(aes(sample = engagement, group = gender, color = fct_rev(gender))) +\n  stat_qq() +\n  stat_qq_line(col = \"goldenrod\") +\n  theme_minimal() + theme(legend.position = \"top\") +\n  facet_wrap(~fct_rev(set)) +\n  labs(title = \"Normal Q-Q Plot\", color = NULL)\n\n\n\n\n\n\n\n\nRun Shapiro-Wilk separately for the males and for the females. Since we are looking at two data sets in tandem, there are four tests below. For the t-test data set,\n\n(ind_num$t_shapiro &lt;- split(ind_num$t_dat, ind_num$t_dat$gender) %&gt;% \n  map(~shapiro.test(.$engagement))\n)\n\n$Male\n\n    Shapiro-Wilk normality test\n\ndata:  .$engagement\nW = 0.98344, p-value = 0.9705\n\n\n$Female\n\n    Shapiro-Wilk normality test\n\ndata:  .$engagement\nW = 0.96078, p-value = 0.5595\n\n\n\nEngagement scores for each level of gender were normally distributed, as assessed by Shapiro-Wilk’s test (p &gt; .05).\n\nFor the Mann-Whitney data set,\n\n(ind_num$mw_shapiro &lt;- split(ind_num$mw_dat, ind_num$mw_dat$gender) %&gt;% \n  map(~shapiro.test(.$engagement))\n)\n\n$Male\n\n    Shapiro-Wilk normality test\n\ndata:  .$engagement\nW = 0.98807, p-value = 0.9946\n\n\n$Female\n\n    Shapiro-Wilk normality test\n\ndata:  .$engagement\nW = 0.8354, p-value = 0.003064\n\n\n\nEngagement scores for each level of gender were not normally distributed for the Female sample, as assessed by Shapiro-Wilk’s test (p = 0.003).\n\nIf the data is not normally distributed, you still have a couple options before reverting to the Mann-Whitney U test.\n\nTransform the dependent variable.\nCarry on regardless - the independent samples t-test is fairly robust to deviations from normality.\n\n\n\nChecking for Homogenous Variances\nIf the data passed the outliers and normality tests, you will use the t-test, so now you need to test the variances to see which version (pooled-variances method if variances are homogeneous; separate variances if variances are heterogeneous). A rule of thumb is that homogeneous variances have a ratio of standard deviations between 0.5 and 2.0:\n\nsd(ind_num$t_dat %&gt;% filter(gender == \"Male\") %&gt;% pull(engagement)) /\n  sd(ind_num$t_dat %&gt;% filter(gender == \"Female\") %&gt;% pull(engagement))\n\n[1] 0.7419967\n\n\nYou can also use the F test to compare the ratio of the sample variances \\(\\hat{r} = s_X^2 / s_Y^2\\) to an hypothesized ratio of population variances \\(r_0 = \\sigma_X^2 / \\sigma_Y^2 = 1.\\)\n\nvar.test(ind_num$t_dat %&gt;% filter(gender == \"Female\") %&gt;% pull(engagement), \n         ind_num$t_dat %&gt;% filter(gender == \"Male\") %&gt;% pull(engagement))\n\n\n    F test to compare two variances\n\ndata:  ind_num$t_dat %&gt;% filter(gender == \"Female\") %&gt;% pull(engagement) and ind_num$t_dat %&gt;% filter(gender == \"Male\") %&gt;% pull(engagement)\nF = 1.8163, num df = 19, denom df = 19, p-value = 0.2025\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.7189277 4.5888826\nsample estimates:\nratio of variances \n          1.816336 \n\n\nBartlett’s test is another option.\n\nbartlett.test(ind_num$t_dat$engagement, ind_num$t_dat$gender)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  ind_num$t_dat$engagement and ind_num$t_dat$gender\nBartlett's K-squared = 1.6246, df = 1, p-value = 0.2024\n\n\nLevene’s test is a third option. Levene’s is less sensitive to departures from normality than Bartlett.\n\n(ind_num$levene &lt;- with(ind_num$t_dat, \n                        car::leveneTest(engagement, gender, center = \"mean\"))\n)\n\nLevene's Test for Homogeneity of Variance (center = \"mean\")\n      Df F value Pr(&gt;F)\ngroup  1   1.922 0.1737\n      38               \n\n\n\nThere was homogeneity of variances for engagement scores for males and females, as assessed by Levene’s test for equality of variances (p = 0.174).\n\n\n\nChecking for Similar Distributions\nIf the data fail either the outliers or the normality test, use the Mann-Whitney test. The Mann-Whitney data set failed both, so the Mann-Whitney test applies. Now you need to test the distributions to determine how to interpret its results. If the distributions are similarly shaped, interpret the Mann-Whitney U test as inferences about differences in medians between the two groups. If the distributions are dissimilar, interpret the test as inferences about the distributions, lower/higher scores and/or mean ranks.\n\n\n\n\n\n\n\n\n\n\nDistributions of the engagement scores for males and females were similar, as assessed by visual inspection.\n\n\n\n\nTest\nConduct the t-test or the Mann-Whitney U test.\n\nt-Test\nThe the t-test data the variances were equal, so the pooled-variances version applies (t.test(var.equal = TRUE)).\n\n(ind_num$t_test &lt;- t.test(engagement ~ gender, data = ind_num$t_dat, var.equal = TRUE))\n\n\n    Two Sample t-test\n\ndata:  engagement by gender\nt = 2.3645, df = 38, p-value = 0.02327\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n 0.03725546 0.48074454\nsample estimates:\n  mean in group Male mean in group Female \n            5.558875             5.299875 \n\n\n\nThere was a statistically significant difference in mean engagement score between males and females, with males scoring higher than females, 0.26 (95% CI, 0.04 to 0.48), t(38) = 2.365, p = 0.023.\n\nThe effect size, Cohen’s d, is defined as \\(d = |M_D| / s\\), where \\(|M_D| = \\bar{x} - \\bar{y}\\), and \\(s\\) is the pooled sample standard deviation, \\(s_p = \\sqrt{\\frac{(n_X - 1) s_X^2 + (n_Y-1) s_Y^2}{n_X + n_Y-2}}\\). \\(d &lt;.2\\) is considered trivial, \\(.2 \\le d &lt; .5\\) small, and \\(.5 \\le d &lt; .8\\) large.\n\n(d &lt;- effectsize::cohens_d(engagement ~ gender, data = ind_num$t_dat, pooled_sd = TRUE))\n\nCohen's d |       95% CI\n------------------------\n0.75      | [0.10, 1.39]\n\n- Estimated using pooled SD.\n\n\n\nThere was a large difference in mean engagement score between males and females, Cohen’s d = 0.75 95% CI [0.10, 1.39]\n\nBefore rejecting the null hypothesis, construct a plot as a sanity check.\n\n\n\n\n\n\n\n\n\n\n\nWilcoxon Rank Sum test\nThe reference level for the gender variable is males, so the Wilcoxon Rank Sum test statistic is the sum of male ranks minus \\(n_f(n_f + 1) / 2\\) where \\(n_f\\) is the number of females. You can calculate the test statistic by hand.\n\n(ind_num$mw_test_manual &lt;- ind_num$mw_dat %&gt;% \n  mutate(R = rank(engagement)) %&gt;%\n  group_by(gender) %&gt;%\n  summarize(.groups = \"drop\", n = n(), R = sum(R), meanR = sum(R)/n()) %&gt;%\n  pivot_wider(names_from = gender, values_from = c(n, R, meanR)) %&gt;%\n  mutate(U = R_Male - n_Female * (n_Female + 1) / 2))\n\n# A tibble: 1 × 7\n  n_Male n_Female R_Male R_Female meanR_Male meanR_Female     U\n   &lt;int&gt;    &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1     20       20    465      355       23.2         17.8   255\n\n\nCompare the test statistic to the Wilcoxon rank sum distribution with pwilcox().\n\npwilcox(\n  q = ind_num$mw_test_manual[1, ]$U - 1, \n  m = ind_num$mw_test_manual[1, ]$n_Male, \n  n = ind_num$mw_test_manual[1, ]$n_Male, \n  lower.tail = FALSE\n) * 2\n\n[1] 0.141705\n\n\nThere is a function for all this.\n\n(ind_num$mw_test &lt;- wilcox.test(\n  engagement ~ gender, \n  data = ind_num$mw_dat, \n  exact = TRUE, \n  correct = FALSE,\n  conf.int = TRUE))\n\n\n    Wilcoxon rank sum exact test\n\ndata:  engagement by gender\nW = 255, p-value = 0.1417\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -0.055  0.420\nsample estimates:\ndifference in location \n                0.1925 \n\n\n\nMedian engagement score was not statistically significantly different between males and females, U = 255, p = 0.142, using an exact sampling distribution for U.\n\nNow you are ready to report the results. Here is how you would report the t test.\n\nData are mean \\(\\pm\\) standard deviation, unless otherwise stated. There were 20 male and 20 female participants. An independent-samples t-test was run to determine if there were differences in engagement to an advertisement between males and females. There were no outliers in the data, as assessed by inspection of a boxplot. Engagement scores for each level of gender were normally distributed, as assessed by Shapiro-Wilk’s test (p &gt; .05), and there was homogeneity of variances, as assessed by Levene’s test for equality of variances (p = 0.174). The advertisement was more engaging to male viewers (5.56 \\(\\pm\\) = 0.29) than female viewers (5.30 \\(\\pm\\) = 0.39), a statistically significant difference of 0.26 (95% CI, 0.04 to 0.48), t(38) = 2.365, p = 0.023, d = 0.75.\n\nHere is how you would report the Mann-Whitney U-Test.\n\nA Mann-Whitney U test was run to determine if there were differences in engagement score between males and females. Distributions of the engagement scores for males and females were similar, as assessed by visual inspection. Median engagement score for males (5.58) and females (5.38) was not statistically significantly different, U = 255, p = 0.142, using an exact sampling distribution for U.\n\nHad the distributions differed, you would report the Mann-Whitney like this:\n\nA Mann-Whitney U test was run to determine if there were differences in engagement score between males and females. Distributions of the engagement scores for males and females were not similar, as assessed by visual inspection. Engagement scores for males (mean rank = 23.25) and females (mean rank = 17.75) were not statistically significantly different, U = 255, p = 0.142, using an exact sampling distribution for U.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous ~ Binomial</span>"
    ]
  },
  {
    "objectID": "05-continuous-binomial.html#footnotes",
    "href": "05-continuous-binomial.html#footnotes",
    "title": "5  Continuous ~ Binomial",
    "section": "",
    "text": "The Mann-Whitney U test is also called the Mann-Whitney U test, Wilcoxon-Mann-Whitney test, and the two-sample Wilcoxon test↩︎",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous ~ Binomial</span>"
    ]
  },
  {
    "objectID": "06-continuous-binomial-pairwise.html",
    "href": "06-continuous-binomial-pairwise.html",
    "title": "6  Paired Samples t-Test",
    "section": "",
    "text": "6.1 Wilcoxon Signed-Rank Test\nThere are two common study designs that employ a paired samples t-test to compare two related groups. One relates the groups as two time points for the same subjects. The second relates the groups as two tests of the same subjects, e.g. comparing reaction time under two lighting conditions.\nThe paired samples t-test uses the mean of sampled paired differences \\(\\bar{d}\\) as an estimate of the mean of the population paired differences \\(\\delta\\) to evaluate an hypothesized mean \\(\\delta_0\\). Test \\(H_0: \\delta = \\delta_0\\) with test statistic \\(T = \\frac{\\bar{d} - \\delta_0}{se}\\), or define a \\((1 - \\alpha)\\%\\) confidence interval as \\(\\delta = \\bar{d} \\pm t_{1 - \\alpha / 2, n - 1} se\\). The paired t-test is really just a one-sample mean t-test operating on variable that is defined as the difference between two variables.\nThe paired samples t test applies when the sampling distribution of the mean of the population paired differences is normally distributed and there are no significant outliers.\nThe Wilcoxon signed-rank test is a nonparametric alternative to the paired-samples t-test for cases in which the paired differences fails the normality condition, but is at least symmetrically distributed.\nThe test statistic is the sum product of the difference signs (-1, +1) and the rank of the difference absolute values, \\(W = \\sum_{i=1}^n sign (d_i) \\cdot R_i\\). The more differences that are of one sign, or of extreme magnitude, the larger \\(W\\) is likely to be, and the more likely to reject \\(H_0\\) of equality of medians.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Paired Samples t-Test</span>"
    ]
  },
  {
    "objectID": "06-continuous-binomial-pairwise.html#sec-wilcoxonsignedrank",
    "href": "06-continuous-binomial-pairwise.html#sec-wilcoxonsignedrank",
    "title": "6  Paired Samples t-Test",
    "section": "",
    "text": "Sign Test\nThe sign test is an alternative to the Wilcoxon signed-rank test for cases in which the paired differences fails the symmetrical distribution condition.\nThe test statistic is the count of pairs whose difference is positive, \\(W = cnt(d_i &gt; 0)\\). \\(W \\sim b(n, 0.5)\\), so the sign test is really just an exact binomial test (exact sign test), or for large n-size, the normal approximation to the binomial (sign test).",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Paired Samples t-Test</span>"
    ]
  },
  {
    "objectID": "06-continuous-binomial-pairwise.html#case-study-2",
    "href": "06-continuous-binomial-pairwise.html#case-study-2",
    "title": "6  Paired Samples t-Test",
    "section": "Case Study 2",
    "text": "Case Study 2\n\\(n\\) = 20 athletes consume a carb-only or carb+protein drink prior to running as far as possible in 2 hours and a researcher records their distances under each condition. Do the distances differ from 0?\nLaerd has three data sets for this example. One meets the conditions for a t-test. The second fails the normality condition, but is symmetric and meets the conditions for the Wilcoxon test. The third fails the symmetry condition and requires the sign test.\n\nt-test data set\n\n(drink$t_gt &lt;- drink$t_dat %&gt;% \n  gtsummary::tbl_summary(statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n)\n\n\n\n\n\n\n\nCharacteristic\nN = 201\n\n\n\n\ncarb\n11.17 (0.73)\n\n\ncarb_protein\n11.30 (0.71)\n\n\ndiff\n0.14 (0.10)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\nThere were 20 participants. Data are mean \\(\\pm\\) standard deviation, unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.30 (0.71) km, than the carbohydrate-only drink, 11.17 (0.73) km.\n\n\n\nWilcoxon data set\nOnce you learn you need Wilcoxon or the sign-test, show the median and IQR summary statistics instead.\n\n(drink$wilcoxon_gt &lt;- drink$wilcoxon_dat %&gt;% \n  gtsummary::tbl_summary()\n)\n\n\n\n\n\n\n\nCharacteristic\nN = 201\n\n\n\n\ncarb\n11.28 (10.38, 11.77)\n\n\ncarb_protein\n11.37 (10.87, 11.84)\n\n\ndiff\n0.19 (-0.11, 0.48)\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n\n\nThere were 20 participants. Data are medians and IQR unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.37 (10.87, 11.84) km, than the carbohydrate-only drink, 11.28 (10.38, 11.77) km.\n\n\n\nSign data set\n\n(drink$sign_gt &lt;- drink$sign_dat %&gt;% \n  gtsummary::tbl_summary()\n)\n\n\n\n\n\n\n\nCharacteristic\nN = 201\n\n\n\n\ncarb\n11.11 (10.41, 11.54)\n\n\ncarb_protein\n11.37 (10.87, 11.84)\n\n\ndiff\n0.23 (0.11, 0.55)\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n\n\nThere were 20 participants. Data are median and IQR unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.37 (10.87, 11.84) km, than the carbohydrate-only drink, 11.11 (10.41, 11.54) km.\n\n\n\nConditions\nThe paired samples t test applies when the variable is continuous and partitioned into dependent pairs, Additionally, there are two conditions related to the data distribution. If either condition fails, consider the suggested work-around or move to the nonparametric alternatives.\n\nOutliers. There should be no outliers in the differences because they exert a large influence on the mean and standard deviation. Test with a box plot. If there are outliers, you might be able to drop them if they do not affect the conclusion, or you can transform the data.\nNormality. Differences should be nearly normally distributed (“nearly” because the t-test is robust to the normality assumption). This condition is especially important with small sample sizes. Test with Q-Q plots or the Shapiro-Wilk test for normality. If the data is very non-normal, you might be able to transform the data.\n\n\nOutliers\nAssess outliers with a box plot. Box plot whiskers extend up to 1.5*IQR from the upper and lower hinges and outliers (beyond the whiskers) are are plotted individually.\n\n\n\n\n\n\n\n\n\n\nThere were no outliers in the data, as assessed by inspection of a boxplot.\n\nHad there been outliers, you might report\n\nX outliers were detected. Inspection of their values did not reveal them to be extreme and they were kept in the analysis.\n\nIf the outliers are data entry errors or measurement errors, fix them or discard them. If the outliers are genuine, you can try leaving them in or transforming the data.\n\n\nNormality\nAssume the population is normally distributed if n \\(\\ge\\) 30. These data sets have n = 20 observations, so you cannot assume normality. Asses a Q-Q plot, skewness and kurtosis values, histogram, or Shapiro-Wilk test.\n\n\n\n\n\n\n\n\n\nFor the t-test data set,\n\n(drink$t_shapiro &lt;- shapiro.test(drink$t_dat$diff))\n\n\n    Shapiro-Wilk normality test\n\ndata:  drink$t_dat$diff\nW = 0.97119, p-value = 0.7797\n\n\n\nThe differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were normally distributed, as assessed by Shapiro-Wilk’s test (p = 0.780).\n\nFor the Wilcoxon data set,\n\n(drink$wilcoxon_shapiro &lt;- shapiro.test(drink$wilcoxon_dat$diff))\n\n\n    Shapiro-Wilk normality test\n\ndata:  drink$wilcoxon_dat$diff\nW = 0.87077, p-value = 0.01212\n\n\n\nThe differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were not normally distributed, as assessed by Shapiro-Wilk’s test (p = 0.012).\n\nFor the sign-test data set,\n\n(drink$sign_shapiro &lt;- shapiro.test(drink$sign_dat$diff))\n\n\n    Shapiro-Wilk normality test\n\ndata:  drink$sign_dat$diff\nW = 0.8968, p-value = 0.03593\n\n\n\nThe differences between the distance ran in the carbohydrate-only and carbohydrate-protein trial were not normally distributed, as assessed by Shapiro-Wilk’s test (p = 0.036).\n\nIf the data is normally distributed, use the t-test. If not, you try transforming the dependent variable, or carrying on regardless since the t-test is fairly robust to deviations from normality.\n\n\nSymmetric Distribution\nIf the data passed the outliers test, but failed the normality test, as the Wilcoxon and sign test data sets above did, you will use the Wilcoxon signed-rank test or sign test. Now you need to test the distribution to determine which test. If the distribution is symmetric, use Wilcoxon; otherwise use the sign test.\n\n\n\n\n\n\n\n\n\nFor the Wilcoxon data set,\n\nThe distribution of the differences between the carbohydrate-protein drink and the carbohydrate-only was symmetric, as assessed by visual inspection.\n\nFor the sign data set,\n\nThe distribution of the differences between the carbohydrate-protein drink and the carbohydrate-only was not asymmetric, as assessed by visual inspection.\n\n\n\n\nTest\n\nt-test\n\n(drink$t_t &lt;- t.test(x = drink$t_dat$carb_protein, y = drink$t_dat$carb, paired = TRUE)\n)\n\n\n    Paired t-test\n\ndata:  drink$t_dat$carb_protein and drink$t_dat$carb\nt = 6.3524, df = 19, p-value = 4.283e-06\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.09085492 0.18014508\nsample estimates:\nmean difference \n         0.1355 \n\n\n\nThe carbohydrate-protein drink elicited an increase of 0.135 (95% CI, 0.091 to 0.180) km in the distance run in two hours compared to a carbohydrate-only drink.\n\nThe effect size, called Cohen’s d, is the number of standard deviations the measured mean difference is from the hypothesized difference, \\((\\bar{d}-d_0) / s\\), where \\(s\\) is the sample standard deviation. .2 is small, .5 is medium, and .8 is large. This one is large.\n\n(drink$t_d &lt;- effectsize::cohens_d(drink$t_dat$diff))\n\nCohen's d |       95% CI\n------------------------\n1.42      | [0.78, 2.04]\n\n\nYou are about to reject the null hypothesis. Construct a plot as a sanity check on your reasoning.\n\n\n\n\n\n\n\n\n\nReport the results.\n\nA paired-samples t-test was used to determine the effect of a new formula of sports drink on running performance. Instead of the regular, carbohydrate-only drink, the new sports drink contains a new carbohydrate-protein mixture. Twenty participants were recruited to the study who each performed two trials in which they had to run as far as possible in two hours on a treadmill. In one of the trials they drank the carbohydrate-only drink and in the other trial they drank the carbohydrate-protein drink. The order of the trials was counterbalanced and the distance they ran in both trials was recorded.\nTwo outliers were detected that were more than 1.5 box-lengths from the edge of the box in a boxplot. Inspection of their values did not reveal them to be extreme and they were kept in the analysis. The assumption of normality was not violated, as assessed by Shapiro-Wilk’s test (p = 0.780).\nData are mean \\(\\pm\\) standard deviation, unless otherwise stated. Participants ran further after consuming the carbohydrate-protein drink, 11.30 (0.71) km, than the carbohydrate-only drink, 11.17 (0.73) km, a statistically significant increase of 0.135 (95% CI, 0.091 to 0.180) km, t(19) = 6.352, p = 0.0000, d = 1.42.\n\n\n\nWilcoxon Signed-Rank Test\nFrom the distribution plot, you can see that most of the signs were positive, and the largest absolute difference values were among the positives, so expect a pretty large test statistic.\n\n(drink$wilcoxon_test &lt;- wilcox.test(drink$wilcoxon_dat$carb_protein,\n                                    drink$wilcoxon_dat$carb, \n                                    paired = TRUE))\n\n\n    Wilcoxon signed rank exact test\n\ndata:  drink$wilcoxon_dat$carb_protein and drink$wilcoxon_dat$carb\nV = 162, p-value = 0.03277\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nThe carbohydrate-protein drink elicited a statistically significant median increase in distance run in two hours compared to the carbohydrate-only drink, W = 162, p = 0.033.\n\nReport the results.\n\nA Wilcoxon signed-rank test was conducted to determine the effect of a new formula of sports drink on running performance. Instead of the regular, carbohydrate-only drink, the new sports drink contains a new carbohydrate-protein mixture. Twenty participants were recruited to the study who each performed two trials in which they had to run as far as possible in two hours on a treadmill. In one of the trials they drank the carbohydrate-only drink and in the other trial they drank the carbohydrate-protein drink. The order of the trials was counterbalanced and the distance they ran in both trials was recorded.\nThe difference scores were approximately symmetrically distributed, as assessed by a histogram with superimposed normal curve.\nData are medians unless otherwise stated. Of the 20 participants recruited to the study, the carbohydrate-protein drink elicited an increase in the distance run in 17 participants compared to the carbohydrate-only drink, whereas two participants saw no improvement and one participant did not run as far with the carbohydrate-protein drink. There was a statistically significant median increase in distance run (0.2300 km) when subjects imbibed the carbohydrate-protein drink (11.368 km) compared to the carbohydrate-only drink (11.108 km), W = 162, p = 0.0328.\n\n\n\nSign Signed-Rank Test\nConduct the exact sign test since the n-size is not so large that we need the normal approximation to the binomial. Notice n is the count of non-zero differences.\n\n(drink$sign_test &lt;- binom.test(sum(drink$sign_dat$diff &gt; 0), \n                               n = sum(drink$sign_dat$diff != 0)))\n\n\n    Exact binomial test\n\ndata:  sum(drink$sign_dat$diff &gt; 0) and sum(drink$sign_dat$diff != 0)\nnumber of successes = 18, number of trials = 18, p-value = 7.629e-06\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.814698 1.000000\nsample estimates:\nprobability of success \n                     1 \n\n\n\nThe carbohydrate-protein drink elicited a statistically significant median increase in distance run (0.230 km) compared to the carbohydrate-only drink, p = 0.000.\n\nReport the results.\n\nAn exact sign test was conducted to determine the effect of a new formula of sports drink on running performance. Instead of the regular, carbohydrate-only drink, the new sports drink contains a new carbohydrate-protein mixture. Twenty participants were recruited to the study who each performed two trials in which they had to run as far as possible in two hours on a treadmill. In one of the trials they drank the carbohydrate-only drink and in the other trial they drank the carbohydrate-protein drink. The order of the trials was counterbalanced and the distance they ran in both trials was recorded.\nAn exact sign test was used to determine whether there was a statistically significant median difference between the distance ran when participants drank a carbohydrate-protein drink compared to a carbohydrate-only drink. Data are medians unless otherwise stated. Of the 20 participants recruited to the study, the carbohydrate-protein drink elicited an increase in the distance run in 18 participants compared to the carbohydrate-only drink, whereas 0 participants did not run as far and 2 participant saw no improvement with the carbohydrate-protein drink. There was a statistically significant median increase in distance run (0.2300 km) when subjects imbibed the carbohydrate-protein drink (11.368 km) compared to the carbohydrate-only drink (11.108 km), p = 0.0000.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Paired Samples t-Test</span>"
    ]
  },
  {
    "objectID": "07-continuous-multinomial.html",
    "href": "07-continuous-multinomial.html",
    "title": "7  Continuous ~ Multnomial",
    "section": "",
    "text": "7.1 One-way ANOVA\nAnalysis of variance (ANOVA) is a method to compare the mean values of a continuous variable between groups of a categorical independent variable. ANOVA is typically used to analyze the response to a manipulation of the independent variable in a controlled experiment, but it can also be used to analyze the difference in the observed value among groups in a non-experimental setting.1\nHow it Works\nANOVA decomposes the variability around the overall mean \\(Y_{ij} - \\bar{Y}_{..}\\) into two parts: the variability of the factor level means around the overall mean \\(\\bar{Y}_{i.} - \\bar{Y}_{..}\\) (between-group variability) plus the variability of the factor level values around their means \\(Y_{ij} - \\bar{Y}_{i.}\\) (within-group variability). In the table below, the ratio of the treatment mean square and the mean squared error, \\(F = \\frac{MSR}{MSE}\\), follows an F distribution with \\(k-1\\) numerator dof and \\(N-k\\) denominator dof. The more observation variance captured by the treatments, the larger is the between-group variability relative to the within-group variability, and thus the larger is \\(F\\), and the less likely that the null hypothesis, \\(H_0 = \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\) is true.\nANOVA Table\n\n\nSource\nSS\ndf\nMS\nF\n\n\n\n\n$SSR$\n$\\sum{n_i(\\bar{Y}_{i.} - \\bar{Y}_{..})^2}$\n$k - 1$\n${SSR}/{(k - 1)}$\n${MSR}/{MSE}$\n\n\n$SSE$\n$\\sum(Y_{ij} - \\bar{Y}_{i.})^2$\n$N - k$\n${SSE}/{(N - k)}$\n\n\n\n$SST$\n$\\sum(Y_{ij} - \\bar{Y}_{..})^2$\n$N - 1$\nAssumptions\nThe ANOVA test applies when the independent variable is categorical, and the dependent variable is continuous and independent within groups. Independence means the observations are from a random sample, or from an experiment using random assignment. Each group’s size should be less than 10% of its population size. The groups must also be independent of each other (non-paired, and non-repeated measures). Additionally, there are three assumptions related to the distribution of the dependent variable. If any assumption fails, either try the work-around or revert to the nonparametric Kruskal-Wallis test (Chapter @ref(kw)).\nPost Hoc Tests\nIf the ANOVA procedure rejects the null hypothesis, use a post hoc procedure to determine which groups differ. The Tukey test is the most common. The test compares the differences in means to Tukey’s \\(w\\), \\(w = q_\\alpha(p, df_{Err}) \\cdot s_\\bar{Y}\\) where \\(q_\\alpha(p, df_{Err})\\) is a lookup table value, and \\(s_\\bar{Y} = \\sqrt{MSE/r}\\) and \\(r\\) is the number of comparisons. Any difference in group means greater than Tukey’s \\(w\\) is statistically significant. The Tukey test is only valid with equal sample sizes. Otherwise, the Tukey–Cramer method calculates the standard deviation for each pairwise comparison separately.\nThere are other post hoc tests. Fisher’s Protected Least Significant Difference (LSD) test is an older approach and less commonly used today. The Bonferroni and Scheffe methods are used for general tests of contrasts, including combinations of groups. The Bonferroni method is better when the number of contrasts is about the same as the number of factor levels. The Scheffe method is better for testing all possible contrasts. Dunnett’s mean comparison method is appropriate for comparisons of treatment levels against a control.\nANOVA and OLS\nANOVA is related to linear regression. The regression model intercept is the overall mean and the coefficient estimators indirectly indicate the group means. The analysis of variance table in a regression model shows how much of the overall variance is explained by those coefficient estimators. It’s the same thing.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Continuous ~ Multnomial</span>"
    ]
  },
  {
    "objectID": "07-continuous-multinomial.html#sec-onewayanova",
    "href": "07-continuous-multinomial.html#sec-onewayanova",
    "title": "7  Continuous ~ Multnomial",
    "section": "",
    "text": "No outliers. There should be no significant outliers in the groups. Outliers exert a large influence on the mean and variance. Test with a box plot or residuals vs predicted plot. Work-arounds are dropping the outliers or transforming the dependent variable.\nNormality. The dependent variable should be nearly normally distributed. ANOVA is robust to this condition, but it important with small sample sizes. Test with the Q-Q plots or the Shapiro-Wilk test for normality. Work-around is transforming the dependent variable.\nEqual Variances. The group variances should be roughly equal. This condition is especially important with differing sample sizes. Test with a box plot, residuals vs predicted plot, rule of thumb (see case study in Chapter @ref(groupdiffscs3)), or one of the formal homogeneity of variance tests such as Bartlett and Levene (be careful here because the formal tests can be overly sensitive, esp. Bartlett). Work-around is the Games-Howell post hoc test instead of the Tukey post hoc test.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Continuous ~ Multnomial</span>"
    ]
  },
  {
    "objectID": "07-continuous-multinomial.html#sec-kruskalwallis",
    "href": "07-continuous-multinomial.html#sec-kruskalwallis",
    "title": "7  Continuous ~ Multnomial",
    "section": "7.2 Kruskal–Wallis Test",
    "text": "7.2 Kruskal–Wallis Test\nThe Kruskal-Wallis H test2 measures the difference of a continuous or ordinal dependent variable between groups of a categorical independent variable. It is a rank-based nonparametric alternative to the one-way ANOVA test. Use Kruskal-Wallis if the dependent variable fails ANOVA’s normality or homogeneity conditions, or if it is ordinal.\nHow it Works\nThe Kruskal-Wallis H test ranks the dependent variable irrespective of its group. The test statistic is a function of the averaged square of the rank sum per group:\n\\[\nH = \\left[ \\frac{12}{n(n+1)} \\sum_{j} \\frac{T_j^2}{n_j} \\right] - 3(n + 1)\n\\]\nwhere \\(T_j\\) is the sum of the ranks of group j. The test statistic approximately follows a \\(\\chi^2\\) distribution with k – 1 degrees of freedom, where k is the number of groups of the independent variable. The null hypothesis is that the rank means are equal. If you reject the null hypothesis, run a post hoc test to determine which groups differ.\nAssumptions\nKruskal-Wallis has no assumptions per se, but the test interpretation depends on the distribution of the dependent variable. If its distribution has a similar shape across the groups of the categorical independent variable, then Kruskal-Wallis is a test of differences in their medians. Otherwise, Kruskal-Wallis is a test of differences in their distributions.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Continuous ~ Multnomial</span>"
    ]
  },
  {
    "objectID": "07-continuous-multinomial.html#groupdiffscs3",
    "href": "07-continuous-multinomial.html#groupdiffscs3",
    "title": "7  Continuous ~ Multnomial",
    "section": "Case Study 3",
    "text": "Case Study 3\nThis case study uses the data set from Laerd Statistics for ANOVA.\n\ncs3 &lt;- list()\n\n# Data sets are the same, so just use one.\n# cs3$kw_dat &lt;- read.spss(\"./input/kruskal-wallis-h-test.sav\", to.data.frame = TRUE)\n# cs3$anova_dat &lt;- read.spss(\"./input/one-way-anova.sav\", to.data.frame = TRUE)\ncs3$dat &lt;- read.spss(\"./input/kruskal-wallis-h-test.sav\", to.data.frame = TRUE)\n\nA study tests whether physically active individuals are better able to cope with workplace stress. The study categorizes \\(n\\) = 31 participants by physical activity level (“Sedentary”, “Low”, “Moderate”, and “High”) and measures their ability to cope with workplace-related stress (CWWS) as the average score of a series of Likert items on a questionnaire (higher scores indicating a greater CWWS ability). The means plot3 and summary table are an initial look at the data.\n\ncs3$dat %&gt;%\n  group_by(group) %&gt;%\n  summarize(\n    .groups = \"drop\",\n    mean_coping_stress = mean(coping_stress),\n    cl_025 = mean_coping_stress + qnorm(.025) * sd(coping_stress) / sqrt(n()),\n    cl_975 = mean_coping_stress + qnorm(.975) * sd(coping_stress) / sqrt(n()),\n    n = n()\n  ) %&gt;%\n  ggplot(aes(x = group, y = mean_coping_stress)) +\n  geom_point(shape = 21, fill = \"gray80\", color = \"black\", size = 3) +\n  geom_errorbar(aes(ymin = cl_025, ymax = cl_975, width = 0.1)) +\n  geom_text(aes(y = 2, label = glue(\"n = {n}\")), size = 3) +\n  labs(title = \"Distribution of CWWS by Physical Activity Level Group\",\n       x = NULL, y = \"Score\",\n       caption = \"Means plot with 95% CI\")\n\n\n\n\n\n\n\n\n\n(cs3$gt &lt;- cs3$dat %&gt;% \n  tbl_summary(\n    by = group, \n    label = list(coping_stress = \"CWWR\"),\n    type = coping_stress ~ \"continuous2\",\n    statistic = coping_stress ~ c(\"{median} ({p25}, {p75})\", \"{mean}, {sd}\")\n  ) %&gt;% \n  add_n())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nSedentary\nN = 7\nLow\nN = 9\nModerate\nN = 8\nHigh\nN = 7\n\n\n\n\nCWWR\n31\n\n\n\n\n\n\n\n\n\n\n    Median (Q1, Q3)\n\n\n4.12 (3.28, 4.93)\n5.50 (4.45, 7.85)\n7.10 (6.01, 8.25)\n7.47 (6.86, 8.89)\n\n\n    Mean, SD\n\n\n4.15, 0.77\n5.88, 1.69\n7.12, 1.57\n7.51, 1.24\n\n\n\n\n\n\n\n\nCWWS score (mean, SD) increased from the sedentary (4.15, 0.77), to low (5.88, 1.69), to moderate (7.12, 1.57) to high (7.51, 1.24) physical activity groups, in that order.\n\n7.2.1 Assumptions\nRecall that the one-way ANOVA test is valid under three assumptions. One, there are no significant outliers that influence the group mean. Two, the dependent variable is at least approximately (ANOVA is robust to this assumption) normally distributed for each group if the sample size is small (for large sample sizes the Central Limit Theorem shows normality is unnecessary). Three, the dependent variable should have equal variances across groups. ANOVA is only sensitive to this condition if the group sample sizes are not similar.\nKruskal-Wallis has no assumptions per se, but the interpretation of its results depend on the distribution of the dependent variable. If the distributions are similar, then the test results tell you whether the medians differ. Otherwise, the test results tell you whether the distributions differ.\nUse a boxplot to assess outliers for ANOVA and the data distribution (if you revert to Kruskal-Wallis). Values greater than 1.5 IQR from the hinges (values beyond the whiskers) are outliers. Outliers might occur from data entry errors or measurement errors, so investigate and fix or throw them out. If the outlier is a genuinely extreme, you still have a couple options before reverting to Kruskal-Wallis. You can transform the dependent variable, but don’t do this unless the data is also non-normal. Transforming the variable also has the downside of making interpretation more difficult. You can also leave the outlier(s) in if it doesn’t affect the conclusion. There are no outliers here.\n\ncs3$dat %&gt;%\n  ggplot(aes(x = group, y = coping_stress)) +\n  geom_boxplot(outlier.color = \"goldenrod\", outlier.size = 2) +\n  labs(title = \"Boxplot of CWWR vs Group\",\n       y = \"Score\", x = \"Group\")\n\n\n\n\n\n\n\n\nThere is no accepted practice for determining whether distributions are similar. The boxplot reveals a wider range of values for “Low” group, but this is close enough to conclude the distributions are similar.\nYou can assume the populations are normally distributed if \\(n_j &gt;= 30\\). Otherwise, try the Q-Q plot, or skewness and kurtosis values, or histograms. If you still don’t feel confident about normality, run the Shapiro-Wilk test of normality or the Kolmogorov-Smirnov test. Definitely do not use Shapiro-Wilk for \\(n_j &gt;= 30\\) because it is too sensitive. The Normal Q-Q plot below looks good for all groups except perhaps the “Low” group. The Shapiro-Wilk test confirms this, with all p-values over .05.\n\ncs3$dat %&gt;% \n  ggplot(aes(sample = coping_stress)) +\n  stat_qq() +\n  stat_qq_line(col = \"goldenrod\") +\n  facet_wrap(facets = vars(group)) +\n  labs(title = \"Q-Q Plot\", x = \"Theoretical\", y = \"Sample\")\n\n\n\n\n\n\n\n\n\nwith(cs3$dat, by(coping_stress, group, shapiro.test)) %&gt;% \n  map(tidy) %&gt;%\n  bind_rows(.id = \"group\")\n\n# A tibble: 4 × 4\n  group     statistic p.value method                     \n  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                      \n1 Sedentary     0.928  0.538  Shapiro-Wilk normality test\n2 Low           0.841  0.0589 Shapiro-Wilk normality test\n3 Moderate      0.976  0.940  Shapiro-Wilk normality test\n4 High          0.944  0.671  Shapiro-Wilk normality test\n\n\nHad the data failed the normality test, you could probably carry on anyway since the test is fairly robust to deviations from normality, particularly if the sample sizes are nearly equal. You can also try transforming the dependent variable. Transformations will generally only work when the distribution of scores in all groups are the same shape. Otherwise, revert to the Kruskal-Wallis H test.\nANOVA’s equality of sample variances condition is less critical when sample sizes are similar among the groups (as they are here). A rule of thumb is that no group’s standard deviation should be more than double that of any other. In this case, “Moderate” and “Low” are more than double “Sedentary”.\n\n\n# A tibble: 4 × 4\n  group         n    sd multiple\n  &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Sedentary     7 0.771     1   \n2 High          7 1.24      1.61\n3 Moderate      8 1.57      2.04\n4 Low           9 1.69      2.19\n\n\nThere are two common tests, Bartlett and Levene4. Levene is less sensitive to departures from normality. Neither test rejects the null hypothesis of equality of variance here.\n\n(cs3$levene &lt;- car::leveneTest(coping_stress ~ group, data = cs3$dat, center = \"mean\"))\n## Levene's Test for Homogeneity of Variance (center = \"mean\")\n##       Df F value Pr(&gt;F)\n## group  3   2.129 0.1199\n##       27\n(cs3$bartlet &lt;- bartlett.test(coping_stress ~ group, data = cs3$dat))\n## \n##  Bartlett test of homogeneity of variances\n## \n## data:  coping_stress by group\n## Bartlett's K-squared = 3.7489, df = 3, p-value = 0.2899\n\nThe residuals vs fitted values plot is included in the set of diagnostic plots that are produced in the base R plot.lm() function.\n\naov(coping_stress ~ group, data = cs3$dat) %&gt;% plot(which = 1)\n\n\n\n\n\n\n\n\nHeterogeneity of variances is a common problem in ANOVA. The Box-Cox procedure can help find a good transformation to remove heterogeneity. MASS::boxcox() calculates a profile of log-likelihoods for a power transformation of the dependent variable \\(Y^\\lambda\\).\n\n\n\n\\(\\lambda\\)\n\\(Y^\\lambda\\)\nTransformation\n\n\n\n\n2\n\\(Y^2\\)\nSquare\n\n\n1\n\\(Y^1\\)\n(no transformation)\n\n\n.5\n\\(Y^{.5}\\)\nSquare Root\n\n\n0\n\\(\\ln(Y)\\)\nLog\n\n\n-.5\n\\(Y^{-.5}\\)\nInverse Square Root\n\n\n-1\n\\(Y^{-1}\\)\nInverse\n\n\n\nThe Box-Cox procedure does not recommend any particular transformation of the data in this case.\n\nMASS::boxcox(aov(coping_stress ~ group, data = cs3$dat), plotit = TRUE)\n\n\n\n\n\n\n\n\nHad the data failed the homogeneity assumption, you could use a modified version of ANOVA called Welch’s ANOVA and the Games-Howell post hoc test, or you could revert to the nonparametric Kruskal-Wallis test.\n\n\n7.2.2 ANOVA\nIf the dependent variable conforms to the three ANOVA assumptions of no outliers, normality, and homogeneity, then you can run a one-way ANOVA with aov(). If the dependent variable only violates the homegeneity assumption, you can run Welch’s ANOVA with oneway.test(..., var.equal = FALSE)\n\ncs3$aov &lt;- aov(coping_stress ~ group, data = cs3$dat)\n(cs3$anova &lt;- anova(cs3$aov))\n## Analysis of Variance Table\n## \n## Response: coping_stress\n##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \n## group      3 49.033 16.3443   8.316 0.0004454 ***\n## Residuals 27 53.066  1.9654                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(cs3$welch &lt;- oneway.test(coping_stress ~ group, data = cs3$dat, var.equal = FALSE))\n## \n##  One-way analysis of means (not assuming equal variances)\n## \n## data:  coping_stress and group\n## F = 14.821, num df = 3.000, denom df = 14.574, p-value = 0.0001058\n\nThe ability to cope with workplace-related stress (CWWS score) was statistically significantly different for different levels of physical activity group, F(3, 27) = 8.3, p = 0.0004.\n\ntibble(\n  f_stat = seq(0, 10, .01), \n  d_val = df(f_stat, 3, 14.574),\n  p_f = pf(f_stat, cs3$anova$Df[1], cs3$anova$Df[2], lower.tail = FALSE),\n  region = if_else(p_f &lt; .05, \"reject\", \"accept\")\n) %&gt;%\n  ggplot(aes(x = f_stat, y = d_val)) +\n  geom_area(aes(fill = region), show.legend = FALSE) +\n  geom_line() +\n  geom_vline(xintercept = cs3$anova$\"F value\"[1], linetype = 2, color = \"firebrick\") +\n  scale_fill_manual(values = c(reject = \"firebrick\", accept = \"white\")) +\n  labs(\n    title = glue::glue(\"F({paste(cs3$anova$Df, collapse = ', ')}) = \",\n                       \"{comma(cs3$anova$'F value'[1], .1)}, p = \",\n                       \"{comma(cs3$anova$'Pr(&gt;F)'[1], .0001)}\"),\n    x = \"F\", y = \"P(F)\"\n  )\n\n\n\n\n\n\n\n\nThe F test does not indicate which populations cause the rejection of \\(H_0\\). Conduct a Tukey post hoc test if you have no specific hypothesis about two groups differing or want to see all group differences.5 If you want to compare two groups or set of groups, then use a custom contrast. Tukey is valid for balanced designs. If you have different sample sizes per group, use the Tukey-Kramer post hoc test. If the dependent variable failed the homogeneity of variances assumption, you would run the Games-Howell post hoc test instead.\n\n(cs3$tukey &lt;- TukeyHSD(cs3$aov))\n##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = coping_stress ~ group, data = cs3$dat)\n## \n## $group\n##                         diff        lwr      upr     p adj\n## Low-Sedentary      1.7276175 -0.2057757 3.661011 0.0923527\n## Moderate-Sedentary 2.9715262  0.9859704 4.957082 0.0018413\n## High-Sedentary     3.3540854  1.3034122 5.404759 0.0006806\n## Moderate-Low       1.2439086 -0.6202750 3.108092 0.2835038\n## High-Low           1.6264679 -0.3069254 3.559861 0.1226045\n## High-Moderate      0.3825593 -1.6029965 2.368115 0.9517285\n(cs3$games_howell &lt;- rstatix::games_howell_test(cs3$dat, coping_stress ~ group))\n## # A tibble: 6 × 8\n##   .y.           group1   group2 estimate conf.low conf.high   p.adj p.adj.signif\n## * &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       \n## 1 coping_stress Sedenta… Low       1.73    -0.163      3.62 7.7 e-2 ns          \n## 2 coping_stress Sedenta… Moder…    2.97     1.07       4.88 3   e-3 **          \n## 3 coping_stress Sedenta… High      3.35     1.66       5.05 5.84e-4 ***         \n## 4 coping_stress Low      Moder…    1.24    -1.04       3.53 4.23e-1 ns          \n## 5 coping_stress Low      High      1.63    -0.508      3.76 1.67e-1 ns          \n## 6 coping_stress Moderate High      0.383   -1.76       2.52 9.51e-1 ns\n\nTukey post hoc analysis revealed that the increase from sedentary to moderate (2.97, 95% CI (0.99 to 4.96)) was statistically significant (p = 0.002), as well as the increase from sedentary to high (3.35, 95% CI (1.30 to 5.40)) was statistically significant (p = 0.001), but no other group differences were statistically significant.\n\ncs3$tukey %&gt;% \n  tidy() %&gt;%\n  ggplot(aes(y = contrast, x = estimate)) +\n  geom_point(shape = 3) +\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = .2) +\n  geom_vline(aes(xintercept = 0), linetype = 2) +\n  labs(x = NULL, y = NULL, title = \"95% family-wise confidence level\")\n\n\n\n\n\n\n\n\nGames-Howell post hoc analysis revealed that the increase from sedentary to moderate (2.97, 95% CI (1.07 to 4.88)) was statistically significant (p =0.003), as well as the increase from sedentary to high (3.35, 95% CI (1.66 to 5.05, p = 0.001).\nIf you have specific hypotheses about the differences between the groups of your independent variable, e.g., whether the mean CWWS differs between the “Low” and “Sedentary” groups, \\(H_0: \\sum_i^K{c_i u_i} = 0\\) where \\(c_i = (1, -1, 0, 0)\\) or “Sedentary” and average of all others, \\(c_i = (1, -1/3, -1/3, -1/3)\\), set up a contrast using the multcomp package.\n\ncs3$glht_1 &lt;- multcomp::glht(cs3$aov, linfct = multcomp::mcp(group = c(-1, 1, 0, 0)))\nsummary(cs3$glht_1)\n## \n##   Simultaneous Tests for General Linear Hypotheses\n## \n## Multiple Comparisons of Means: User-defined Contrasts\n## \n## \n## Fit: aov(formula = coping_stress ~ group, data = cs3$dat)\n## \n## Linear Hypotheses:\n##        Estimate Std. Error t value Pr(&gt;|t|)  \n## 1 == 0   1.7276     0.7065   2.445   0.0213 *\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## (Adjusted p values reported -- single-step method)\ncs3$glht_2 &lt;- multcomp::glht(cs3$aov, linfct = multcomp::mcp(group = c(-1, 1/3, 1/3, 1/3)))\nsummary(cs3$glht_2)\n## \n##   Simultaneous Tests for General Linear Hypotheses\n## \n## Multiple Comparisons of Means: User-defined Contrasts\n## \n## \n## Fit: aov(formula = coping_stress ~ group, data = cs3$dat)\n## \n## Linear Hypotheses:\n##        Estimate Std. Error t value Pr(&gt;|t|)    \n## 1 == 0   2.6844     0.6029   4.452 0.000133 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## (Adjusted p values reported -- single-step method)\n\nThere are three groups, so you need to adjust the p-value and 95% CI for them.\n\nconfint(cs3$glht_1, level = 1-.05/3)\n## \n##   Simultaneous Confidence Intervals\n## \n## Multiple Comparisons of Means: User-defined Contrasts\n## \n## \n## Fit: aov(formula = coping_stress ~ group, data = cs3$dat)\n## \n## Quantile = 2.5525\n## 98.3333333333333% family-wise confidence level\n##  \n## \n## Linear Hypotheses:\n##        Estimate lwr     upr    \n## 1 == 0  1.7276  -0.0757  3.5309\nconfint(cs3$glht_2, level = 1-.05/3)\n## \n##   Simultaneous Confidence Intervals\n## \n## Multiple Comparisons of Means: User-defined Contrasts\n## \n## \n## Fit: aov(formula = coping_stress ~ group, data = cs3$dat)\n## \n## Quantile = 2.5525\n## 98.3333333333333% family-wise confidence level\n##  \n## \n## Linear Hypotheses:\n##        Estimate lwr    upr   \n## 1 == 0 2.6844   1.1454 4.2234\n\nThere was no statistically significant increase in CWWS score from the sedentary group (4.15, 0.77) to the group performing a low level of physical activity (5.88, 1.69), a mean increase of 1.7 (95% CI, -0.08, 3.53), p = 0.021.\nCWWS score was statistically significantly higher in the non-sedentary groups (M = 6.8) compared to the sedentary group (4.15, 0.77), a mean increase of 1.7 (95% CI, 1.15, 4.22), p = 0.000.\nYou may also want to report the \\(\\omega^2\\) effect size,\n\\[\\omega^2 = \\frac{SSR - df_R \\cdot MSE}{MSE + SST}\\]\nwhere SSR is the between groups sum of squares, 49.0, MSE is the within groups mean square, 1.97, and SST is the total sum of squares, 102.1.\n\n(cs3$anova_stats &lt;- sjstats::anova_stats(cs3$aov))\n\netasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f\n------------------------------------------------------------------------\n0.480 |         0.480 |   0.415 |           0.415 |     0.423 |    0.961\n      |               |         |                 |           |         \n\netasq |      term |  sumsq | df | meansq | statistic | p.value | power\n----------------------------------------------------------------------\n0.480 |     group | 49.033 |  3 | 16.344 |     8.316 |  &lt; .001 | 0.993\n      | Residuals | 53.066 | 27 |  1.965 |           |         |      \n\n\n\\(\\omega^2\\) estimates the population effect size. It \\(\\omega^2\\) ranges from -1 to +1. Here, \\(\\omega^2\\) is 0.415.\n\ncomma(cs3$anova$`Sum Sq`[1], .1)\n\n[1] \"49.0\"\n\n\nAlternatively, the partial eta squared statistic, \\(\\eta^2\\), measures the effect size in the sample. Here \\(\\eta^2\\) is 0.48.\nNow you can report your results.\n\nA one-way ANOVA was conducted to determine if the ability to cope with workplace-related stress (CWWS score) was different for groups with different physical activity levels. Participants were classified into four groups: sedentary (n = 7), low (n = 9), moderate (n = 8) and high levels of physical activity (n = 7). There were no outliers, as assessed by boxplot; data was normally distributed for each group, as assessed by Shapiro-Wilk test (p &gt; .05); and there was homogeneity of variances, as assessed by Levene’s test of homogeneity of variances (p = 0.120). CWWS score was statistically significantly different between different physical activity groups, F(3, 27) = 8.3, p = 0.0004, \\(\\omega^2\\) = 0.415. CWWS score (Mean, SD) increased from the sedentary (4.15, 0.77), to low (5.88, 1.69), to moderate (7.12, 1.57) to high (7.51, 1.24) physical activity groups, in that order. Tukey post hoc analysis revealed that the mean increase from sedentary to moderate (2.97, 95% CI [0.99 to 4.96]) was statistically significant (p = 0.002), as well as the increase from sedentary to high (3.35, 95% CI [1.30 to 5.40], p = 0.001), but no other group differences were statistically significant.\n\nHad the dependent variable failed the homogeneity of variances assumption, you would report the results from Welch’s ANOVA,\n\nThe ability to cope with workplace-related stress (CWWS score) was statistically significantly different for different levels of physical activity group, Welch’s F(3, 14.6) = 14.8, p &lt; .0005.\n\nand the Games-Howell post hoc test,\n\nGames-Howell post hoc analysis revealed that the increase from sedentary to moderate (2.97, 95% CI [1.07 to 4.88]) was statistically significant (p =0.003), as well as the increase from sedentary to high (3.35, 95% CI [1.66 to 5.05], p = 0.001).\n\nPower Analysis\nIf you run an ANOVA and do not reject the null hypothesis, you may want to run a power analysis to make sure the power of the test was not very low. Power is the ability to reject the null when the null is really false. Power is affected by sample size, effect size, variability of the experiment, and the significance of the type 1 error. You typically want power to be at 80%, meaning 80% of the time your test rejects the null when it should, and 20% of the time your test does not reject the null when it should.\n\npower.anova.test(\n  groups = cs3$aov$rank,\n  n = cs3$aov$model %&gt;% count(group) %&gt;% pull(n) %&gt;% min(),\n  between.var = cs3$dat %&gt;% group_by(group) %&gt;% \n    summarize(M = mean(coping_stress)) %&gt;% pull(M) %&gt;% var(),\n  within.var= cs3$anova$`Mean Sq`[2],\n  sig.level = 0.05\n)\n\n\n     Balanced one-way analysis of variance power calculation \n\n         groups = 4\n              n = 7\n    between.var = 2.283631\n     within.var = 1.965395\n      sig.level = 0.05\n          power = 0.9787783\n\nNOTE: n is number in each group\n\n\n\n\n7.2.3 Kruskal-Wallis Test\nRun a Kruskal-Wallis H test with kruskal.test().\n\n(cs3$kruskal &lt;- kruskal.test(coping_stress ~ group, data = cs3$dat))\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  coping_stress by group\nKruskal-Wallis chi-squared = 14.468, df = 3, p-value = 0.002332\n\n\nThe dependent variable has similarly shaped distributions for all groups of the independent variable, so you can conclude the median CWWS scores were statistically significantly different between groups, \\(\\chi^2\\)(3) = 14.5, p = 0.0023. Otherwise you would conclude the distributions differ. You rejected the null hypothesis, so continue on with a post hoc test to determine which medians (similar distributions) or mean ranks (dissimilar distributions) differ with the Dunn procedure using a Bonferroni correction for multiple comparisons.\n\n(cs3$dunn &lt;- FSA::dunnTest(coping_stress ~ group, data = cs3$dat, method = \"bonferroni\"))\n\n            Comparison          Z      P.unadj       P.adj\n1           High - Low  1.6801430 0.0929294869 0.557576921\n2      High - Moderate  0.2163067 0.8287486760 1.000000000\n3       Low - Moderate -1.5121301 0.1305007724 0.783004635\n4     High - Sedentary  3.3216144 0.0008949829 0.005369897\n5      Low - Sedentary  1.8429610 0.0653346998 0.392008199\n6 Moderate - Sedentary  3.2142419 0.0013078945 0.007847367\n\n\nP.adj equals P.unadj multiplied by the number of comparisons (6). You could report the adjusted p or the unadjusted p with a note that you accepted statistical significance at the p &lt; .05 / 6 = 0.0083 level.\nNow you can report your results.\n\nA Kruskal-Wallis test was conducted to determine if there were differences in CWWS scores between groups that differed in their level of physical activity: the “sedentary” (n = 7), “low” (n = 9), “moderate” (n = 8) and “high” (n = 7) physical activity level groups. Distributions of CWWS scores were similar for all groups, as assessed by visual inspection of a boxplot. Median CWWS scores were statistically significantly different between the different levels of physical activity group, \\(\\chi^2\\)(3) = 14.5, p = 0.0023. Subsequently, pairwise comparisons were performed using Dunn’s (1964) procedure with a Bonferroni correction for multiple comparisons. Adjusted p-values are presented. This post hoc analysis revealed statistically significant differences in CWWS scores between the sedentary (Mdn = 4.12 (3.28, 4.93)) and moderate (Mdn = 7.10 (6.01, 8.25)) (p = 0.0078) and sedentary and high (Mdn = 7.47 (6.86, 8.89)) (p = 0.0054) physical activity groups, but not between the low physical activity group (Mdn = 5.50 (4.45, 7.85)) or any other group combination.\n\nHad the distributions been different, you would report “CWWS scores” instead of “Median CWWS scores” and report the mean ranks instead of Mdn. Unfortunately, you cannot retrieve those ranks from the test object, so you would have to calculate them yourself.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Continuous ~ Multnomial</span>"
    ]
  },
  {
    "objectID": "07-continuous-multinomial.html#footnotes",
    "href": "07-continuous-multinomial.html#footnotes",
    "title": "7  Continuous ~ Multnomial",
    "section": "",
    "text": "These notes are gleaned from PSU STAT-502 “Analysis of Variance and Design of Experiments”, and Laerd Statistics.↩︎\nThe Kruskal-Wallis H test is also called the one-way ANOVA on ranks↩︎\nTrying APA style guidelines.↩︎\nNIST has a good write-up for Bartlett and Levene↩︎\nThere are other options for post-hoc tests not discussed here: Fisher’s Least Significant Difference (LSD), Bonferroni, Scheffe, and Dunnett.↩︎",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Continuous ~ Multnomial</span>"
    ]
  },
  {
    "objectID": "08-binomial-binomial.html",
    "href": "08-binomial-binomial.html",
    "title": "8  Binomial ~ Binomial",
    "section": "",
    "text": "8.1 Two Proportion Z-Test\nThe tests presented here compare two proportions. That is, the outcome is binomial (1|0) and you want to compare the proportion (outcome = 1) between two groups.\nThe Z-test uses the difference in sample proportions, \\(d = p_1 - p_2\\), to test whether the difference in population proportions, \\(\\delta = \\pi_1 - \\pi_2\\), differs from an hypothesized difference, \\(d_0 = \\pi_1 - \\pi_2\\), or to construct a \\((1−\\alpha)\\%\\) confidence interval around \\(d\\) to estimate \\(\\delta\\).\nThe Z-test applies when the central limit theorem conditions hold so that the normal distribution approximates the binomial distribution.\nIf these conditions hold, the sampling distribution of \\(\\delta\\) is normally distributed around \\(d\\) with standard error \\(se_d = \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 − p_2)}{n_2}}\\). When \\(d_0 = 0\\) (almost always), pool the proportions, so \\(se_d = \\sqrt{\\frac{p(1 - p)}{n_1} + \\frac{p(1 − p)}{n_2}}\\), or simply:\n\\[se_d = \\sqrt{p(1-p)\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\n\\tag{8.1}\\]\nThe Z-test statistic is \\[Z = \\frac{d-d_0}{se_{d}} \\tag{8.2}\\]\nDefine a \\((1 − \\alpha)\\%\\) confidence interval as \\(d \\pm z_{1-\\alpha / 2}se_d\\).",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binomial ~ Binomial</span>"
    ]
  },
  {
    "objectID": "08-binomial-binomial.html#sec-08-z",
    "href": "08-binomial-binomial.html#sec-08-z",
    "title": "8  Binomial ~ Binomial",
    "section": "",
    "text": "Note\n\n\n\nThe two propportion Z-test and the chi-square test of homogeneity produce the same statistical significance result because they are algebraically identical. The Z statistic equals \\(\\sqrt{\\chi^2}\\). There is no Z-test function in the stats library.\n\n\n\n\n\nThe sample is independently drawn, meaning random assignment (experiments) or random sampling without replacement from \\(n &lt; 10\\%\\) of the population (observational studies),\nthere are at least \\(n_i p_i &gt;= 5\\) successes and \\(n_i (1 - p_i) &gt;= 5\\) failures for each group, \\(i\\),\nthe sample sizes are both \\(n_i &gt;= 30\\), and\nthe probability of success for each group is not extreme, \\(0.2 &lt; \\pi_i &lt; 0.8\\).",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binomial ~ Binomial</span>"
    ]
  },
  {
    "objectID": "08-binomial-binomial.html#sec-08-chisq",
    "href": "08-binomial-binomial.html#sec-08-chisq",
    "title": "8  Binomial ~ Binomial",
    "section": "8.2 Chi-Square Test of Homogeneity",
    "text": "8.2 Chi-Square Test of Homogeneity\nThe chi-square test of homogeneity tests whether frequency counts of the R levels of a categorical variable are distributed identically across the C populations. It tests whether observed joint frequency counts \\(O_{ij}\\) differ from expected frequency counts \\(E_{ij}\\) under the independence model (the model of independent explanatory variables, \\(\\pi_{ij} = \\pi_{i+} \\pi_{+j}\\). \\(H_0\\) is \\(O_{ij} = E_{ij}\\).\nThere are two possible test statistics for this test, Pearson\n\\[X^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} \\tag{8.3}\\]\nand deviance\n\\[G^2 = 2 \\sum_{ij} O_{ij} \\log \\left( \\frac{O_{ij}}{E_{ij}} \\right). \\tag{8.4}\\]",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binomial ~ Binomial</span>"
    ]
  },
  {
    "objectID": "08-binomial-binomial.html#sec-08-fet",
    "href": "08-binomial-binomial.html#sec-08-fet",
    "title": "8  Binomial ~ Binomial",
    "section": "8.3 Fisher’s Exact Test",
    "text": "8.3 Fisher’s Exact Test\nFisher’s exact test is an “exact test” in that the p-value is calculated exactly from the hypergeometric distribution rather than relying on the approximation that the test statistic distribution approaches \\(\\chi^2\\) as \\(n \\rightarrow \\infty\\). The test is applicable in situations where\n\nthe row totals \\(n_{i+}\\) and the column totals \\(n_+j\\) are fixed by study design (rarely applies), and\nthe expected values of &gt;20% of cells (at least 1 cell in a 2x2 table) have expected cell counts &gt;5, and no expected cell count is &lt;1.\n\nThe p-value from the test is computed as if the margins of the table are fixed. This leads under a null hypothesis of independence to a hypergeometric distribution of the numbers in the cells of the table (Wikipedia). Fisher’s exact test is useful for small n-size samples where the chi-squared distribution assumption of the chi-squared and G-test tests fails. Fisher’s exact test is overly conservative (p-values too high) for large n-sizes.\nThe Hypergeometric density function is \\[f_X(k|N, K, n) = \\frac{{{K}\\choose{k}}{{N-K}\\choose{n-k}}}{{N}\\choose{n}}. \\tag{8.5}\\]\nThe density is the exact hypergeometric probability of observing this particular arrangement of the data, assuming the given marginal totals, on the null hypothesis that the conditional probabilities are equal.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binomial ~ Binomial</span>"
    ]
  },
  {
    "objectID": "08-binomial-binomial.html#case-study",
    "href": "08-binomial-binomial.html#case-study",
    "title": "8  Binomial ~ Binomial",
    "section": "8.4 Case Study",
    "text": "8.4 Case Study\nThis case study uses a data set from Laerd and a second version modified to have small sample size. The first data set passes the Z-test requirements. The second (in parentheses), fails the sample sizes condition.\n\nz_dat &lt;- read.spss(\n  \"./input/test-of-two-proportions-individual-scores.sav\",\n  to.data.frame = TRUE\n)\n\nfisher_dat &lt;- z_dat[seq(2, 100, 2),]\n\nA researcher recruits 100 (50) patients who have a “high” classification of cholesterol and a poor lifestyle. The researcher randomly assigns 50 (25) of them to a drug intervention and 50 (25) to a lifestyle intervention. After six months, a doctor reclassifies the patients’ cholesterol classification as either “high” or “normal”.\n\n\nShow the code\nbind_rows(\n  `Larger Sample (n = 50, 50)` = z_dat,\n  `Smaller Sample (n = 25, 25)` = fisher_dat,\n  .id = \"set\"\n) |&gt;\n  count(set, intervention, risk_level) %&gt;%\n  summarize(\n    .by = c(set, intervention),\n    p = sum(if_else(risk_level == \"Normal\", n, as.integer(0))) / sum(n),\n    n = sum(n),\n    se = sqrt(p * (1 - p) / n),\n    ci_lwr = p - qt(.975, n - 1) * se,\n    ci_upr = p + qt(.975, n - 1) * se\n  ) %&gt;%\n  ggplot(aes(x = intervention)) +\n  geom_col(aes(y = p), fill = \"snow3\", color = \"snow4\", width = 0.25) +\n  geom_errorbar(aes(ymin = ci_lwr, ymax = ci_upr), color = \"snow4\", width = .125) +\n  theme_minimal() +\n  scale_y_continuous(labels = scales::percent) +\n  facet_wrap(vars(set)) +\n  labs(x = NULL, y = NULL,\n       title = \"Cholesterol Classification Improvement from High to Normal\",\n       subtitle = \"Two data sets with different sample sizes.\",\n       caption = \"Error bars show 95% CI.\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nx &lt;-\n  z_dat |&gt; \n  gtsummary::tbl_cross(\n    row = intervention, \n    col = risk_level, \n    percent = \"row\", \n    label = list(intervention = \"Intervention\", risk_level = \"Risk Level\")\n  )\n\ny &lt;- \n  fisher_dat |&gt; \n  gtsummary::tbl_cross(\n    row = intervention, \n    col = risk_level, \n    percent = \"row\", \n    label = list(intervention = \"Intervention\", risk_level = \"Risk Level\")\n  )\n\ngtsummary::tbl_merge(\n  list(x, y), \n  tab_spanner = c(\"Larger Sample\", \"Smaller Sample\")\n) |&gt;\n  gtsummary::as_gt() |&gt;\n  gt::tab_header(title = \"Summary statistics, Z-Test case, Fisher test case.\") |&gt;\n  gt::tab_options(heading.align = \"left\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary statistics, Z-Test case, Fisher test case.\n\n\n\n\nLarger Sample\n\n\nSmaller Sample\n\n\n\nHigh\nNormal\nTotal\nHigh\nNormal\nTotal\n\n\n\n\nIntervention\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Drug\n18 (36%)\n32 (64%)\n50 (100%)\n9 (36%)\n16 (64%)\n25 (100%)\n\n\n    Lifestyle\n33 (66%)\n17 (34%)\n50 (100%)\n16 (64%)\n9 (36%)\n25 (100%)\n\n\nTotal\n51 (51%)\n49 (49%)\n100 (100%)\n25 (50%)\n25 (50%)\n50 (100%)\n\n\n\n\n\n\n\n\nZ-Test\nThere is no R function that performs a two-sample Z-test. Let’s do it manually.\n\ndat_drug &lt;- z_dat |&gt; filter(intervention == \"Drug\")\ndat_lifestyle &lt;- z_dat |&gt; filter(intervention == \"Lifestyle\")\n\nn_drug &lt;- nrow(dat_drug)\nn_lifestyle &lt;- nrow(dat_lifestyle)\n\np_drug &lt;- mean(dat_drug$risk_level == \"Normal\")\np_lifestyle &lt;- mean(dat_lifestyle$risk_level == \"Normal\")\np_pool &lt;- mean(z_dat$risk_level == \"Normal\")\n\nse &lt;- sqrt(p_pool * (1 - p_pool) * (1 / n_drug + 1 / n_lifestyle))\n(z &lt;- (p_drug - p_lifestyle) / se)\n## [1] 3.0006\n(p_value &lt;- pnorm(z, lower.tail = FALSE) * 2) # mult by 2 for two-sided test.\n## [1] 0.002694481\n\n\n100 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 50 in each intervention. The test of two proportions used was the two sample Z-test. At the conclusion of the drug intervention, 32 patients (64%) had improved their cholesterol classification from high to normal compared to 17 patients (34%) in the lifestyle intervention, a difference in proportions of 0.30, p = 0.0027.\n\n\n\nChi-Square\nThe chi-square test achieves an identical result. The X-squared value is double the Z statistic and the p values are identical.\n\n(chisq_test &lt;- z_dat %&gt;%\n  tabyl(intervention, risk_level) %&gt;%\n  chisq.test(correct = FALSE))\n\n\n    Pearson's Chi-squared test\n\ndata:  .\nX-squared = 9.0036, df = 1, p-value = 0.002694\n\n\n\n100 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 50 in each intervention. The test of two proportions used was the chi-square test of homogeneity. At the conclusion of the drug intervention, 32 patients (64%) had improved their cholesterol classification from high to normal compared to 17 patients (34%) in the lifestyle intervention, a difference in proportions of 0.30, p = 0.0027.\n\n\n\nFisher’s Exact\nUse the Fisher exact test from the janitor package.\n\n(fisher_test &lt;- fisher_dat %&gt;%\n  tabyl(intervention, risk_level) %&gt;%\n  fisher.test())\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  .\np-value = 0.08874\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.08497039 1.15362199\nsample estimates:\nodds ratio \n 0.3241952 \n\n\n\n50 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 25 in each intervention. At the conclusion of the drug intervention, 16 patients (64%) had improved their cholesterol classification from high to normal compared to 9 patients (36%) in the lifestyle intervention. Due to small sample sizes, Fisher’s exact test was run. There was a non-statistically significant difference in proportions of 0.28, p = 0.0887.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Binomial ~ Binomial</span>"
    ]
  },
  {
    "objectID": "09-multinomial-multinomial.html",
    "href": "09-multinomial-multinomial.html",
    "title": "9  Multinomial ~ Multinomial",
    "section": "",
    "text": "9.1 Chi-Square Test of Homogeneity\nThe chi-square test of homogeneity tests whether frequency counts of the R levels of a categorical variable are distributed identically across the C populations. It tests whether observed joint frequency counts \\(O_{ij}\\) differ from expected frequency counts \\(E_{ij}\\) under the independence model (the model of independent explanatory variables, \\(\\pi_{ij} = \\pi_{i+} \\pi_{+j}\\). \\(H_0\\) is \\(O_{ij} = E_{ij}\\). The chi-square homogeneity test can be extended to cases where \\(I\\) and/or \\(J\\) is greater than 2.\nThere are two possible test statistics for this test, Pearson \\(X^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\), and deviance \\(G^2 = 2 \\sum_{ij} O_{ij} \\log \\left( \\frac{O_{ij}}{E_{ij}} \\right)\\).\nSide note: z-Test of Two Proportions\nThe z-test and chi-square test produce the same statistical significance result because they are algebraically identical.\nThe z-test uses the difference in sample proportions \\(\\hat{d} = p_1 - p_2\\) as an estimate of the difference in population proportions \\(\\delta = \\pi_1 - \\pi_2\\) to evaluate an hypothesized difference in population proportions \\(d_0 = \\pi_0 - \\pi_1\\) and/or construct a \\((1−\\alpha)\\%\\) confidence interval around \\(\\hat{d}\\) to estimate \\(\\delta\\) within a margin of error \\(\\epsilon\\).\nThe z-test applies when the central limit theorem conditions hold so that the normal distribution approximates the binomial distribution.\nIf these conditions hold, the sampling distribution of \\(\\delta\\) is normally distributed around \\(\\hat{d}\\) with standard error \\(se_\\hat{d} = \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 − p_2)}{n_2}}\\). The measured values \\(\\hat{d}\\) and \\(se_\\hat{d}\\) approximate the population values \\(\\delta\\) and \\(se_\\delta\\). Define a \\((1 − \\alpha)\\%\\) confidence interval as \\(\\hat{d} \\pm z_{\\alpha / 2}se_\\hat{d}\\) or test the hypothesis of \\(d = d_0\\) with test statistic \\(z = \\frac{\\hat{d} − d_0}{se_{d_0}}\\) where \\(se_{d_0} = \\sqrt{p^*(1 - p^*) \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\\) and \\(p^*\\) is the overall success probability.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multinomial ~ Multinomial</span>"
    ]
  },
  {
    "objectID": "09-multinomial-multinomial.html#sec-chisqhomogeneity",
    "href": "09-multinomial-multinomial.html#sec-chisqhomogeneity",
    "title": "9  Multinomial ~ Multinomial",
    "section": "",
    "text": "the sample is independently drawn, meaning random assignment (experiments) or random sampling without replacement from \\(n &lt; 10\\%\\) of the population (observational studies),\nthere are at least \\(n_i p_i &gt;= 5\\) successes and \\(n_i (1 - p_i) &gt;= 5\\) failures for each group \\(i\\),\nthe sample sizes are both \\(n_i &gt;= 30\\), and\nthe probability of success for each group is not extreme, \\(0.2 &lt; \\pi_i &lt; 0.8\\).",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multinomial ~ Multinomial</span>"
    ]
  },
  {
    "objectID": "09-multinomial-multinomial.html#sec-fisherexact",
    "href": "09-multinomial-multinomial.html#sec-fisherexact",
    "title": "9  Multinomial ~ Multinomial",
    "section": "9.2 Fisher’s Exact Test",
    "text": "9.2 Fisher’s Exact Test\nFisher’s exact test is an “exact test” in that the p-value is calculated exactly from the hypergeometric distribution rather than relying on the approximation that the test statistic distribution approaches \\(\\chi^2\\) as \\(n \\rightarrow \\infty\\).\nThe test is applicable in situations where\n\nthe row totals \\(n_{i+}\\) and the column totals \\(n_+j\\) are fixed by study design (rarely applies), and\nthe expected values of &gt;20% of cells (at least 1 cell in a 2x2 table) have expected cell counts &gt;5, and no expected cell count is &lt;1.\n\nThe p-value from the test is computed as if the margins of the table are fixed. This leads under a null hypothesis of independence to a hypergeometric distribution of the numbers in the cells of the table (Wikipedia). Fisher’s exact test is useful for small n-size samples where the chi-squared distribution assumption of the chi-squared and G-test tests fails. Fisher’s exact test is overly conservative (p values too high) for large n-sizes.\nThe Hypergeometric density function is \\[f_X(k|N, K, n) = \\frac{{{K}\\choose{k}}{{N-K}\\choose{n-k}}}{{N}\\choose{n}}.\\]\nThe density is the exact hypergeometric probability of observing this particular arrangement of the data, assuming the given marginal totals, on the null hypothesis that the conditional probabilities are equal.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multinomial ~ Multinomial</span>"
    ]
  },
  {
    "objectID": "09-multinomial-multinomial.html#case-study-4",
    "href": "09-multinomial-multinomial.html#case-study-4",
    "title": "9  Multinomial ~ Multinomial",
    "section": "Case Study 4",
    "text": "Case Study 4\nThe case study below uses a data set from Laerd and a second modified version. The first data set passes the chi-square test of homogeneity requirements. The second (in parentheses), fails the n-sizes test.\nA researcher recruits 100 (50) patients who have a “high” classification of cholesterol and who currently have a poor lifestyle. The researcher randomly assigns 50 (25) of them to a drug intervention and 50 (25) to a lifestyle intervention. After six months, a doctor reclassifies the patients as either still having a “high” classification of cholesterol or now having a “normal” classification of cholesterol.\n\n\n\n\n\n\n\n\n\nThe chi-sq data set has the following summary statistics.\nThe Fisher data set has the following summary statistics.\n\nConditions\n\nn-Size\nThe chi-square test of homogeneity applies with the CLT conditions hold.\n\nthe sample is independently drawn,\nthere are at least 5 successes (Normal) and failures (High) for each group \\(i\\),\nthe sample sizes for both groups are &gt;=30, and\nthe probability of success for each group is not extreme, \\(0.2 &lt; \\pi_i &lt; 0.8\\).\n\nThe conditions hold for the chi-sq data set, but not for the Fisher data set.\n\n\n\nTest\n\nChi-Square\n\n(ind_discrete$chisq_test &lt;- ind_discrete$chisq_dat %&gt;%\n  tabyl(intervention, risk_level) %&gt;%\n  chisq.test(correct = FALSE))\n\n\n    Pearson's Chi-squared test\n\ndata:  .\nX-squared = 9.0036, df = 1, p-value = 0.002694\n\n\n\n100 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 50 in each intervention. The test of two proportions used was the chi-square test of homogeneity. At the conclusion of the drug intervention, 32 patients (64%) had improved their cholesterol classification from high to normal compared to 17 patients (34%) in the lifestyle intervention, a difference in proportions of 0.30, p = 0.0027.\n\n\n\nFisher\n\n(ind_discrete$fisher_test &lt;- ind_discrete$fisher_dat %&gt;%\n  tabyl(intervention, risk_level) %&gt;%\n  fisher.test())\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  .\np-value = 0.08874\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.08497039 1.15362199\nsample estimates:\nodds ratio \n 0.3241952 \n\n\n\n50 patients with a high cholesterol classification were randomly assigned to either a drug or lifestyle intervention, 25 in each intervention. At the conclusion of the drug intervention, 16 patients (64%) had improved their cholesterol classification from high to normal compared to 9 patients (36%) in the lifestyle intervention. Due to small sample sizes, Fisher’s exact test was run. There was a non-statistically significant difference in proportions of 0.28, p = 0.0887.",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multinomial ~ Multinomial</span>"
    ]
  },
  {
    "objectID": "10-binomial-multinomial-pairwise.html",
    "href": "10-binomial-multinomial-pairwise.html",
    "title": "10  Pairwise Discrete ~ Multinomial",
    "section": "",
    "text": "10.1 Pairwise Prop Test\nlibrary(tidyverse)\nM &lt;- 3573\nF &lt;- 4177\ndat &lt;- tribble(\n  ~gender, ~src, ~Y, ~N,\n  \"Male\", \"Indeed\", 1699, M-1699,\n  \"Male\", \"LinkedIn\", 1755, M-1755,\n  \"Male\", \"Google\", 1578, M-1578,\n  \"Female\", \"Indeed\", 2554, F-2554,\n  \"Female\", \"LinkedIn\", 1914, F-1914,\n  \"Female\", \"Google\", 1694, F-1694\n)\nprop.test(x = dat$Y, n = dat$Y + dat$N)\n\n\n    6-sample test for equality of proportions without continuity correction\n\ndata:  dat$Y out of dat$Y + dat$N\nX-squared = 412.66, df = 5, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\nsample estimates:\n   prop 1    prop 2    prop 3    prop 4    prop 5    prop 6 \n0.4755108 0.4911839 0.4416457 0.6114436 0.4582236 0.4055542 \n\npairwise.prop.test(x = dat$Y, n = dat$Y + dat$N)\n\n\n    Pairwise comparisons using Pairwise comparison of proportions \n\ndata:  dat$Y out of dat$Y + dat$N \n\n  1       2       3       4       5      \n2 0.40250 -       -       -       -      \n3 0.02026 0.00021 -       -       -      \n4 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 -       -      \n5 0.40250 0.02026 0.40250 &lt; 2e-16 -      \n6 6.3e-09 4.8e-13 0.00873 &lt; 2e-16 1.1e-05\n\nP value adjustment method: holm",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pairwise Discrete ~ Multinomial</span>"
    ]
  },
  {
    "objectID": "10-binomial-multinomial-pairwise.html#sec-mcnemar",
    "href": "10-binomial-multinomial-pairwise.html#sec-mcnemar",
    "title": "10  Pairwise Discrete ~ Multinomial",
    "section": "10.2 McNemar’s Test",
    "text": "10.2 McNemar’s Test\nThis test applies when you have paired samples.\nWilcoxon Paired-Sample applies when the variable distributions are non-normally distributed and samples are paired.\n\n10.2.1 MANOVA\nMulti-factor ANOVA (MANOVA) is a method to compare mean responses by treatment factor level of two or more treatments applied in combination. The null hypotheses are \\(H_0: \\mu_{1.} = \\mu_{2.} = \\dots = \\mu_{a.}\\) for the \\(a\\) levels of factor 1, \\(H_0: \\mu_{.1} = \\mu_{.2} = \\dots = \\mu_{.b}\\) for the \\(b\\) levels of factor 2, etc. for all the factors in the experiment, and $H_0: $ no interaction for all the factor interactions.\nThere are two equivalent ways to state the MANOVA model:\n\\[Y_{ijk} = \\mu_{ij} + \\epsilon_{ijk}\\]\nIn this notation \\(Y_{ijk}\\) refers to the \\(k^{th}\\) observation in the \\(j^{th}\\) level of factor two and the \\(i^{th}\\) level of factor 1. Potentially there could be additional factors. This model formulation decomposes the response into a cell mean and an error term. The second makes the factor effect more explicit and is thus more common:\n\\[Y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} +  \\epsilon_{ijk}\\]\n\n\n10.2.2 Multiple Variance Comparison F Test\n\n\n10.2.3 Example\nA study investigates the relationship between oxygen update and two explanatory variables: smoking, and type of stress test. A sample of \\(n = 27\\) persons, 9 non-smoking, 9 moderately-smoking, and 9 heavy-smoking are divided into three stress tests, bicycle, treadmill, and steps and their oxygen uptake was measured. Is oxygen uptake related to smoking status and type of stress test? Is there an interaction effect between smoking status and type of stress test?\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(nortest)  # for Anderson-Darling test\nlibrary(stats)  # for anova\n\nsmoker &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, \n            2, 2, 2, 2, 2, 2, 2, 2, 2, \n            3, 3, 3, 3, 3, 3, 3, 3, 3)\nstress &lt;- c(1, 1, 1, 2, 2, 2, 3, 3, 3,\n            1, 1, 1, 2, 2, 2, 3, 3, 3,\n            1, 1, 1, 2, 2, 2, 3, 3, 3)\noxytime &lt;- c(12.8, 13.5, 11.2, 16.2, 18.1, 17.8, 22.6, 19.3, 18.9,\n             10.9, 11.1, 9.8, 15.5, 13.8, 16.2, 20.1, 21.0, 15.9,\n             8.7, 9.2, 7.5, 14.7, 13.2, 8.1, 16.2, 16.1, 17.8)\noxy &lt;- data.frame(oxytime, smoker, stress)\noxy$smoker &lt;- ordered(oxy$smoker,\n                      levels = c(1, 2, 3),\n                      labels = c(\"non-smoker\", \"moderate\", \"heavy\"))\noxy$stress &lt;- factor(oxy$stress,\n                     labels = c(\"bicycle\", \"treadmill\", \"steps\"))\n\nlm_oxy &lt;- lm(oxytime~smoker+stress+smoker*stress, data = oxy)\nanova(lm_oxy)\n\nAnalysis of Variance Table\n\nResponse: oxytime\n              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsmoker         2  84.899  42.449 12.8967 0.0003348 ***\nstress         2 298.072 149.036 45.2793 9.473e-08 ***\nsmoker:stress  4   2.815   0.704  0.2138 0.9273412    \nResiduals     18  59.247   3.291                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSFU BIO710",
    "crumbs": [
      "Group Differences",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pairwise Discrete ~ Multinomial</span>"
    ]
  },
  {
    "objectID": "11-association.html",
    "href": "11-association.html",
    "title": "11  Association",
    "section": "",
    "text": "11.1 Pearson’s Correlation\nTests of association assess the strength of association between two variables. There are many variations on this theme.\nPearson’s correlation assesses the strength of a linear relationship between two continuous variables. It applies when the relationship is linear with no outliers and the variables are bi-variate normal. There are two less restrictive alternatives, Spearman’s rho and Kendall’s tau, that assess the strength and direction of association.\nA two-way frequency table is a frequency table for two categorical variables. You usually construct a two-way table to test whether the frequency counts in one categorical variable differ from the other categorical variable using the chi-square test for independence or G-test, or Fisher’s exact test. If there is a significant difference (i.e., the variables are related), then describe the relationship with an analysis of the residuals, calculations of measures of association (difference in proportions, Phi and Cramer’s V, Relative risks, or Odds Ratio), and partition tests.\nIf one of the variables is bivariate categorical, use point-biserial correlation, a special case of Pearson’s correlation. Pearson’s partial correlation controls for one or more variables - linear regression?\nIf both variables are ordinal, use Goodman and Kruskal’s gamma. Somers’ d is an alternative if you want to distinguish between a dependent and independent variable (instead of linear regression?). The Mantel-Haenszel test of trend is used to determine whether there is a linear trend (i.e., a linear relationship/association) between two ordinal variables that are represented in a contingency table. The Cochran-Armitage test of trend is used to determine whether there is a linear trend (i.e., a linear relationship/association) between an ordinal independent variable and a dichotomous dependent variable.\nGoodman and Kruskal’s λ is a nonparametric measure of the strength of association between two nominal variables where a distinction is made between a dependent and independent variable\nLoglinear analysis is used to understand (and model) associations between two or more categorical variables (i.e., nominal or ordinal variables). However, loglinear analysis is usually employed when dealing with three or more categorical variables, as opposed to two variables, where a chi-square test for association is usually conducted instead.\nThere are three common correlation tests for categorical variables1: Tetrachoric correlation for binary categorical variables; polychoric correlation for ordinal categorical variables; and Cramer’s V for nominal categorical variables.\nThe Pearson product-moment correlation measures the strength and direction of a linear relationship between two continuous variables, x and y. The Pearson correlation coefficient, r, ranges from -1 (perfect negative linear relationship) to +1 (perfect positive linear relationship). A value of 0 indicates no relationship between two variables.\n\\[r_{x,y} = \\frac{\\text{Cov}(x,y)}{\\text{SD}(x) \\text{SD}(y)}\\]\nThe statistic can be used as an estimate of the population correlation, \\(\\rho\\), in a test of statistical significance from 0 (H0: \\(\\rho\\) = 0).\n\\[\\rho_{X,Y} = \\frac{\\text{Cov}(X,Y)}{\\text{SD}(X) \\text{SD}(Y)}\\]\nAs rule of thumb, \\(|r|\\) &lt;.1 is no correlation, [.1, .3) is small, [.3, .5) is moderate, and [.5, 1.0] is strong. The test statistic follows a t-distribution with n − 2 degrees of freedom.\n\\[t = r_{x,y} \\sqrt{\\frac{n - 2}{1 - r^2_{x,y}}}\\]",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#spearman",
    "href": "11-association.html#spearman",
    "title": "11  Association",
    "section": "11.2 Spearman’s Rho",
    "text": "11.2 Spearman’s Rho\nSpearman’s ranked correlation (Spearman’s rho) is a measure of the strength and direction of a monotonic relationship between two variables that are at least ordinal. Spearman’s correlation is a non-parametric alternative to Pearson when one or more of its conditions are violated. Unlike Pearson, the relationship need not be linear (it only needs to be monotonic), and has no outliers or bivariate normality conditions.\nSpearman’s correlation is Pearson’s correlation applied to the ranks of variables (for ordinal variables, their value already is a rank). However, there is also a second definition that gives the same result, at least when there are no ties in the ranks:\n\\[\\rho = 1 - \\frac{6 \\sum_i d^2_i}{n(n^2 - 1)}\\]\nwhere \\(d_i\\) is the difference in ranks of observation \\(i\\).",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#kendall",
    "href": "11-association.html#kendall",
    "title": "11  Association",
    "section": "11.3 Kendal’s Tau",
    "text": "11.3 Kendal’s Tau\nKendal’s tau is a second alternative to Pearson and is identical to Spearman’s rho with regard to assumptions. Kendal’s tau only differs from Spearman’s rho in how it measures the relationship. Whereas Spearman measures the correlation of the ranks, Kendal’s tau is a function of concordant (C), discordant (D) and tied (Tx and Ty) pairs of observations. Concordant means both X and Y in one observation of a pair are larger than in the other. Discordant means X is larger in one observation than the other while Y is smaller. Tied mean either both observations have the same X or both have the same Y.\n\\[\\mathrm{Kendall's} \\space \\tau_b = \\frac{C - D}{\\sqrt{(C + D + T_x) \\times (C + D + T_Y)}}\\]",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#case-study-pearson-spearman-kendall",
    "href": "11-association.html#case-study-pearson-spearman-kendall",
    "title": "11  Association",
    "section": "11.4 Case Study: Pearson, Spearman, Kendall",
    "text": "11.4 Case Study: Pearson, Spearman, Kendall\nThis case study works with two data sets. dat1 is composed of two continuous variables; dat2 is composed of two ordinal variables.\nA researcher investigates the relationship between cholesterol concentration and time spent watching TV, time_tv, in n = 100 otherwise healthy 45 to 65 year old men (dat1). This data set will meet the conditions for Pearson, so we try all three tests on it.\nA researcher investigates the relationship between the level of agreement with the statement “Taxes are too high” (tax_too_high, four level ordinal) and participant income level (three level ordinal) (dat2). The ordinal variables rule out Pearson, leaving Spearman and Kendall.\n\nConditions\nPearson’s correlation applies when X and Y are continuous (interval or ratio) paired variables with 1) a linear relationship that 2) has no significant outliers, and 3) are bivariate normal. Spearman’s rho and Kendall’s tau only require that X and Y be at least ordinal with 1) a monotonically increasing or decreasing relationship.\n\nLinearity and Monotonicity. A visual inspection of a scatterplot should find a linear relationship (Pearson) or monotonic relationship (Spearman and Kendall).\n\nPearson’s correlation additionall requires\n\nNo Outliers. Identify outliers with the scatterplot.\nNormality. Bivariate normality is difficult to assess. Instead, check that each variable is individually normally distributed. Use the Shapiro-Wilk test.\n\n\nLinearity / Monotonicity\nAssess linearity and monotonicity with a scatter plot. dat1 is plotted on the left in Figure @ref(fig:ccscatter). A second version that fails the linearity test is shown to the right. If the linear relationship assumption fails, consider transforming the variable instead of reverting to Spearman or Kendall.\n\n\n\n\nThe left scatter plot is dat1. It meets Pearson’s linearity condition. A second version at right illustrates what a failure might look like.\n\n\n\n\n\nThe ordinal variable data set dat2 is plotted in Figure @ref(fig:ooscatter).\n\n\n\n\ndat2 meets the mononicity assumption for Spearman’s rho and Kendall’s tau.\n\n\n\n\n\n\n\nNo Outliers\nPearson’s correlation requires no outliers. Both plots in Figure @ref(fig:ccscatter) are free of outliers. If there were outliers, check whether they are data entry errors or measurement errors and fix or discard them. If the outliers are genuine, leave them in if they do not affect the conclusion. You can also try tranforming the variable. Failing all that, revert to the Spearman’s rho or Kendall’s tau.\n\n\nBivariate Normality\nBivariate normality is difficult to assess. If two variables are bivariate normal, they will each be individually normal as well. That’s the best you can hope to check for. Use the Shapiro-Wilk test.\n\nshapiro.test(cs$dat1$time_tv)\n## \n##  Shapiro-Wilk normality test\n## \n## data:  cs$dat1$time_tv\n## W = 0.97989, p-value = 0.1304\nshapiro.test(cs$dat1$cholesterol)\n## \n##  Shapiro-Wilk normality test\n## \n## data:  cs$dat1$cholesterol\n## W = 0.97594, p-value = 0.06387\n\nIf a variable is not normally distributed, you can transform it, carry on regardless since the Pearson correlation is fairly robust to deviations from normality, or revert to Spearman and Kendall.\n\n\n\nTest\nCalculate Pearson’s correlation, Spearman’s rho, or Kendall’s tau. dat meets the assumptions for Pearson’s correlation, but try Spearman’s rho and Kendall’s tau too, just to see how close they come to Pearson. dat2 only meets the assumptions for Spearman and Kendall.\n\nPearson’s Correlation\ndat1 met the conditions for Pearson’s correlation.\n\n(cs$cc_pearson &lt;- \n  cor.test(cs$dat1$cholesterol, cs$dat1$time_tv, method = \"pearson\")\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  cs$dat1$cholesterol and cs$dat1$time_tv\nt = 3.9542, df = 98, p-value = 0.0001451\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1882387 0.5288295\nsample estimates:\n      cor \n0.3709418 \n\n\nr = 0.37 falls in the range of a “moderate” linear relationship. \\(r^2\\) = 14% is the coefficient of determination. Interpret it as the percent of variability in one variable that is explained by the other. If you are not testing a hypothesis (HO: \\(\\rho \\ne 0\\)), you can report just report r. Otherwise, include the p-value. Report your results like this:\n\nA Pearson’s product-moment correlation was run to assess the relationship between cholesterol concentration and daily time spent watching TV in males aged 45 to 65 years. One hundred participants were recruited.\nPreliminary analyses showed the relationship to be linear with both variables normally distributed, as assessed by Shapiro-Wilk’s test (p &gt; .05), and there were no outliers.\nThere was a statistically significant, moderate positive correlation between daily time spent watching TV and cholesterol concentration, r(98) = 0.37, p &lt; .0005, with time spent watching TV explaining 14% of the variation in cholesterol concentration.\n\nYou wouldn’t use Spearman’s rho or Kendall’s tau here since the more precise Pearson’s correlation is available. But just out of curiosity, here are the correlations using those two measures.\n\ncor(cs$dat1$cholesterol, cs$dat1$time_tv, method = \"kendall\")\n## [1] 0.2383971\ncor(cs$dat1$cholesterol, cs$dat1$time_tv, method = \"spearman\")\n## [1] 0.3322122\n\nBoth Kendall and Spearman produced more conservative estimates of the strength of the relationship - Kendall especially so.\nYou probably wouldn’t use linear regression here either because it describes the linear relationship between a response variable and changes to an independent explanatory variable. Even though we are reluctant to interpret a regression model in terms of causality, that is what is implied the formulation y ~ x and independence assumption in of X. Nevertheless, correlation and regression are related. The slope term in a simple linear regression of the normalized values equals the Pearson correlation.\n\nlm(\n  y ~ x, \n  data = cs$dat1 %&gt;% mutate(y = scale(cholesterol), x = scale(time_tv))\n)\n\n\nCall:\nlm(formula = y ~ x, data = cs$dat1 %&gt;% mutate(y = scale(cholesterol), \n    x = scale(time_tv)))\n\nCoefficients:\n(Intercept)            x  \n -3.092e-16    3.709e-01  \n\n\n\n\nSpearman’s Rho\nData set dat2 did not meet the conditions for Pearson’s correlation, so use Spearman’s rho and/or Kendall’s tau.\nStart with Spearman’s rho. Recall that Spearman’s rho is just the Pearson correlation applied to the ranks. Recall also that the Pearson’s correlation is just the covariance divided by the product of the standard deviations. You can quickly calculate it by hand.\n\ncov(rank(cs$dat2$income), rank(cs$dat2$tax_too_high)) /\n  (sd(rank(cs$dat2$income)) * sd(rank(cs$dat2$tax_too_high)))\n\n[1] 0.6024641\n\n\nUse the function though. I don’t get why cor.test requires x and y be numeric.\n\n(cs$spearman &lt;- \n  cor.test(\n    as.numeric(cs$dat2$tax_too_high), \n    as.numeric(cs$dat2$income), \n    method = \"spearman\")\n)\n\n\n    Spearman's rank correlation rho\n\ndata:  as.numeric(cs$dat2$tax_too_high) and as.numeric(cs$dat2$income)\nS = 914.33, p-value = 0.001837\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6024641 \n\n\nInterpret the statistic using the same rule of thumb as for Pearson’s correlation. A rho over .5 is a strong correlation.\n\nA Spearman’s rank-order correlation was run to assess the relationship between income level and views towards income taxes in 24 participants. Preliminary analysis showed the relationship to be monotonic, as assessed by visual inspection of a scatterplot. There was a statistically significant, strong positive correlation between income level and views towards income taxes, \\(r_s\\) = 0.602, p = 0.002.\n\n\n\nKendall’s Tau\nRecall that Kendall’s tau is a function of concordant (C), discordant (D) and tied (Tx and Ty) pairs of observations. The manual calculation is a little more involved. Here is the function instead.\n\n(cs$kendall &lt;- \n  cor.test(\n    as.numeric(cs$dat2$tax_too_high), \n    as.numeric(cs$dat2$income), \n    method = \"kendall\")\n)\n\n\n    Kendall's rank correlation tau\n\ndata:  as.numeric(cs$dat2$tax_too_high) and as.numeric(cs$dat2$income)\nz = 2.9686, p-value = 0.002991\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5345225 \n\n\nAs with the case study on cholesterol and television, Kendall’s tau was more conservative than Spearman’s rho. \\(\\tau_b\\) = 0.535 is still in the “strong” range, though just barely.\n\nA Kendall’s tau-b correlation was run to assess the relationship between income level and views towards income taxes amongst 24 participants. Preliminary analysis showed the relationship to be monotonic, as assessed by visual inspection of a scatterplot. There was a statistically significant, strong positive correlation between income level and the view that taxes were too high, \\(\\tau_b\\) = 0.535, p = 0.003.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#chisq-independence",
    "href": "11-association.html#chisq-independence",
    "title": "11  Association",
    "section": "11.5 Chi-Square Test of Independence",
    "text": "11.5 Chi-Square Test of Independence\nThe chi-square test of independence tests whether two categorical variables are associated, or are instead independent2. It tests whether the observed joint frequency counts \\(O_{ij}\\) differ from expected frequency counts \\(E_{ij}\\) under the independence model (the model of independent explanatory variables, \\(\\pi_{ij} = \\pi_{i+} \\pi_{+j}\\). The null hypothesis is \\(O_{ij} = E_{ij}\\). The test assumes the two variables are independent3 and that all cell counts are at least 5.\nChoose from two test statistics, Pearson \\(X^2\\) (and the continuity adjusted \\(X^2\\)), and deviance G. As \\(n \\rightarrow \\infty\\) their sampling distributions approach \\(\\chi^2(df)\\) with degrees of freedom (df) equal to the saturated model df \\(I \\times J - 1\\) minus the independence model df \\((I - 1) + (J - 1)\\), which you can algebraically solve for \\(df = (I - 1)(J - 1)\\).\nThe Pearson goodness-of-fit statistic is\n\\[X^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\]\nwhere \\(O_{ij}\\) is the observed count, and \\(E_{ij}\\) is the product of the row and column marginal probabilities. The deviance statistic is\n\\[G = 2 \\sum_{ij} O_{ij} \\log \\left( \\frac{O_{ij}}{E_{ij}} \\right)\\]\n\\(X^2\\) and G increase with the disagreement between the saturated model proportions \\(p_{ij}\\) and the independence model proportions \\(\\pi_{ij}\\).",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#fisher-exact",
    "href": "11-association.html#fisher-exact",
    "title": "11  Association",
    "section": "11.6 Fisher’s Exact Test",
    "text": "11.6 Fisher’s Exact Test\nWhereas the chi-squared and G-test rely on the approximation that the test statistic distribution approaches \\(\\chi^2\\) as \\(n \\rightarrow \\infty\\), Fisher’s exact test is an “exact test” in that the p-value is calculated exactly from the hypergeometric distribution. Therefore Fisher’s test should only apply only to 2 x 2 tables. For some reason, it doesn’t.4\nThe test assumes the row totals \\(n_{i+}\\) and the column totals \\(n_{+j}\\) are fixed by study design, and the expected values of at least 20% of cells in the table have expected cell count &gt;5, and no expected cell count is 0.\nThe famous example of the Fisher exact test is the “Lady tea testing” example. A lady claims she can guess whether the milk was poured into the cup before or after the tea. The experiment consists of 8 cups, 4 with milk poured first, 4 with milk poured second. The lady guesses correctly in 6 of the 8 cups.\n\n(tea &lt;- matrix(c(3, 1, 1, 3), nrow = 2, \n       dimnames = list(Guess = c(\"Milk\", \"Tea\"),\n                       Truth = c(\"Milk\", \"Tea\"))))\n\n      Truth\nGuess  Milk Tea\n  Milk    3   1\n  Tea     1   3\n\n\nThis is a hypergeometric distribution question because you want to know the probability of 3 or 4 successes in a sample of 4. If \\(X = k\\) is the count of successful events in a sample of size \\(n\\) without replacement from a population of size \\(N\\) containing \\(K\\) successes, then \\(X\\) is a random variable with a hypergeometric distribution\n\\[f_X(k|N, K, n) = \\frac{{{K}\\choose{k}}{{N-K}\\choose{n-k}}}{{N}\\choose{n}}.\\]\nThe formula follows from the frequency table of the possible outcomes. \\({K}\\choose{k}\\) is the number of ways to get k successes in K draws. \\({N-K}\\choose{n-k}\\) is the number of ways to fail to get k successes in K draws. And the denominator \\({N}\\choose{n}\\) is the total of all ways to succeed and fail.\n\ntibble::tribble(\n  ~` `, ~Sampled, ~`Not Sampled`,  ~Total,\n  \"success\", \"k\", \"K-k\", \"K\",\n  \"non-success\", \"n-k\", \"(N-K)-(n-k)\", \"N-K\",\n  \"Total\", \"n\", \"N-n\", \"N\"\n) %&gt;%\n  flextable::flextable() %&gt;%\n  flextable::autofit()\n\n SampledNot SampledTotalsuccesskK-kKnon-successn-k(N-K)-(n-k)N-KTotalnN-nN\n\n\nFunction choose() returns the binomial coefficient \\({{n}\\choose{k}} = \\frac{n!}{k!(n-k)!}\\). The probability of choosing correctly at least 3 times out of 4 is the number of combinations of k = 3 plus the number with k = 4 divided by the number of combinations of any outcome.\n\nk &lt;- 3; n &lt;- 4; K &lt;- 4; N &lt;- 8\n\nchoose(K, k) * choose(N-K, n-k) / choose(N, n) +\nchoose(K, k+1) * choose(N-K, n-(k+1)) / choose(N, n)\n\n[1] 0.2428571\n\n\nphyper() does this.5\n\n(pi &lt;- phyper(q = k-1, m = K, n = N-K, k = n, lower.tail = FALSE))\n\n[1] 0.2428571\n\n\nThe p-value from Fisher’s exact test is calculated this way.\n\nfisher.test(tea, alternative = \"greater\")\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tea\np-value = 0.2429\nalternative hypothesis: true odds ratio is greater than 1\n95 percent confidence interval:\n 0.3135693       Inf\nsample estimates:\nodds ratio \n  6.408309 \n\n\nThe odds ratio at the bottom is the odds of success divided by the odds of non-success. The sample odds ratio is (3/1) / (1/3) = 9, but the documentation for fisher.test() explains that this it calculates the conditional maximum likelihood estimate.6",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#case-study-chi-square-fisher",
    "href": "11-association.html#case-study-chi-square-fisher",
    "title": "11  Association",
    "section": "11.7 Case Study: Chi-Square, Fisher",
    "text": "11.7 Case Study: Chi-Square, Fisher\nA researcher investigates whether males and females enrolled in an Exercise Science degree course differ in the type of exercise then engage, competitive or non-competitive. They survey 25 males and 25 females.\n\ncs$or2x2 %&gt;% \n  gtsummary::tbl_cross(\n    percent = \"row\",\n    label = list(comp ~ \"Competitive\")\n  ) %&gt;%\n  gtsummary::add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompetitive\n\nTotal\np-value1\n\n\nYes\nNo\n\n\n\n\ngender\n\n\n\n\n\n\n0.023\n\n\n    Male\n18 (72%)\n7 (28%)\n25 (100%)\n\n\n\n\n    Female\n10 (40%)\n15 (60%)\n25 (100%)\n\n\n\n\nTotal\n28 (56%)\n22 (44%)\n50 (100%)\n\n\n\n\n\n1 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\nConditions\nUse the Chi-Square test of independence for nominal, independent variables. The test requires all cell counts to be greater than 5. If your data does not meet this condition, consider collapsing some levels. If you collapse all the way to a 2 x 2 cross-tabulation and still do not have at least 5 counts per cell, use Fisher’s exact test.\nUse Fisher’s exact test for dichotomous nominal, independent variables. The test is valid for cross-sectional samples, but not for prospective or retrospective samples.\n\n\nTest\n\nChi-Square\nTo see what’s going on, here is chi-square test done by hand. The expected values are the joint probabilities from the independence model (e.g., \\(E(\\mathrm{male}, {\\mathrm{yes}}) = \\pi_{\\mathrm{male}} \\times \\pi_{\\mathrm{yes}} \\times n\\)).\n\nexer_table &lt;- cs$or2x2 %&gt;% table()\nexpected &lt;- marginSums(exer_table, 1) %*% t(marginSums(exer_table, 2)) / sum(exer_table)\n(X2 &lt;- sum((exer_table - expected)^2 / expected))\n## [1] 5.194805\n(df &lt;- (2 - 1) * (2 - 1))\n## [1] 1\npchisq(X2, df, lower.tail = FALSE)\n## [1] 0.02265449\n\nAnd the G test.\n\n(G &lt;- 2 * sum(exer_table * log(exer_table / expected)))\n## [1] 5.294731\npchisq(G, df, lower.tail = FALSE)\n## [1] 0.02139004\n\nThe chisq.test() function applies the Yates continuity correction by default to correct for situations with small cell counts. The Yates continuity correction subtracts 0.5 from the \\(O_{ij} - E_{ij}\\) differences. Set correct = FALSE to suppress Yates. The Yates continuity correction only applies to 2 x 2 tables.\n\n(cs$or2x2_chisq.test &lt;- chisq.test(exer_table, correct = FALSE))\n\n\n    Pearson's Chi-squared test\n\ndata:  exer_table\nX-squared = 5.1948, df = 1, p-value = 0.02265\n\n\nCalculate the G test with DescTools::GTest().\n\n(cs$or2x2_g.test &lt;- DescTools::GTest(exer_table, correct = \"none\"))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  exer_table\nG = 5.2947, X-squared df = 1, p-value = 0.02139\n\n\nAs a side note, if the cell size &gt;5 condition is violated, you can use Monte Carlo simulation.\n\nchisq.test(exer_table, correct = FALSE, simulate.p.value = TRUE)\n\n\n    Pearson's Chi-squared test with simulated p-value (based on 2000\n    replicates)\n\ndata:  exer_table\nX-squared = 5.1948, df = NA, p-value = 0.04398\n\n\n\n\nFisher\nThe documentation for fisher.test() explains that the p-value is based on the the first element of the contingency table “with non-centrality parameter given by the odds ratio.” I don’t understand the odds ratio business and cannot figure out how it is calculated. It says in the documentation for the estimate value that “Note that the conditional Maximum Likelihood Estimate (MLE) rather than the unconditional MLE (the sample odds ratio) is used.”, so that may hold the answer.\nAt least the p-value I can calculate by hand.\n\nphyper(q = exer_table[1, 1] - 1,  # k minus 1\n       m = sum(exer_table[1, ]),  # K\n       n = sum(exer_table[2, ]),  # N - K\n       k = sum(exer_table[, 1]),  # n\n       lower.tail = FALSE) * 2\n\n[1] 0.04500454\n\n\n\n(cs$or2x2_fisher.test &lt;- fisher.test(exer_table))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  exer_table\np-value = 0.045\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  1.02531 15.01800\nsample estimates:\nodds ratio \n   3.74678 \n\n\n\n\nPost-Test: Phi, Cramer’s V\nThe problem with the chi-square test for association is that it does not measure the strength of any association. Two measures of associate are often calculated after the chi-squared or Fisher tests.\nCramer’s V is derived from the chi-square statistic. It restricts the statistic to a range of 0 to 1. 7 Values under .1 are considered poor evidence of association; &gt;.2 are “moderately strong” evidence.\n\\[V = \\sqrt{\\frac{\\chi^2 / n}{\\mathrm{min}(I, J) - 1}}\\]\n\n# by hand\nsqrt(cs$or2x2_chisq.test$statistic / sum(exer_table) / (min(2, 2) - 1))\n## X-squared \n## 0.3223292\n\n# from package\n(cs$or2x2_v &lt;- rcompanion::cramerV(exer_table))\n## Cramer V \n##   0.3223\n\nThe Phi Coefficient is defined\n\\[\\Phi = \\sqrt{\\frac{AD-BC}{(A+B)(C+D)(A+C)(B+D)}}\\]\nwhere A, B, C, and D are the four values of the 2 x 2 contingency table.\n\nmatrix(c(\"A\", \"C\", \"B\", \"D\"), nrow = 2)\n\n     [,1] [,2]\n[1,] \"A\"  \"B\" \n[2,] \"C\"  \"D\" \n\n\nSimilar to a Pearson Correlation Coefficient, a Phi Coefficient takes on values between -1 and 1.\n\n# by hand\ndet(matrix(exer_table, nrow = 2)) / \n  sqrt(prod(c(marginSums(exer_table, 1), marginSums(exer_table, 2))))\n## [1] 0.3223292\n\n# from package\n(cs$or2x2_phi &lt;- psych::phi(exer_table))\n## [1] 0.32\n\n\n\nReporting\n\nA chi-square test for association was conducted between gender and preference for performing competitive sport. All expected cell frequencies were greater than five. There was a statistically significant association between gender and preference for performing competitive sport, (\\(X^2\\)(1) = 5.195, p = 0.023. There was a moderately strong association between gender and preference for performing competitive sport, V = 0.322.\n\n\nA Fisher’s Exact test was conducted between gender and preference for performing competitive sport. There was a statistically significant association between gender and preference for performing competitive sport, p = 0.045.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#kruskals-lambda",
    "href": "11-association.html#kruskals-lambda",
    "title": "11  Association",
    "section": "11.8 Kruskal’s Lambda",
    "text": "11.8 Kruskal’s Lambda",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#relative-risk",
    "href": "11-association.html#relative-risk",
    "title": "11  Association",
    "section": "11.9 Relative Risk",
    "text": "11.9 Relative Risk",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#odds-ratio",
    "href": "11-association.html#odds-ratio",
    "title": "11  Association",
    "section": "11.10 Odds Ratio",
    "text": "11.10 Odds Ratio\nCalculate relative risks for dichotomous nominal, independent variables when one variable is independent, the other dependent. Relative risks are valid for prospective and retrospective cohort designs, randomized controlled trials (RCTs), and some types of cross-sectional studies, but not with case-control studies.\nCalculate odds ratios as an alternative to relative risk. It makes the same assumptions. Unlike relative risk, it is valid for all study designs.\n\ncs$or2\n\nNULL\n\n# Smoking vs Lung Cancer\n# https://statistics.laerd.com/premium/spss/rr2x2/relative-risk-2x2-in-spss.php\ncs$rr2x2 &lt;- read.spss(\n  \"./input/relative-risk-2x2-individual-scores.sav\", \n  to.data.frame = TRUE\n)",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#partial-correlation",
    "href": "11-association.html#partial-correlation",
    "title": "11  Association",
    "section": "11.11 Partial Correlation",
    "text": "11.11 Partial Correlation\nThe partial correlation of \\(\\textbf{Y}_j\\) and \\(\\textbf{Y}_k\\) is their correlation conditioned on sampling from a sub-population of \\(X\\). Express the sub-population as \\(\\textbf{Z} = \\begin{pmatrix}\\textbf{X}_1 \\\\ \\textbf{X}_2 \\end{pmatrix}\\) with partitioned mean vector \\(\\boldsymbol{\\bar{x}} = \\begin{pmatrix}\\boldsymbol{\\bar{x}}_1 \\\\ \\boldsymbol{\\bar{x}}_2 \\end{pmatrix}\\). The variance-covariance matrix is complicated by the covariances between \\(\\textbf{X}_1\\) and \\(\\textbf{X}_1\\), so the partition is a matrix of matrices, \\(\\boldsymbol{S} = \\begin{pmatrix} \\boldsymbol{S}_{11} & \\boldsymbol{S}_{12} \\\\ \\boldsymbol{S}_{21} & \\boldsymbol{S}_{22} \\end{pmatrix}\\). \\(\\boldsymbol{S}_{11}\\) and \\(\\boldsymbol{S}_{22}\\) are the variance-covariance matrices of \\(\\textbf{X}_1\\) and \\(\\textbf{X}_2\\), and \\(\\boldsymbol{S}_{12}\\) and \\(\\boldsymbol{S}_{21}\\) are the (identical) variance-covariance matrices between the variables in \\(\\textbf{X}_1\\) and the variables in \\(\\textbf{X}_2\\).\nPartitioning means you can express the mean, (\\(\\textbf{M}\\), and variance-covariance matrix, \\(\\textbf{CV}\\) of \\(Y\\) conditioned on \\(\\textbf{X} = \\textbf{x}_2\\).\n\\[\n\\begin{equation}\n\\textbf{M} = \\boldsymbol{\\bar{x}}_1 + \\boldsymbol{S}_{12} \\boldsymbol{S}_{22}^{-1} (\\textbf{x}_2 - \\boldsymbol{\\bar{x}}_2)\n\\end{equation}\n\\]\n\\[\n\\begin{equation}\n\\textbf{CV} = \\boldsymbol{S}_{11} - \\boldsymbol{S}_{12} \\boldsymbol{S}_{22}^{-1} \\boldsymbol{S}_{21}\n\\end{equation}\n(\\#eq:s06-cond-cov)\n\\]\nTo see what this means, consider the bi-variate case. Suppose height and weight are distributed \\(\\mu = \\begin{pmatrix} 175 \\\\ 71 \\end{pmatrix}\\) with variance-covariance matrix \\(\\boldsymbol{\\Sigma} = \\begin{pmatrix} 550 & 40 \\\\ 40 & 8 \\end{pmatrix}\\). The mean of height, \\(Y\\) given weight \\(\\textbf{X} = \\textbf{x}_2\\) is \\(\\textbf{M}_{\\textbf{Y.x}} = 175 + \\frac{40}{8} (x_2 - 71)\\). The variance is \\(\\textbf{v}_{\\textbf{Y.x}} = 550 = \\frac{40^2}{8}\\) (a constant).\nThe conditional mean of \\(\\textbf{Y}\\) given \\(\\textbf{X} = \\textbf{x}\\) is \\(\\mu_{\\textbf{Y.x}} = E(\\textbf{Y|X=x})\\). If the distribution is multivariate normal, then the conditional mean equals its overall mean plus an adjustment based how \\(\\textbf{Y}\\) varies with \\(\\textbf{X}\\) as a fraction of the variation of \\(\\textbf{X}\\) multiplied by the distance of \\(\\textbf{X}\\) from its mean.\n\\[\n\\begin{equation}\n\\mu_{\\textbf{Y.x}} = E(\\textbf{Y|X=x}) = \\mu_\\textbf{Y} + \\boldsymbol{\\Sigma}_\\textbf{YX} \\boldsymbol{\\Sigma}_\\textbf{X}^{-1} (\\textbf{x} - \\boldsymbol{\\mu}_\\textbf{X})\n\\end{equation}\n(\\#eq:s06-conditional-mean)\n\\]\nNote how if \\(\\textbf{x} = \\boldsymbol{\\mu}_\\textbf{X}\\) the conditional mean equals the overall mean. If the \\(\\textbf{X}\\)’s are generally positively correlated with the \\(\\textbf{Y}\\)’s, then \\(\\textbf{x} &gt; \\boldsymbol{\\mu}_\\textbf{X}\\) results in a positive adjustment, and vice-versa.\nhttps://online.stat.psu.edu/stat505/lesson/6/6.1\nThe conditional variance is \\(\\sigma_{\\textbf{Y.x}}^2 =E\\{ (\\textbf{Y} - \\boldsymbol{\\mu}_{\\textbf{Y.x}})^2 | \\textbf{X = x} \\}\\). The conditional covariance between \\(Y_i\\) and \\(Y_j\\) is \\(\\sigma_{i,j.\\textbf{x}} =E\\{ (Y_i - \\mu_{Y_i.x})(Y_j - \\mu_{Y_j.x}) | \\textbf{X = x} \\}\\). The variances and covariances can be collected into a variance-covariance matrix.\n\\[\n\\boldsymbol{\\Sigma}_{\\textbf{Y}.\\textbf{x}} = \\begin{pmatrix}\n\\sigma_{Y_{1}.\\textbf{X}} & \\sigma_{12.\\textbf{X}} & \\cdots & \\sigma_{1p.\\textbf{X}} \\\\\n\\sigma_{21.\\textbf{X}} & \\sigma_{Y_{2}.\\textbf{X}} & \\cdots & \\sigma_{2p.\\textbf{X}} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{p1.\\textbf{X}} & \\sigma_{p2.\\textbf{X}} & \\cdots & \\sigma_{Y_{p}.\\textbf{X}}\n\\end{pmatrix}\n\\]\nDivide the covariance of two variables by the product of their standard deviations to get the unconditional correlation, \\(r_{jk} = \\frac{s_{jk}}{s_j s_k}\\). \\(r_{jk}\\) estimates the population correlation, \\(\\rho_{jk} = \\frac{\\sigma_{jk}}{\\sigma_j \\sigma_k}\\). The partial correlation is \\(\\rho_{jk.\\textbf{X}} = \\frac{\\sigma_{jk.\\textbf{X}}}{\\sigma_{Y_j.\\textbf{X}} \\sigma_{Y_k.\\textbf{X}}}\\)\nTest the null hypothesis that \\(H_0: \\rho_{jk} = 0\\) with a t-test where\n\\[\nt = r_{jk}\\sqrt{\\frac{n-2}{1-r_{jk}^2}}\n\\]\nis distributed with \\(n - 2\\) degrees of freedom. The 95% CI is complicated by the [-1, 1] bounding of the data which creates skew. The 95% CI is formed from the Fisher transformation of the data,\n\\[\nz_{jk} = \\frac{1}{2} \\log \\frac{1 + r_{jk}}{1 - r_{jk}}\n\\]\n\\(z_{jk}\\) is distributed normally with variance \\(\\frac{1}{n - 3}\\).\nQuick Example.\n\n# 37x5 data set from [PSU STAT 505](https://online.stat.psu.edu/stat505/lesson/4/4.7).\nwechsler &lt;- readr::read_fwf(\n  file = \"./input/wechsler.txt\", \n  col_positions = readr::fwf_widths(\n    c(2, 3, 3, 3, 3),\n    col_names = c(\"ID\", \"Information\", \"Similarities\", \"Arithmetic\", \"PictureCompletion\")\n  ),\n  show_col_types = FALSE\n) \n\n# Correlation between Information and Similarities\ncor(wechsler$Information, wechsler$Similarities)\n## [1] 0.7715297\n\n# t.test with 95% CI.\ncor.test(wechsler$Information, wechsler$Similarities)\n## \n##  Pearson's product-moment correlation\n## \n## data:  wechsler$Information and wechsler$Similarities\n## t = 7.1746, df = 35, p-value = 2.277e-08\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  0.5966733 0.8764458\n## sample estimates:\n##       cor \n## 0.7715297\n\nThe sum of the diagonal of any square matrix is called the trace. The trace of the covariance matrix is a single number that expresses the total dispersion of the data set.\n\\[\\mathrm{Trace}(S) = \\sum_p S_{pp}\\]\nThe trace has the shortcoming of not taking the variable correlations into account. A data set can have a large trace, but really high correlations. Instead, the generalized variance expresses total variation with the determinant.\n\\[|S| = \\sum_{j = 1}^p (-1)^{j+1} b_{1j} |B_{1j}|\\]\nBuild your intuition with the bivariate case. If variables \\(Y\\) and \\(X\\) have a multivariate normal distribution, the conditional distribution of \\(Y|X = x\\) is normal with mean \\(\\mu_Y + \\frac{\\sigma_{YX}}{\\sigma_{XX}}(x - \\mu_X)\\) and variance \\(\\sigma_{YY} - \\frac{\\sigma_{YX}^2}{\\sigma_{XX}}\\). For example, suppose \\(Y\\) = height (in) and \\(X\\) = weight (lbs) are distributed \\(\\mu = \\begin{pmatrix}175 \\\\ 71 \\end{pmatrix}\\) with variance-covariance matrix \\(\\boldsymbol{\\Sigma} = \\begin{pmatrix} 550 & 40 \\\\ 40 & 8 \\end{pmatrix}\\). Conditioning on \\(X = x\\), \\(\\mu_{Y.x} = 175 + \\frac{40}{8}(x - 71)\\) and \\(\\sigma_{Y.x} = 550 - \\frac{40^2}{8}\\).\nExtend this to the multivariate case. Let \\(\\textbf{Y}\\) be a set of outcomes (e.g., blood pressure and cholesterol) and \\(\\textbf{X}\\) be a set of conditioning variables (e.g., age, height, and weight). The multivariate conditional mean, \\(\\mu_{\\textbf{Y}.\\textbf{x}}\\), is\n\\[\n\\begin{equation}\nE(\\textbf{Y} | \\textbf{X} = \\textbf{x}) = \\mu_{\\textbf{Y}} + \\boldsymbol{\\Sigma}_{\\textbf{YX}} \\boldsymbol{\\Sigma}_\\textbf{X}^{-1}(\\textbf{x} - \\boldsymbol{\\mu}_\\textbf{X})\n(\\#eq:multivariate-conditional-mean)\n\\end{equation}\n\\]\nThe multivariate conditional variance-covariance matrix of \\(\\textbf{Y}\\), \\(\\Sigma_{\\textbf{Y}.\\textbf{x}}\\), is\n\\[\n\\begin{equation}\nE(\\textbf{Y} | \\textbf{X} = \\textbf{x}) = \\mu_{\\textbf{Y}} + \\boldsymbol{\\Sigma}_{\\textbf{YX}} \\boldsymbol{\\Sigma}_\\textbf{X}^{-1}(\\textbf{x} - \\boldsymbol{\\mu}_\\textbf{X})\n(\\#eq:multivariate-conditional-mean)\n\\end{equation}\n\\]\nthe mean of a set of outcomes, \\(\\textbf{Y}\\) (e.g., blood pressure and cholesterol) conditioned on a set of attributes, \\(\\textbf{X}\\) (e.g., age, height, and weight). Denote it as . Denote the conditional variance as \\(\\sigma_{\\textbf{Y}.x}^2 = \\text{var}(\\textbf{Y}|\\textbf{X}=\\textbf{x})\\). It is equal to conditional squared difference from the mean, \\(E\\{(\\textbf{Y} - \\boldsymbol{\\mu}_{\\textbf{Y}.\\textbf{x}})^2|\\textbf{X} = \\textbf{x}\\}\\). Any two variables, \\(Y_i\\) and \\(Y_j\\) have a conditional covariance \\(\\sigma_{i,j.\\textbf{x}} = \\text{cov}(Y_i,Y_j|\\textbf{X} = \\textbf{x})\\). It is equal to \\(E\\{ (Y_i - \\mu_{Y_{i.x}}) (Y_j - \\mu_{Y_{j.x}}) | \\textbf{X} = \\textbf{x}\\}\\). The set of all covariances is a matrix.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "11-association.html#footnotes",
    "href": "11-association.html#footnotes",
    "title": "11  Association",
    "section": "",
    "text": "See https://www.statology.org/correlation-between-categorical-variables/↩︎\nThe test is sometimes call the chi-square test for association.↩︎\nIndependence is usually true by assumption and/or construction. It can be violated by, for example, a sample that includes spouses where one spouse’s status (e.g., preference for a vacation destination) may be related to the other spouse’s status.↩︎\nIt doesn’t apply to just 2 x 2, so I need to figure out why.↩︎\nk-1 because it returns the probability of &gt;k and we want &gt;=k).↩︎\nI don’t really know what that means. Brownlee might help.↩︎\nThis tutorial says both variables should have more than two levels, but doesn’t explain why.↩︎",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Association</span>"
    ]
  },
  {
    "objectID": "12-matrix-algebra.html",
    "href": "12-matrix-algebra.html",
    "title": "12  Matrix Algebra",
    "section": "",
    "text": "12.1 Central Tendancy, Dispersion, and Association\nThis section is a primer on basic matrix algebra and its application to multivariate statistics.1\nAn initial remark on these notes: Matrix algebra treats data transposed to how it is actually stored. An \\(n\\)-row \\(\\times\\) \\(p\\)-column data set is represented in matrix \\(X\\) as \\(n\\) columns and \\(p\\) rows. Think of \\(X\\) as a column vector of variables with each variable represented by a row vector of observations.\n\\[\nX_i = \\begin{pmatrix}X_{i1} \\\\ X_{i2} \\\\ \\vdots \\\\ X_{ip} \\end{pmatrix}\n\\]\nSo \\(X_{ij}\\) refers to index \\(i\\) of row vector \\(j\\), opposite of how the data frame is organized. Observation \\(i\\) is represented as \\(X_i\\), but it is a column vector of the matrix.\nThe mean of variable \\(j\\) is the average of row vector \\(X_j\\), \\(\\bar{x}_j = \\frac{1}{n} \\sum_{i = 1}^n X_{ij}\\). \\(\\bar{x}_j\\) estimates the population mean, \\(\\mu_j = E(X_j)\\). The collection of means are a column vector.\n\\[\\boldsymbol{\\mu} = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\cdots \\\\ \\mu_p  \\end{pmatrix}\\]\nThe variance of variable \\(j\\) is the average squared difference from the mean for row vector \\(X_j\\), \\(s_j^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar{x}_j)^2\\). It estimates the population variance, \\(\\sigma_j^2 = E(X_j - \\mu_j)^2\\). Again, the collection is represented as a column vector,\n\\[\\boldsymbol{\\sigma}^2 = \\begin{pmatrix} \\sigma_1^2 \\\\ \\sigma_2^2 \\\\ \\cdots \\\\ \\sigma_p^2  \\end{pmatrix}\\]\nThe covariance of variables \\(j\\) and \\(k\\) is the average product of differences from their respective means, \\(s_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar{x}_j) (X_{ik} - \\bar{x}_k)\\). It estimates the population covariance, \\(\\sigma_{jk} = E\\{ (X_{ij} - \\mu_j) (X_{ik} - \\mu_k)\\}\\). Notice how the covariance is positive if when one variable is larger than its mean, so is the other. A zero covariance implies the value of one variable tells you nothing about the other. It can be shown that the covariance is equivalently expressed as\n\\[\ns_{jk} = \\frac{1}{n-1} \\left[ \\sum_{i=1}^n X_{ij}X_{ik} - \\frac{\\sum_{i = 1}^n X_{ij} \\sum_{i = 1}^n X_{ik}}{n} \\right]\n\\]\nThis is how it is actually calculated (see example below). The first term is dot product \\(X_j \\cdot X_k\\). The second term is the product of the averages. The generalization across the entire matrix is the variance-covariance matrix.\n\\[\n\\begin{align}\nS &= \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{x}) (X_i - \\bar{x})' \\\\\n&= \\frac{1}{n-1} \\left[ \\sum_{i=1}^n X_i X_i^{'} - \\frac{\\sum_{i = 1}^n X_i \\sum_{i = 1}^n X_i}{n} \\right]\n\\end{align}\n\\]\nDivide the covariance of two variables by the product of their standard deviations to get the correlation.\n\\[\n\\rho_{jk} = \\frac{\\sigma_{jk}}{\\sigma_j \\sigma_k}\n\\]\nThe sum of the diagonal of any square matrix is called the trace. The trace of the covariance matrix is a single number that expresses the total dispersion of the data set.\n\\[\\mathrm{Trace}(S) = \\sum_p S_{pp}\\]\nThe trace has the shortcoming of not taking the variable correlations into account. A data set can have a large trace, but really high correlations. Instead, the generalized variance expresses total variation with the determinant.\n\\[|S| = \\sum_{j = 1}^p (-1)^{j+1} b_{1j} |B_{1j}|\\]",
    "crumbs": [
      "Reference",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matrix Algebra</span>"
    ]
  },
  {
    "objectID": "12-matrix-algebra.html#central-tendancy-dispersion-and-association",
    "href": "12-matrix-algebra.html#central-tendancy-dispersion-and-association",
    "title": "12  Matrix Algebra",
    "section": "",
    "text": "Example\nFile nutrient.txt is from PSU STAT 505.\n\nnutrient &lt;- readr::read_fwf(\n  file = \"./input/nutrient.txt\", \n  col_positions = readr::fwf_widths(\n    c(3, 8, 8, 8, 8, 8),\n    col_names = c(\"ID\", \"Calcium\", \"Iron\", \"Protien\", \"Vitamin A\", \"Vitamin C\")\n  ),\n  show_col_types = FALSE\n) \n\nThis is an 737 \\(\\times\\) 5 data set.\n\n(nutrient_smry &lt;- nutrient %&gt;% pivot_longer(cols = -ID) %&gt;%\n  summarize(M = mean(value), SD = sd(value), .by = name))\n\n# A tibble: 5 × 3\n  name          M      SD\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Calcium   624.   397.  \n2 Iron       11.1    5.98\n3 Protien    65.8   30.6 \n4 Vitamin A 840.  1634.  \n5 Vitamin C  78.9   73.6 \n\n\nCalculate the variance-covariance matrix with matrix algebra. Notice the transpose step, t(), to convert the \\(i \\times j\\) data set into the \\(j \\times i\\) matrix .\n\nX &lt;- nutrient %&gt;% select(-ID) %&gt;% as.matrix() %&gt;% t()\n\nvarcov_mtrx &lt;- 1 / (nrow(nutrient) - 1) * \n    (X %*% t(X) - rowSums(X) %*% t(rowSums(X)) / nrow(nutrient))\n\nround(varcov_mtrx, 0)\n\n          Calcium Iron Protien Vitamin A Vitamin C\nCalcium    157829  940    6076    102411      6702\nIron          940   36     114      2383       138\nProtien      6076  114     935      7330       477\nVitamin A  102411 2383    7330   2668452     22063\nVitamin C    6702  138     477     22063      5416\n\n\nDivide by the product of the standard deviations to get the correlation matrix.\n\nsd_prd &lt;- nutrient_smry$SD %*% t(nutrient_smry$SD)\n\ncorr_mtrx &lt;- varcov_mtrx / sd_prd\n\nround(corr_mtrx, 3)\n\n          Calcium  Iron Protien Vitamin A Vitamin C\nCalcium     1.000 0.395   0.500     0.158     0.229\nIron        0.395 1.000   0.623     0.244     0.313\nProtien     0.500 0.623   1.000     0.147     0.212\nVitamin A   0.158 0.244   0.147     1.000     0.184\nVitamin C   0.229 0.313   0.212     0.184     1.000\n\n\nThat’s what cor() does.\n\nnutrient %&gt;% select(-ID) %&gt;% cor() %&gt;% round(digits = 3)\n\n          Calcium  Iron Protien Vitamin A Vitamin C\nCalcium     1.000 0.395   0.500     0.158     0.229\nIron        0.395 1.000   0.623     0.244     0.313\nProtien     0.500 0.623   1.000     0.147     0.212\nVitamin A   0.158 0.244   0.147     1.000     0.184\nVitamin C   0.229 0.313   0.212     0.184     1.000\n\n\nThe coefficient of determination is the square of the correlation coefficient. Interpret cell (1, 2) below as 15.6% of the variation in iron is explained by calcium intake, or vice-versa.\n\nr_sqr_mtrx &lt;- corr_mtrx^2\n\nround(r_sqr_mtrx, 3)\n\n          Calcium  Iron Protien Vitamin A Vitamin C\nCalcium     1.000 0.156   0.250     0.025     0.053\nIron        0.156 1.000   0.389     0.059     0.098\nProtien     0.250 0.389   1.000     0.022     0.045\nVitamin A   0.025 0.059   0.022     1.000     0.034\nVitamin C   0.053 0.098   0.045     0.034     1.000\n\n\nThe total variation of the nutrient data set is the trace of the covariance-variance matrix.\n\npsych::tr(varcov_mtrx)\n## [1] 2832669\n\n# Or just the sum of the variances\nsum((nutrient_smry$SD)^2)\n## [1] 2832669\n\nThe generalized variance is the determinant.\n\ndet(varcov_mtrx)\n\n[1] 2.831042e+19",
    "crumbs": [
      "Reference",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matrix Algebra</span>"
    ]
  },
  {
    "objectID": "12-matrix-algebra.html#linear-transformations",
    "href": "12-matrix-algebra.html#linear-transformations",
    "title": "12  Matrix Algebra",
    "section": "12.2 Linear Transformations",
    "text": "12.2 Linear Transformations\nLinear combinations can be expressed as the multiplication of a matrix by the transpose of a column vector, \\(\\textbf{Y} = \\textbf{c}^{'} \\textbf{X}\\). A trivial example can be taken from the nutrient.txt example data from the prior section. Vitamin A is measured in micrograms and vitamin C is measured in milligrams. The total intake in milligrams is measured by the transformation, \\(\\textbf{Y} = .001 X_4 + X_5\\).\nThe mean of linear combination is the linear combination of the means, \\(\\bar{\\textbf{y}} = \\textbf{c}'\\bar{x}\\). \\(\\bar{\\textbf{y}}\\) estimates the population mean, \\(\\textbf{c}'\\mathbf{\\mu} = E(\\textbf{Y})\\).\n\\(\\text{Var}(Y) = \\textbf{c}' \\mathbf{\\Sigma} \\textbf{c}\\) where \\(\\mathbf{\\Sigma}\\) is the variance-covariance matrix.\nSuppose you have two linear transformations, \\(\\textbf{Y}_1 = \\textbf{c}^{'} \\textbf{X}\\) and \\(\\textbf{Y}_1 = \\textbf{d}^{'} \\textbf{X}\\). Their covariance, \\(\\sigma_{Y_1 Y_2}\\), is \\(\\text{Cov}(Y_1, Y_2) = \\textbf{c}' \\mathbf{\\Sigma} \\textbf{d}\\). Their correlation is their covariance divided by the individual standard deviations, \\(\\rho = \\frac{\\sigma_{Y_1 Y_2}}{\\sigma_{Y_1}\\sigma_{Y_2}}\\).\n\nExample\nUsing file nutrient.txt from the prior section, if \\(Y = .001 X_4 + X5\\), then the mean of \\(Y\\) is 79.8.\n\nC &lt;- c(0, 0, 0, .001, 1)\nx_bar &lt;- nutrient_smry$M\n\n# Mean\nt(C) %*% x_bar\n##          [,1]\n## [1,] 79.76808\n\n# Variance\n(VarY1 &lt;- t(C) %*% varcov_mtrx %*% C)\n##          [,1]\n## [1,] 5463.059\n\n# Covariance between Y1 = cX and Y2 = dX\nd &lt;- c(1, 1, 0, 0, 0)\n(CovY1Y2 &lt;- t(C) %*% varcov_mtrx %*% d)\n##          [,1]\n## [1,] 6944.082\n\n# Correlation\nVarY2 &lt;- t(d) %*% varcov_mtrx %*% d\n(CorY1Y2 &lt;- CovY1Y2 / sqrt(VarY1 * VarY2))\n##           [,1]\n## [1,] 0.2350621",
    "crumbs": [
      "Reference",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matrix Algebra</span>"
    ]
  },
  {
    "objectID": "12-matrix-algebra.html#multivariate-normal-distribution",
    "href": "12-matrix-algebra.html#multivariate-normal-distribution",
    "title": "12  Matrix Algebra",
    "section": "12.3 Multivariate Normal Distribution",
    "text": "12.3 Multivariate Normal Distribution\nThe univariate normal distribution, \\(X \\sim N(\\mu, \\sigma^2)\\), is a function of the variable’s mean and variance, \\(\\phi(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\exp\\{-\\frac{1}{2\\sigma^2} (x - \\mu)^2\\}\\). The multivariate normal distribution is similar except that the mean is the mean vector and the variance is the variance-covariance matrix, \\(\\textbf{X} \\sim N(\\mu, \\Sigma)\\). Notice the determinant \\(|\\Sigma|\\) and matrix inverse in the equation.\n\\[\n\\begin{equation}\n\\phi(\\textbf{X}) = \\left(\\frac{1}{2 \\pi}\\right)^{p/2}|\\Sigma|^{-1/2}\\exp\\{-\\frac{1}{2} (\\textbf{x} - \\mathbf{\\mu})'\\Sigma^{-1}(\\textbf{x} - \\mathbf{\\mu})\\}\n\\end{equation}\n(\\#eq:multivariate-normal)\n\\]\nIf \\(p\\) is 2, then you have a bi-variate normal distribution. The exponentiated term \\((\\textbf{x} - \\mathbf{\\mu})'\\Sigma^{-1}(\\textbf{x} - \\mathbf{\\mu})\\) is called the squared Mahalanobis distance between \\(x\\) and \\(\\mu\\).\nA linear transformation is distributed \\(\\textbf{Y} \\sim N(\\textbf{c}'\\mu, \\textbf{c}'\\Sigma \\textbf{c})\\). It’s useful to note that each variable in the multivariate normal distribution is normal, as are subsets of variables, linear combinations, and conditional distributions.\nFor an intuitive understanding of the material, consider the bivariate case.\n\\[\n\\begin{pmatrix}X_1 \\\\ X_2 \\end{pmatrix} \\sim N \\left[ \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix} \\begin{pmatrix} \\sigma_1^2 & \\rho \\sigma_1 \\sigma_2 \\\\ \\rho \\sigma_1 \\sigma_2 & \\sigma_2^2 \\end{pmatrix}\\right]\n\\]\nIf \\(\\rho\\) is 0, then the bivariate normal density function is symmetric in all dimension. As \\(\\rho \\rightarrow 1\\), the curve gets increasing skinny along the diagonal.\n\nx &lt;- seq(-4, 4, .1)\ny &lt;- seq(-4, 4, .1)\n\nz_values &lt;- function(x, y, r = .8) {\n  exp(-(x^2-2*r*x*y+y^2)/2/(1-r^2))/2/pi/sqrt(1-r^2)\n}\n\n\n\n\n\n# correlation is .3\nz &lt;- outer(x, y, z_values, .3)\npersp(x, y, z)\n\n\n\n\n\n\n\n\n\n\n\n# correlation is .9\nz &lt;- outer(x, y, z_values, .9)\npersp(x, y, z)\n\n\n\n\n\n\n\n\n\n\nThe squared Mahalanobis distance, \\(d^2 = (\\textbf{x} - \\mathbf{\\mu})'\\Sigma^{-1}(\\textbf{x} - \\mathbf{\\mu})\\), is the equation for a hyper-ellipse centered at \\(\\mu\\). In two dimensions, it looks like this:\n\nbvn_mtrx &lt;- MASS::mvrnorm(\n  n = 100,\n  mu = c(10, 5),\n  Sigma = matrix(c(10, 5, 2, 9), ncol = 2)\n)\ncolnames(bvn_mtrx) &lt;- c(\"x1\", \"x2\")\n\nd2 &lt;- mahalanobis(bvn_mtrx, colMeans(bvn_mtrx), cov(bvn_mtrx))\n\nbvn &lt;- as_tibble(bvn_mtrx) %&gt;% bind_cols(d2 = d2)\n\nbvn %&gt;% ggplot(aes(x = x1, y = x2, color = d2)) + \n  geom_point() +\n  scale_color_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\n\\(d^2\\) has a chi-square distribution with \\(p\\) degrees of freedom. The distribution can be used to evaluate whether a point is an outlier or whether the data is multivariate normal. A Q-Q plot shows the ordered Mahalanobis distances versus the quantiles for a sample of size \\(n\\) from a chi-squared distribution with \\(p\\) degrees of freedom.\n\nqqplot(dchisq(bvn$d2, 2), bvn$d2)\n\n\n\n\n\n\n\n\nDescribe the shape of the ellipse mathematically with eigenvalues and eigenvectors of the variance-covariance matrix.2 A \\(p \\times p\\) matrix \\(\\textbf{A}\\) has \\(p\\) eigenvalues, \\([\\lambda_1, .., \\lambda_p]\\), that solve the expression\n\\[\n\\begin{equation}\n|\\textbf{A} - \\lambda \\textbf{I}| = 0.\n(\\#eq:eigenvalue)\n\\end{equation}\n\\]\nCalculate \\(\\lambda\\) by taking the determinant and solving the resulting \\(p\\)-ordered polynomial. The result is \\(p\\) solutions, not necessarily all unique. Plug the eigenvectors into the following equation and solve for the \\(p\\) eigenvectors, \\(\\textbf{e}\\). The eigenvector solutions are generally not unique, so to obtain a unique solution, require that \\(\\textbf{e}_j'\\textbf{e}_j = 1\\).\n\\[\n\\begin{equation}\n(\\textbf{A} - \\lambda_j \\textbf{I}) \\textbf{e}_j = \\textbf{0}\n(\\#eq:eigenvector)\n\\end{equation}\n\\]\nThe eigenvalues and eigenvectors define the shape and orientation of the \\((1 - \\alpha)\\%\\) prediction ellipse. The ellipse is centered on the means with axes pointing in the directions of the eigenvectors. The distance from the origin to the ellipse boundary is\n\\[\n\\begin{equation}\nl_j = \\sqrt{\\lambda_j \\chi_{p, \\alpha}^2}\n(\\#eq:prediction-ellipse-dist)\n\\end{equation}\n\\]\n\ndat &lt;- tibble(X = runif(40, 5, 20))\ndat$Y &lt;- dat$X + rnorm(40, 0, 3)\n\nmu_X &lt;- mean(dat$X)\nmu_Y &lt;- mean(dat$Y)\n\ndat %&gt;%\n  ggplot(aes(x = X, y = Y)) + \n  geom_point() + \n  stat_ellipse(type = \"norm\") +\n  geom_segment(aes(x = mu_X, y = 0, xend = mu_X, yend = mu_Y), linetype = 2) +\n  geom_segment(aes(x = 0, y = mu_Y, xend = mu_X, yend = mu_Y), linetype = 2) +\n  # annotate(\"text\", x = 0, y = mu_Y*1.1, label = expression(paste(mu[Y])), parse = TRUE, hjust = 0) +\n  # annotate(\"text\", x = mu_X*1.05, y = 0, label = expression(paste(mu[X])), parse = TRUE, hjust = 0) +\n  geom_segment(x = mu_X, y = mu_Y, xend = 8.5, yend = 16, \n               arrow = arrow(length = unit(0.03, \"npc\")), color = \"goldenrod\") +\n  geom_segment(x = mu_X, y = mu_Y, xend = 22.5, yend = 24.5, \n               arrow = arrow(length = unit(0.03, \"npc\")), color = \"goldenrod\") +\n  # annotate(\"text\", x = 8, y = 14.5, label = expression(paste(lambda[Y])), \n  #          parse = TRUE, hjust = 0, color = \"darkgoldenrod\") +\n  # annotate(\"text\", x = 20, y = 23.5, label = expression(paste(lambda[X])), \n  #          parse = TRUE, hjust = 0, color = \"darkgoldenrod\") +\n  tune::coord_obs_pred()\n\n\n\n\n\n\n\n\nThe elliptical shape is due to the correlation in the data. In the two-dimensional diagram above, the ellipse would be a perfect circle if the covariances were zero. The eigenvalues would equal the variances, \\(\\lambda = \\sigma^2\\), and the eigenvectors would be parallel to the coordinate axis, \\(\\textbf{e} = \\begin{pmatrix}1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\). The ellipse flattens with increasing correlation.\n\nExample\nFile wechsler.txt is a 37x4 data set from PSU STAT 505 with variance-covariance matrix\n\nwechsler &lt;- readr::read_fwf(\n  file = \"./input/wechsler.txt\", \n  col_positions = readr::fwf_widths(\n    c(2, 3, 3, 3, 3),\n    col_names = c(\"ID\", \"Information\", \"Similarities\", \"Arithmetic\", \"PictureCompletion\")\n  ),\n  show_col_types = FALSE\n) \n\n(weschler_cov &lt;- cov(wechsler[, -1]))\n\n                  Information Similarities Arithmetic PictureCompletion\nInformation         11.474474    9.0855856   6.382883         2.0713213\nSimilarities         9.085586   12.0855856   5.938438         0.5435435\nArithmetic           6.382883    5.9384384  11.090090         1.7912913\nPictureCompletion    2.071321    0.5435435   1.791291         3.6936937\n\n\nand the eigenvalues and eigenvectors\n\n(weschler_eigen &lt;- eigen(weschler_cov))\n\neigen() decomposition\n$values\n[1] 26.245278  6.255366  3.931553  1.911647\n\n$vectors\n           [,1]       [,2]       [,3]        [,4]\n[1,] -0.6057467  0.2176473  0.4605028  0.61125912\n[2,] -0.6047618  0.4958117 -0.3196759 -0.53501516\n[3,] -0.5051337 -0.7946452 -0.3349263  0.03468877\n[4,] -0.1103360 -0.2744802  0.7573433 -0.58216643\n\n\nNow consider the 95% prediction ellipse formed by the multivariate normal distribution whose variance-covariance matrix. The half-lengths of the ellipse axes are \\(l_j = \\sqrt{\\lambda_j \\chi_{p, \\alpha}^2}\\) where \\(\\chi_{4, .05}^2\\) is 9.49.\n\n(weschler_half_len &lt;- (weschler_eigen$values * qchisq(.95, 4))^.5)\n\n[1] 15.779990  7.703845  6.107496  4.258778\n\n\nThe eigenvectors are the directions of the axes. The first vector, (-0.606, -0.605, -0.505, -0.110) has large values for the first three variables (Information, Similarities, and Arithmetic) and a small value for the fourth (PictureCompletion), so the vector points toward the first three. The second axis has a half-length that is about half the size of the first. It’s directed mostly toward the third variable (Arithmetic) and decreasing for the second variable (Similarities). Overall, the ellipse has one long axis and three shorter axes.\n\nmu_Information &lt;- mean(wechsler$Information)\n\nmu_Similarities &lt;- mean(wechsler$Similarities)\n\nggplot(wechsler, aes(x = Information, y = Similarities)) + \n  geom_point() + \n  stat_ellipse(type = \"norm\") +\n  geom_segment(aes(x = mu_Information, y = 0, xend = mu_Information, yend = mu_Similarities), linetype = 2) +\n  geom_segment(aes(x = 0, y = mu_Similarities, xend = mu_Information, yend = mu_Similarities), linetype = 2) +\n  annotate(\"text\", x = 0, y = mu_Similarities*1.1, label = expression(paste(mu[2])), parse = TRUE, hjust = 0) +\n  annotate(\"text\", x = mu_Information*1.05, y = 0, label = expression(paste(mu[1])), parse = TRUE, hjust = 0) +\n  geom_segment(x = mu_Information, y = mu_Similarities, xend = 10, yend=12.5, arrow = arrow(length = unit(0.03, \"npc\"))) +\n  geom_segment(x = mu_Information, y = mu_Similarities, xend = 21, yend=17.5, arrow = arrow(length = unit(0.03, \"npc\"))) +\n  annotate(\"text\", x = 11, y = 12, label = expression(paste(lambda[2])), parse = TRUE, hjust = 0) +\n  annotate(\"text\", x = 19, y = 17, label = expression(paste(lambda[1])), parse = TRUE, hjust = 0) +\n  tune::coord_obs_pred()\n\nhttps://online.stat.psu.edu/stat505/lesson/4",
    "crumbs": [
      "Reference",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matrix Algebra</span>"
    ]
  },
  {
    "objectID": "12-matrix-algebra.html#footnotes",
    "href": "12-matrix-algebra.html#footnotes",
    "title": "12  Matrix Algebra",
    "section": "",
    "text": "Notes are primarily from PSU STAT 505: Applied Multivariate Statistical Analysis.↩︎\nEigenvalues and eigenvectors show up in confidence ellipses, PCA, and factor analysis.↩︎",
    "crumbs": [
      "Reference",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Matrix Algebra</span>"
    ]
  },
  {
    "objectID": "13-references.html",
    "href": "13-references.html",
    "title": "References",
    "section": "",
    "text": "r if (knitr::is_html_output()) ' '",
    "crumbs": [
      "References"
    ]
  }
]